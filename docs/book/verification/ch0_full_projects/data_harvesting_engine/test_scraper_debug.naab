// Debug web scraper

use io
use json
use string

main {
    io.write("Testing web scraper with example.com\n")

    let test_url = "https://example.com"
    let extraction_rules_json = '{"item_container": "body", "agent_name": "h1", "agent_description": "p"}'

    let result_json: string? = <<python[test_url, extraction_rules_json]
import requests
from bs4 import BeautifulSoup
import json

web_url = test_url
extraction_rules_dict = json.loads(extraction_rules_json)

scraped_items_list = []
error_message = None

try:
    response = requests.get(web_url, timeout=10)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, 'html.parser')

    item_container_selector = extraction_rules_dict.get("item_container", "")

    if item_container_selector:
        containers = soup.select(item_container_selector)
        for container in containers:
            name_el = container.select_one(extraction_rules_dict.get("agent_name", ""))
            desc_el = container.select_one(extraction_rules_dict.get("agent_description", ""))

            name = name_el.get_text(strip=True) if name_el else "N/A"
            description = desc_el.get_text(strip=True) if desc_el else "N/A"

            scraped_items_list.append({
                "name": name,
                "description": description,
                "raw_html_snippet": str(container)[:200]
            })

except Exception as e:
    error_message = f"Python Request Error: {e}"

if error_message:
    result_data = {"error": error_message}
else:
    result_data = scraped_items_list

json.dumps(result_data)
    >>

    if result_json == null {
        io.write_error("❌ Python returned null\n")
    } else {
        io.write("✅ Python result:\n", result_json, "\n\n")

        let parsed = json.parse(result_json)
        io.write("Parsed type check\n")
    }
}
