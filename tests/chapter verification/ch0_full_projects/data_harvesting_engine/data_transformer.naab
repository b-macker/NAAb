// data_transformer.naab - Module for processing, cleaning, and validating scraped data

// Import standard library modules
use io
use json
use string
use array

// Imports the ScrapedItem struct from web_scraper.naab
use web_scraper

// Structure to hold processed data
struct ProcessedItem {
    name: string,
    description: string,
    processed_timestamp: float,
    description_length: int
    // Potentially more fields after cleaning and normalization
}

// Function to clean, normalize, and validate a list of scraped items
fn process_and_validate_data(raw_items: list<web_scraper.ScrapedItem>) -> list<ProcessedItem>? {
    io.write("üßπ Processing and validating raw data...\n")

    // Serialize structs directly - json.stringify now supports structs!
    let raw_items_json = json.stringify(raw_items)
    let schema_json = '{
        "type": "object",
        "properties": {
            "name": {"type": "string", "minLength": 1},
            "description": {"type": "string"},
            "processed_timestamp": {"type": "number"},
            "description_length": {"type": "number"}
        },
        "required": ["name", "description", "processed_timestamp", "description_length"]
    }'

    let result_json = <<python[raw_items_json, schema_json]
import pandas as pd
import json
from jsonschema import validate, ValidationError
import sys
import io as pyio
import time

old_stdout = sys.stdout
old_stderr = sys.stderr
redirected_output = pyio.StringIO()
sys.stdout = redirected_output
sys.stderr = old_stderr

raw_items_str = raw_items_json
schema_str = schema_json

processed_items_list = []
error_message = None

try:
    raw_data = json.loads(raw_items_str)
    schema = json.loads(schema_str)

    # Convert to pandas DataFrame for easy manipulation
    df = pd.DataFrame(raw_data)

    # --- Data Cleaning and Normalization ---
    # Example: Fill missing descriptions, convert to lowercase, remove extra spaces
    if 'description' in df.columns:
        df['description'] = df['description'].fillna('').astype(str).str.lower().str.strip()
    if 'name' in df.columns:
        df['name'] = df['name'].fillna('').astype(str).str.strip()

    # Example: Feature Engineering - Add description length
    df['description_length'] = df['description'].apply(len)

    # Add processing timestamp
    df['processed_timestamp'] = time.time()

    # Select and rename columns to match ProcessedItem struct
    # This ensures only the relevant data goes back to NAAb
    processed_df = df[['name', 'description', 'processed_timestamp', 'description_length']]
    
    # Convert DataFrame records back to list of dicts for JSON serialization
    processed_items_list = processed_df.to_dict(orient='records')

    # --- Data Validation (per item) ---
    for item in processed_items_list:
        try:
            validate(instance=item, schema=schema)
        except ValidationError as e:
            error_message = f"Schema Validation Error: {e.message} in item {item.get('name', 'unknown')}"
            raise # Re-raise to be caught by the outer except

except ValidationError as e:
    error_message = f"Validation Error (Python): {e.message}"
except Exception as e:
    error_message = f"Python Processing/General Error: {e}"

finally:
    sys.stdout = old_stdout
    sys.stderr = old_stderr

if error_message:
    _ = json.dumps({"error": error_message})
else:
    _ = json.dumps(processed_items_list)
    >>

    let python_output_str = result_json

    if str.starts_with(python_output_str, "{") && str.contains(python_output_str, "\"error\":") {
        let error_obj = json.parse(python_output_str)
        if error_obj["error"] != null {
            io.write_error("‚ùå Data processing failed: ", error_obj["error"], "\n")
            return null
        }
    }

    let parsed_items = json.parse(python_output_str)
    let processed_items: list<ProcessedItem> = []

    for item_data in parsed_items {
        let new_item = new ProcessedItem {
            name: item_data["name"],
            description: item_data["description"],
            processed_timestamp: item_data["processed_timestamp"],
            description_length: item_data["description_length"]
        }
        processed_items = array.push(processed_items, new_item)
    }
    return processed_items
}
