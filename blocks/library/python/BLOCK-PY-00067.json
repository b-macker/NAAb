{
  "code": "extern \"C\" {\n\nvoid BLOCK-PY-00067_execute() {\n    class DevOpsGenerator(BaseCodeGenerator):\n    def __init__(self):\n        super().__init__(\"devops\")\n        self.supported_platforms = [\n            'docker', 'kubernetes', 'k8s',\n            'github-actions', 'gitlab-ci', 'jenkins', 'azure-devops',\n            'terraform', 'ansible', 'helm',\n            'prometheus', 'grafana', 'elk', 'datadog',\n            'aws', 'azure', 'gcp', 'digital-ocean'\n        ]\n    \n    def _initialize_generators(self) -> Dict[str, callable]:\n        \"\"\"Initialize DevOps generator methods\"\"\"\n        return {\n            'dockerfile': self._generate_dockerfile,\n            'docker_compose': self._generate_docker_compose,\n            'k8s_deployment': self._generate_k8s_deployment,\n            'github_actions': self._generate_github_actions,\n            'default': self._generate_basic_devops\n        }\n    \n    def _initialize_patterns(self) -> Dict[str, List[str]]:\n        \"\"\"Initialize DevOps keyword patterns\"\"\"\n        return {\n            'dockerfile': ['docker', 'container', 'image'],\n            'docker_compose': ['compose', 'multi container'],\n            'k8s_deployment': ['kubernetes', 'k8s', 'deployment'],\n            'github_actions': ['github actions', 'workflow', 'ci', 'pipeline']\n        }\n    \n    def _initialize_templates(self) -> Dict[str, str]:\n        \"\"\"Initialize DevOps templates\"\"\"\n        return {\n            'basic_dockerfile': '''FROM node:18-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nEXPOSE 3000\nCMD [\"npm\", \"start\"]'''\n        }\n    \n    def _generate_fallback(self, request) -> CodeGenerationResult:\n        \"\"\"Generate fallback DevOps config\"\"\"\n        return self._generate_basic_devops(request, 'docker', 'medium')\n        \n    def generate_code(self, request) -> CodeGenerationResult:\n        try:\n            message = getattr(request, 'message', '').lower()\n            complexity = getattr(request, 'complexity', 'medium')\n            platform = getattr(request, 'framework', '').lower() or self._detect_platform(message)\n            \n            patterns = {\n                # Container Orchestration\n                r'docker.*file|docker.*image|container.*build': self._generate_dockerfile,\n                r'docker.*compose|multi.*container': self._generate_docker_compose,\n                r'kubernetes|k8s.*deployment': self._generate_k8s_deployment,\n                r'helm.*chart|helm.*template': self._generate_helm_chart,\n                r'pod.*config|k8s.*pod': self._generate_k8s_pod,\n                \n                # CI/CD Pipelines\n                r'github.*action|github.*workflow': self._generate_github_actions,\n                r'gitlab.*ci|gitlab.*pipeline': self._generate_gitlab_ci,\n                r'jenkins.*file|jenkins.*pipeline': self._generate_jenkins_pipeline,\n                r'azure.*devops|azure.*pipeline': self._generate_azure_pipeline,\n                r'ci.*cd.*pipeline|deployment.*pipeline': self._generate_generic_pipeline,\n                \n                # Infrastructure as Code\n                r'terraform|tf.*config': self._generate_terraform,\n                r'ansible.*playbook|ansible.*config': self._generate_ansible_playbook,\n                r'cloudformation|aws.*template': self._generate_cloudformation,\n                r'bicep|azure.*template': self._generate_bicep_template,\n                \n                # Monitoring & Observability\n                r'prometheus|monitoring.*config': self._generate_prometheus_config,\n                r'grafana.*dashboard|metrics.*dashboard': self._generate_grafana_dashboard,\n                r'elk.*stack|elasticsearch.*config': self._generate_elk_stack,\n                r'logging.*config|log.*aggregation': self._generate_logging_config,\n                \n                # Security & Compliance\n                r'security.*scan|vulnerability.*scan': self._generate_security_pipeline,\n                r'compliance.*check|policy.*enforcement': self._generate_compliance_config,\n                r'secret.*management|credential.*management': self._generate_secret_management,\n                \n                # Performance & Scaling\n                r'load.*balancer|ingress.*controller': self._generate_ingress_config,\n                r'auto.*scaling|hpa.*config': self._generate_autoscaling,\n                r'performance.*test|load.*test': self._generate_performance_test,\n                \n                # Backup & Disaster Recovery\n                r'backup.*strategy|disaster.*recovery': self._generate_backup_config,\n                r'restore.*procedure|recovery.*plan': self._generate_recovery_plan,\n                \n                # Cloud Native Patterns\n                r'microservice.*mesh|service.*mesh': self._generate_service_mesh,\n                r'api.*gateway|ingress.*gateway': self._generate_api_gateway,\n                r'event.*driven|message.*queue': self._generate_event_system,\n            }\n            \n            for pattern, generator_func in patterns.items():\n                if re.search(pattern, message):\n                    result = generator_func(request, platform, complexity)\n                    result.dependencies = self._extract_dependencies(result.code, platform)\n                    return result\n            \n            return self._generate_default_devops(request, platform, complexity)\n            \n        except Exception as e:\n            return CodeGenerationResult(\n                success=False,\n                code=\"\",\n                language=\"devops\",\n                error=f\"DevOps generation error: {str(e)}\"\n            )\n    \n    def _detect_platform(self, message: str) -> str:\n        \"\"\"Detect DevOps platform from message\"\"\"\n        platform_patterns = {\n            'docker': ['docker', 'container', 'dockerfile'],\n            'kubernetes': ['kubernetes', 'k8s', 'kubectl', 'pod', 'deployment'],\n            'terraform': ['terraform', 'tf', 'infrastructure', 'iac'],\n            'ansible': ['ansible', 'playbook', 'configuration management'],\n            'github-actions': ['github actions', 'github workflow'],\n            'gitlab-ci': ['gitlab ci', 'gitlab pipeline'],\n            'jenkins': ['jenkins', 'jenkinsfile'],\n            'aws': ['aws', 'amazon', 'ec2', 's3', 'lambda'],\n            'azure': ['azure', 'microsoft cloud'],\n            'gcp': ['gcp', 'google cloud', 'gke']\n        }\n        \n        for platform, keywords in platform_patterns.items():\n            for keyword in keywords:\n                if keyword in message:\n                    return platform\n        return 'docker'  # Default to Docker\n    \n    def _generate_dockerfile(self, request, platform: str, complexity: str) -> CodeGenerationResult:\n        \"\"\"Generate comprehensive Dockerfile\"\"\"\n        message = request.message.lower()\n        \n        if 'node' in message or 'javascript' in message:\n            dockerfile = self._generate_nodejs_dockerfile(complexity)\n        elif 'python' in message:\n            dockerfile = self._generate_python_dockerfile(complexity)\n        elif 'java' in message or 'spring' in message:\n            dockerfile = self._generate_java_dockerfile(complexity)\n        elif 'go' in message or 'golang' in message:\n            dockerfile = self._generate_go_dockerfile(complexity)\n        elif 'nginx' in message or 'web server' in message:\n            dockerfile = self._generate_nginx_dockerfile(complexity)\n        else:\n            dockerfile = self._generate_generic_dockerfile(complexity)\n        \n        return CodeGenerationResult(\n            success=True,\n            code=dockerfile,\n            language=\"dockerfile\",\n            framework=\"docker\",\n            code_type=CodeType.CONFIGURATION\n        )\n    \n    def _generate_nodejs_dockerfile(self, complexity: str) -> str:\n        \"\"\"Generate Node.js optimized Dockerfile\"\"\"\n        if complexity == 'high':\n            return \"\"\"# Multi-stage Node.js Production Dockerfile\n# Stage 1: Build stage\nFROM node:18-alpine AS builder\n\n# Security: Create non-root user\nRUN addgroup -g 1001 -S nodejs\nRUN adduser -S nextjs -u 1001\n\n# Set working directory\nWORKDIR /app\n\n# Copy package files for dependency caching\nCOPY package*.json ./\nCOPY yarn.lock* ./\n\n# Install dependencies with cache mount\nRUN --mount=type=cache,target=/root/.npm \\\n    npm ci --only=production --frozen-lockfile\n\n# Copy source code\nCOPY . .\n\n# Build application\nRUN npm run build\n\n# Stage 2: Production runtime\nFROM node:18-alpine AS runner\n\n# Install security updates\nRUN apk update && apk upgrade && apk add --no-cache \\\n    dumb-init \\\n    curl \\\n    && rm -rf /var/cache/apk/*\n\n# Security: Create non-root user\nRUN addgroup -g 1001 -S nodejs\nRUN adduser -S nextjs -u 1001\n\nWORKDIR /app\n\n# Copy built application from builder stage  \nCOPY --from=builder --chown=nextjs:nodejs /app/dist ./dist\nCOPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules\nCOPY --from=builder --chown=nextjs:nodejs /app/package*.json ./\n\n# Security: Switch to non-root user\nUSER nextjs\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n    CMD curl -f http://localhost:3000/health || exit 1\n\n# Expose port\nEXPOSE 3000\n\n# Use dumb-init for proper signal handling\nENTRYPOINT [\"dumb-init\", \"--\"]\nCMD [\"node\", \"dist/index.js\"]\n\n# Metadata\nLABEL maintainer=\"devops@company.com\"\nLABEL version=\"1.0.0\"\nLABEL description=\"Production Node.js application\"\nLABEL org.opencontainers.image.source=\"https://github.com/company/app\"\nLABEL org.opencontainers.image.documentation=\"https://docs.company.com/app\"\nLABEL org.opencontainers.image.licenses=\"MIT\"\n\n# Environment variables\nENV NODE_ENV=production\nENV PORT=3000\"\"\"\n        \n        elif complexity == 'medium':\n            return \"\"\"# Node.js Production Dockerfile\nFROM node:18-alpine\n\n# Install security updates and required packages\nRUN apk update && apk upgrade && apk add --no-cache \\\n    dumb-init \\\n    curl\n\n# Create app directory and user\nWORKDIR /app\nRUN addgroup -g 1001 -S nodejs && \\\n    adduser -S nextjs -u 1001\n\n# Copy package files and install dependencies\nCOPY package*.json ./\nRUN npm ci --only=production && npm cache clean --force\n\n# Copy application code\nCOPY . .\nRUN chown -R nextjs:nodejs /app\n\n# Switch to non-root user\nUSER nextjs\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=3s \\\n    CMD curl -f http://localhost:3000/health || exit 1\n\n# Expose port and start application\nEXPOSE 3000\nENTRYPOINT [\"dumb-init\", \"--\"]\nCMD [\"node\", \"index.js\"]\"\"\"\n        \n        else:  # simple\n            return \"\"\"# Simple Node.js Dockerfile\nFROM node:18-alpine\n\nWORKDIR /app\n\n# Copy package files and install dependencies\nCOPY package*.json ./\nRUN npm install --production\n\n# Copy application code\nCOPY . .\n\n# Expose port\nEXPOSE 3000\n\n# Start application\nCMD [\"node\", \"index.js\"]\"\"\"\n    \n    def _generate_python_dockerfile(self, complexity: str) -> str:\n        \"\"\"Generate Python optimized Dockerfile\"\"\"\n        if complexity == 'high':\n            return \"\"\"# Multi-stage Python Production Dockerfile\n# Stage 1: Build stage with development tools\nFROM python:3.11-slim AS builder\n\n# Install build dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    gcc \\\n    python3-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set working directory\nWORKDIR /app\n\n# Copy requirements and install Python dependencies\nCOPY requirements*.txt ./\nRUN pip install --no-cache-dir --user -r requirements.txt\n\n# Stage 2: Production runtime\nFROM python:3.11-slim AS runner\n\n# Install runtime dependencies and security updates\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    curl \\\n    tini \\\n    && apt-get upgrade -y \\\n    && rm -rf /var/lib/apt/lists/* \\\n    && apt-get clean\n\n# Create non-root user\nRUN groupadd -r appuser && useradd -r -g appuser appuser\n\n# Set working directory\nWORKDIR /app\n\n# Copy Python packages from builder\nCOPY --from=builder /root/.local /home/appuser/.local\n\n# Copy application code\nCOPY . .\nRUN chown -R appuser:appuser /app\n\n# Switch to non-root user\nUSER appuser\n\n# Add local Python packages to PATH\nENV PATH=/home/appuser/.local/bin:$PATH\nENV PYTHONPATH=/app\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \\\n    CMD curl -f http://localhost:8000/health || exit 1\n\n# Expose port\nEXPOSE 8000\n\n# Use tini for proper signal handling\nENTRYPOINT [\"tini\", \"--\"]\nCMD [\"python\", \"-m\", \"gunicorn\", \"--bind\", \"0.0.0.0:8000\", \"--workers\", \"4\", \"app:app\"]\n\n# Metadata\nLABEL maintainer=\"devops@company.com\"\nLABEL version=\"1.0.0\"\nLABEL description=\"Production Python application\"\nLABEL python.version=\"3.11\"\nLABEL org.opencontainers.image.source=\"https://github.com/company/python-app\"\nLABEL security.scan=\"enabled\"\nLABEL compliance.level=\"high\"\n\n# Security: Set file permissions\nRUN chmod -R 755 /app && chmod +x /app/entrypoint.sh 2>/dev/null || true\"\"\"\n        \n        elif complexity == 'medium':\n            return \"\"\"# Python Production Dockerfile\nFROM python:3.11-slim\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    curl \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Create non-root user\nRUN groupadd -r appuser && useradd -r -g appuser appuser\n\nWORKDIR /app\n\n# Copy and install Python dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY . .\nRUN chown -R appuser:appuser /app\n\n# Switch to non-root user\nUSER appuser\n\n# Environment variables\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s \\\n    CMD curl -f http://localhost:8000/health || exit 1\n\n# Expose port and start application\nEXPOSE 8000\nCMD [\"gunicorn\", \"--bind\", \"0.0.0.0:8000\", \"app:app\"]\"\"\"\n        \n        else:  # simple\n            return \"\"\"# Simple Python Dockerfile  \nFROM python:3.11-slim\n\nWORKDIR /app\n\n# Copy and install dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Copy application code\nCOPY . .\n\n# Expose port\nEXPOSE 8000\n\n# Start application\nCMD [\"python\", \"app.py\"]\"\"\"\n    \n    def _generate_docker_compose(self, request, platform: str, complexity: str) -> CodeGenerationResult:\n        \"\"\"Generate comprehensive Docker Compose configuration\"\"\"\n        message = request.message.lower()\n        \n        if 'web app' in message or 'full stack' in message:\n            compose = self._generate_fullstack_compose(complexity)\n        elif 'microservice' in message:\n            compose = self._generate_microservices_compose(complexity)\n        elif 'database' in message:\n            compose = self._generate_database_compose(complexity)\n        else:\n            compose = self._generate_generic_compose(complexity)\n        \n        return CodeGenerationResult(\n            success=True,\n            code=compose,\n            language=\"yaml\",\n            framework=\"docker-compose\",\n            code_type=CodeType.CONFIGURATION\n        )\n    \n    def _generate_fullstack_compose(self, complexity: str) -> str:\n        \"\"\"Generate full-stack Docker Compose with all services\"\"\"\n        if complexity == 'high':\n            return \"\"\"# Full-Stack Production Docker Compose\nversion: '3.8'\n\n# Define custom networks\nnetworks:\n  frontend:\n    driver: bridge\n  backend:\n    driver: bridge\n  database:\n    driver: bridge\n    internal: true\n\n# Define persistent volumes\nvolumes:\n  postgres_data:\n    driver: local\n  redis_data:\n    driver: local\n  elasticsearch_data:\n    driver: local\n  grafana_data:\n    driver: local\n  prometheus_data:\n    driver: local\n\nservices:\n  # Reverse Proxy & Load Balancer\n  nginx:\n    image: nginx:1.24-alpine\n    container_name: nginx-proxy\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/ssl:/etc/nginx/ssl:ro\n      - ./nginx/logs:/var/log/nginx\n    networks:\n      - frontend\n      - backend\n    depends_on:\n      - web-app\n      - api-server\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n\n  # Frontend React Application\n  web-app:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile.prod\n      args:\n        - NODE_ENV=production\n        - BUILD_DATE=${BUILD_DATE:-$(date -u +'%Y-%m-%dT%H:%M:%SZ')}\n        - VCS_REF=${VCS_REF:-$(git rev-parse --short HEAD)}\n    container_name: react-app\n    environment:\n      - NODE_ENV=production\n      - REACT_APP_API_URL=https://api.company.com\n      - REACT_APP_SENTRY_DSN=${SENTRY_DSN}\n    networks:\n      - frontend\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    depends_on:\n      api-server:\n        condition: service_healthy\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.webapp.rule=Host(`app.company.com`)\"\n      - \"traefik.http.services.webapp.loadbalancer.server.port=3000\"\n\n  # Backend API Server\n  api-server:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile.prod\n      args:\n        - APP_ENV=production\n        - BUILD_DATE=${BUILD_DATE:-$(date -u +'%Y-%m-%dT%H:%M:%SZ')}\n    container_name: api-server\n    environment:\n      - NODE_ENV=production\n      - DATABASE_URL=postgresql://app_user:${DB_PASSWORD}@postgres:5432/app_db\n      - REDIS_URL=redis://redis:6379\n      - JWT_SECRET=${JWT_SECRET}\n      - SENTRY_DSN=${SENTRY_DSN}\n      - LOG_LEVEL=info\n    networks:\n      - backend\n      - database\n    depends_on:\n      postgres:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 30s\n    labels:\n      - \"traefik.enable=true\" \n      - \"traefik.http.routers.api.rule=Host(`api.company.com`)\"\n      - \"traefik.http.services.api.loadbalancer.server.port=8000\"\n\n  # PostgreSQL Database\n  postgres:\n    image: postgres:15-alpine\n    container_name: postgres-db\n    environment:\n      - POSTGRES_DB=app_db\n      - POSTGRES_USER=app_user\n      - POSTGRES_PASSWORD=${DB_PASSWORD}\n      - POSTGRES_INITDB_ARGS=--auth-host=scram-sha-256\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql:ro\n      - ./database/postgresql.conf:/etc/postgresql/postgresql.conf:ro\n    networks:\n      - database\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U app_user -d app_db\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    command: >\n      postgres \n      -c config_file=/etc/postgresql/postgresql.conf\n      -c shared_preload_libraries=pg_stat_statements\n      -c logging_collector=on\n      -c log_destination=csvlog\n    \n  # Redis Cache\n  redis:\n    image: redis:7-alpine\n    container_name: redis-cache\n    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 256mb --maxmemory-policy allkeys-lru\n    volumes:\n      - redis_data:/data\n      - ./redis/redis.conf:/etc/redis/redis.conf:ro\n    networks:\n      - database\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"--raw\", \"incr\", \"ping\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  # Message Queue\n  rabbitmq:\n    image: rabbitmq:3.12-management-alpine\n    container_name: rabbitmq-queue\n    environment:\n      - RABBITMQ_DEFAULT_USER=admin\n      - RABBITMQ_DEFAULT_PASS=${RABBITMQ_PASSWORD}\n      - RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit log_levels [{connection,error},{default,info}]\n    volumes:\n      - ./rabbitmq/data:/var/lib/rabbitmq\n      - ./rabbitmq/logs:/var/log/rabbitmq\n    networks:\n      - backend\n    ports:\n      - \"15672:15672\"  # Management UI\n    restart: unless-stopped\n    healthcheck:\n      test: rabbitmq-diagnostics -q ping\n      interval: 30s\n      timeout: 30s\n      retries: 3\n\n  # Elasticsearch for Logging\n  elasticsearch:\n    image: elasticsearch:8.8.1\n    container_name: elasticsearch\n    environment:\n      - discovery.type=single-node\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n      - xpack.security.enabled=false\n    volumes:\n      - elasticsearch_data:/usr/share/elasticsearch/data\n    networks:\n      - backend\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:9200/_cluster/health || exit 1\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  # Monitoring with Prometheus\n  prometheus:\n    image: prom/prometheus:latest\n    container_name: prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--web.console.libraries=/etc/prometheus/console_libraries'\n      - '--web.console.templates=/etc/prometheus/consoles'\n      - '--storage.tsdb.retention.time=200h'\n      - '--web.enable-lifecycle'\n    volumes:\n      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro\n      - prometheus_data:/prometheus\n    networks:\n      - backend\n    ports:\n      - \"9090:9090\"\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--no-verbose\", \"--tries=1\", \"--spider\", \"http://localhost:9090/\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  # Grafana Dashboards\n  grafana:\n    image: grafana/grafana:latest\n    container_name: grafana\n    environment:\n      - GF_SECURITY_ADMIN_USER=admin\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}\n      - GF_USERS_ALLOW_SIGN_UP=false\n    volumes:\n      - grafana_data:/var/lib/grafana\n      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro\n      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro\n    networks:\n      - backend\n    ports:\n      - \"3001:3000\"\n    restart: unless-stopped\n    depends_on:\n      - prometheus\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:3000/api/health || exit 1\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n# Development override file: docker-compose.override.yml\n# Use: docker-compose -f docker-compose.yml -f docker-compose.override.yml up\"\"\"\n        \n        elif complexity == 'medium':\n            return \"\"\"# Full-Stack Docker Compose\nversion: '3.8'\n\nnetworks:\n  app-network:\n    driver: bridge\n\nvolumes:\n  postgres_data:\n  redis_data:\n\nservices:\n  # Frontend\n  web-app:\n    build: ./frontend\n    container_name: react-app\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NODE_ENV=production\n      - REACT_APP_API_URL=http://localhost:8000\n    networks:\n      - app-network\n    depends_on:\n      - api-server\n\n  # Backend API\n  api-server:\n    build: ./backend  \n    container_name: api-server\n    ports:\n      - \"8000:8000\"\n    environment:\n      - DATABASE_URL=postgresql://user:password@postgres:5432/app_db\n      - REDIS_URL=redis://redis:6379\n    networks:\n      - app-network\n    depends_on:\n      - postgres\n      - redis\n\n  # Database\n  postgres:\n    image: postgres:15-alpine\n    container_name: postgres-db\n    environment:\n      - POSTGRES_DB=app_db\n      - POSTGRES_USER=user\n      - POSTGRES_PASSWORD=password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    networks:\n      - app-network\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U user\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  # Cache\n  redis:\n    image: redis:7-alpine\n    container_name: redis-cache\n    volumes:\n      - redis_data:/data\n    networks:\n      - app-network\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\"\"\"\n        \n        else:  # simple\n            return \"\"\"# Simple Docker Compose\nversion: '3.8'\n\nservices:\n  web:\n    build: .\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NODE_ENV=production\n    depends_on:\n      - db\n\n  db:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_DB=app_db\n      - POSTGRES_USER=user\n      - POSTGRES_PASSWORD=password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\nvolumes:\n  postgres_data:\"\"\"\n    \n    def _generate_k8s_deployment(self, request, platform: str, complexity: str) -> CodeGenerationResult:\n        \"\"\"Generate Kubernetes deployment manifests\"\"\"\n        message = request.message.lower()\n        \n        if 'web' in message or 'frontend' in message:\n            manifests = self._generate_web_k8s_deployment(complexity)\n        elif 'api' in message or 'backend' in message:\n            manifests = self._generate_api_k8s_deployment(complexity) \n        elif 'database' in message:\n            manifests = self._generate_database_k8s_deployment(complexity)\n        else:\n            manifests = self._generate_generic_k8s_deployment(complexity)\n        \n        return CodeGenerationResult(\n            success=True,\n            code=manifests,\n            language=\"yaml\",\n            framework=\"kubernetes\",\n            code_type=CodeType.CONFIGURATION\n        )\n    \n    def _generate_web_k8s_deployment(self, complexity: str) -> str:\n        \"\"\"Generate Kubernetes deployment for web application\"\"\"\n        if complexity == 'high':\n            return \"\"\"# Production Kubernetes Deployment for Web Application\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\n  namespace: production\n  labels:\n    app: web-app\n    tier: frontend\n    version: v1.0.0\n  annotations:\n    deployment.kubernetes.io/revision: \"1\"\n    kubernetes.io/change-cause: \"Initial deployment\"\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n      maxSurge: 1\n  selector:\n    matchLabels:\n      app: web-app\n      tier: frontend\n  template:\n    metadata:\n      labels:\n        app: web-app\n        tier: frontend\n        version: v1.0.0\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"3000\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      serviceAccountName: web-app-sa\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 1001\n        fsGroup: 2000\n      containers:\n      - name: web-app\n        image: company/web-app:1.0.0\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 3000\n          name: http\n          protocol: TCP\n        env:\n        - name: NODE_ENV\n          value: \"production\"\n        - name: REACT_APP_API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: web-app-config\n              key: api-url\n        - name: SENTRY_DSN\n          valueFrom:\n            secretKeyRef:\n              name: web-app-secrets\n              key: sentry-dsn\n        resources:\n          requests:\n            memory: \"128Mi\"\n            cpu: \"100m\"\n          limits:\n            memory: \"512Mi\"  \n            cpu: \"500m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: http\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n          successThreshold: 1\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: http\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 3\n          successThreshold: 1\n          failureThreshold: 3\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          capabilities:\n            drop:\n            - ALL\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: cache\n          mountPath: /app/.cache\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: cache\n        emptyDir: {}\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - web-app\n              topologyKey: kubernetes.io/hostname\n      tolerations:\n      - key: \"node.kubernetes.io/not-ready\"\n        operator: \"Exists\"\n        effect: \"NoExecute\"\n        tolerationSeconds: 300\n      - key: \"node.kubernetes.io/unreachable\"\n        operator: \"Exists\"  \n        effect: \"NoExecute\"\n        tolerationSeconds: 300\n\n---\n# Service for Web Application\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-app-service\n  namespace: production\n  labels:\n    app: web-app\n    tier: frontend\nspec:\n  type: ClusterIP\n  ports:\n  - port: 80\n    targetPort: http\n    protocol: TCP\n    name: http\n  selector:\n    app: web-app\n    tier: frontend\n\n---\n# ConfigMap for Web Application\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: web-app-config\n  namespace: production\ndata:\n  api-url: \"https://api.company.com\"\n  log-level: \"info\"\n  feature-flags: |\n    {\n      \"newUI\": true,\n      \"analytics\": true,\n      \"betaFeatures\": false\n    }\n\n---\n# Secret for Web Application  \napiVersion: v1\nkind: Secret\nmetadata:\n  name: web-app-secrets\n  namespace: production\ntype: Opaque\nstringData:\n  sentry-dsn: \"https://your-sentry-dsn@sentry.io/project\"\n  google-analytics: \"GA_TRACKING_ID\"\n\n---\n# Horizontal Pod Autoscaler\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: web-app-hpa\n  namespace: production\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: web-app\n  minReplicas: 3\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\n      - type: Percent\n        value: 10\n        periodSeconds: 60\n    scaleUp:\n      stabilizationWindowSeconds: 0\n      policies:\n      - type: Percent\n        value: 100\n        periodSeconds: 15\n      - type: Pods\n        value: 4\n        periodSeconds: 15\n      selectPolicy: Max\n\n---\n# Network Policy\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: web-app-netpol\n  namespace: production\nspec:\n  podSelector:\n    matchLabels:\n      app: web-app\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - namespaceSelector:\n        matchLabels:\n          name: ingress-nginx\n    ports:\n    - protocol: TCP\n      port: 3000\n  egress:\n  - to:\n    - namespaceSelector:\n        matchLabels:\n          name: production\n    ports:\n    - protocol: TCP\n      port: 8000  # API server\n  - to: []  # Allow DNS\n    ports:\n    - protocol: UDP\n      port: 53\"\"\"\n        \n        elif complexity == 'medium':\n            return \"\"\"# Kubernetes Deployment for Web Application\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\n  labels:\n    app: web-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: web-app\n  template:\n    metadata:\n      labels:\n        app: web-app\n    spec:\n      containers:\n      - name: web-app\n        image: company/web-app:latest\n        ports:\n        - containerPort: 3000\n        env:\n        - name: NODE_ENV\n          value: \"production\"\n        - name: API_URL\n          valueFrom:\n            configMapKeyRef:\n              name: app-config\n              key: api-url\n        resources:\n          requests:\n            memory: \"64Mi\"\n            cpu: \"50m\"\n          limits:\n            memory: \"256Mi\"\n            cpu: \"200m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: web-app-service\nspec:\n  selector:\n    app: web-app\n  ports:\n  - port: 80\n    targetPort: 3000\n  type: ClusterIP\n\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\ndata:\n  api-url: \"http://api-service:8000\"\n  log-level: \"info\" \"\"\"\n        \n        else:  # simple\n            return \"\"\"# Simple Kubernetes Deployment\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web-app\n  template:\n    metadata:\n      labels:\n        app: web-app\n    spec:\n      containers:\n      - name: web-app\n        image: nginx:alpine\n        ports:\n        - containerPort: 80\n\n---\napiVersion: v1  \nkind: Service\nmetadata:\n  name: web-app-service\nspec:\n  selector:\n    app: web-app\n  ports:\n  - port: 80\n    targetPort: 80\n  type: LoadBalancer\"\"\"\n    \n    def _generate_github_actions(self, request, platform: str, complexity: str) -> CodeGenerationResult:\n        \"\"\"Generate GitHub Actions CI/CD workflow\"\"\"\n        message = request.message.lower()\n        \n        if 'node' in message or 'javascript' in message:\n            workflow = self._generate_nodejs_github_actions(complexity)\n        elif 'python' in message:\n            workflow = self._generate_python_github_actions(complexity)\n        elif 'docker' in message:\n            workflow = self._generate_docker_github_actions(complexity)\n        else:\n            workflow = self._generate_generic_github_actions(complexity)\n        \n        return CodeGenerationResult(\n            success=True,\n            code=workflow,\n            language=\"yaml\",\n            framework=\"github-actions\",\n            code_type=CodeType.PIPELINE\n        )\n    \n    def _generate_nodejs_github_actions(self, complexity: str) -> str:\n        \"\"\"Generate Node.js GitHub Actions workflow\"\"\"\n        if complexity == 'high':\n            return \"\"\"# Production-Ready Node.js CI/CD Pipeline\nname: Node.js Production Pipeline\n\non:\n  push:\n    branches: [ main, develop ]\n    paths-ignore:\n      - 'docs/**'\n      - '*.md'\n  pull_request:\n    branches: [ main ]\n    types: [opened, synchronize, reopened]\n  release:\n    types: [published]\n  schedule:\n    - cron: '0 2 * * 1'  # Weekly dependency check\n\nenv:\n  NODE_VERSION: '18.x'\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  # Security and Dependency Scanning\n  security-scan:\n    name: Security Scan\n    runs-on: ubuntu-latest\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n      with:\n        fetch-depth: 0\n\n    - name: Run Trivy vulnerability scanner\n      uses: aquasecurity/trivy-action@master\n      with:\n        scan-type: 'fs'\n        scan-ref: '.'\n        format: 'sarif'\n        output: 'trivy-results.sarif'\n\n    - name: Upload Trivy scan results to GitHub Security tab\n      uses: github/codeql-action/upload-sarif@v2\n      with:\n        sarif_file: 'trivy-results.sarif'\n\n    - name: Audit npm dependencies\n      run: npm audit --audit-level moderate\n\n    - name: Check for known security vulnerabilities\n      uses: securecodewarrior/github-action-add-sarif@v1\n      with:\n        sarif-file: 'trivy-results.sarif'\n\n  # Code Quality and Testing\n  test:\n    name: Test Suite\n    runs-on: ubuntu-latest\n    needs: security-scan\n    strategy:\n      matrix:\n        node-version: [16.x, 18.x, 20.x]\n        os: [ubuntu-latest, windows-latest, macos-latest]\n    services:\n      postgres:\n        image: postgres:15\n        env:\n          POSTGRES_PASSWORD: postgres\n          POSTGRES_DB: testdb\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 5432:5432\n      redis:\n        image: redis:7\n        options: >-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 6379:6379\n\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Setup Node.js ${{ matrix.node-version }}\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ matrix.node-version }}\n        cache: 'npm'\n        cache-dependency-path: package-lock.json\n\n    - name: Install dependencies\n      run: npm ci --frozen-lockfile\n\n    - name: Run ESLint\n      run: npm run lint:check\n\n    - name: Run Prettier format check\n      run: npm run format:check\n\n    - name: Run TypeScript type check\n      run: npm run type-check\n\n    - name: Run unit tests\n      run: npm run test:unit -- --coverage --watchAll=false\n      env:\n        NODE_ENV: test\n        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/testdb\n        REDIS_URL: redis://localhost:6379\n\n    - name: Run integration tests\n      run: npm run test:integration\n      env:\n        NODE_ENV: test\n        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/testdb\n        REDIS_URL: redis://localhost:6379\n\n    - name: Run E2E tests\n      run: npm run test:e2e\n      env:\n        NODE_ENV: test\n\n    - name: Upload coverage reports to Codecov\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage/lcov.info\n        flags: unittests\n        name: codecov-umbrella\n        fail_ci_if_error: false\n\n    - name: SonarCloud Scan\n      uses: SonarSource/sonarcloud-github-action@master\n      env:\n        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}\n\n  # Performance and Load Testing\n  performance:\n    name: Performance Tests\n    runs-on: ubuntu-latest\n    needs: test\n    if: github.event_name == 'push' && github.ref == 'refs/heads/main'\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ env.NODE_VERSION }}\n        cache: 'npm'\n\n    - name: Install dependencies\n      run: npm ci --frozen-lockfile\n\n    - name: Build application\n      run: npm run build\n\n    - name: Start application\n      run: |\n        npm start &\n        sleep 30\n      env:\n        NODE_ENV: production\n\n    - name: Run Lighthouse CI\n      uses: treosh/lighthouse-ci-action@v10\n      with:\n        configPath: './lighthouse-ci.json'\n        uploadArtifacts: true\n        temporaryPublicStorage: true\n\n    - name: Run K6 performance tests\n      uses: grafana/k6-action@v0.3.0\n      with:\n        filename: performance/load-test.js\n      env:\n        BASE_URL: http://localhost:3000\n\n  # Build and Push Docker Image\n  build:\n    name: Build and Push\n    runs-on: ubuntu-latest\n    needs: [test, performance]\n    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')\n    outputs:\n      image: ${{ steps.image.outputs.image }}\n      digest: ${{ steps.build.outputs.digest }}\n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n\n    - name: Setup Docker Buildx\n      uses: docker/setup-buildx-action@v3\n\n    - name: Log into registry ${{ env.REGISTRY }}\n      uses: docker/login-action@v3\n      with:\n        registry: ${{ env.REGISTRY }}\n        username: ${{ github.actor }}\n        password: ${{ secrets.GITHUB_TOKEN }}\n\n    - name: Extract metadata\n      id: meta\n      uses: docker/metadata-action@v5\n      with:\n        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n        tags: |\n          type=ref,event=branch\n          type=ref,event=pr\n          type=sha,prefix={{branch}}-\n          type=raw,value=latest,enable={{is_default_branch}}\n\n    - name: Build and push Docker image\n      id: build\n      uses: docker/build-push-action@v5\n      with:\n        context: .\n        file: ./Dockerfile.prod\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}\n        labels: ${{ steps.meta.outputs.labels }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        build-args: |\n          BUILD_DATE=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.created'] }}\n          VCS_REF=${{ fromJSON(steps.meta.outputs.json).labels['org.opencontainers.image.revision'] }}\n\n    - name: Output image\n      id: image\n      run: |\n        echo \"image=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ steps.meta.outputs.version }}\" >> $GITHUB_OUTPUT\n\n  # Deploy to Staging\n  deploy-staging:\n    name: Deploy to Staging\n    runs-on: ubuntu-latest\n    needs: build\n    if: github.ref == 'refs/heads/develop'\n    environment:\n      name: staging\n      url: https://staging.company.com\n    steps:\n    - name: Deploy to staging cluster\n      uses: azure/k8s-deploy@v1\n      with:\n        manifests: |\n          k8s/staging/deployment.yaml\n          k8s/staging/service.yaml\n        images: ${{ needs.build.outputs.image }}\n        kubectl-version: 'v1.28.0'\n\n    - name: Run smoke tests\n      run: |\n        curl -f https://staging.company.com/health || exit 1\n        curl -f https://staging.company.com/api/health || exit 1\n\n  # Deploy to Production\n  deploy-production:\n    name: Deploy to Production  \n    runs-on: ubuntu-latest\n    needs: build\n    if: github.ref == 'refs/heads/main'\n    environment:\n      name: production\n      url: https://company.com\n    steps:\n    - name: Deploy to production cluster\n      uses: azure/k8s-deploy@v1\n      with:\n        manifests: |\n          k8s/production/deployment.yaml\n          k8s/production/service.yaml\n        images: ${{ needs.build.outputs.image }}\n        kubectl-version: 'v1.28.0'\n\n    - name: Run smoke tests\n      run: |\n        curl -f https://company.com/health || exit 1\n        curl -f https://company.com/api/health || exit 1\n\n    - name: Notify Slack\n      uses: 8398a7/action-slack@v3\n      with:\n        status: ${{ job.status }}\n        channel: '#deployments'\n        webhook_url: ${{ secrets.SLACK_WEBHOOK }}\n      if: always()\"\"\"\n        \n        elif complexity == 'medium':\n            return \"\"\"# Node.js CI/CD Pipeline\nname: Node.js CI\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node-version: [16.x, 18.x]\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Use Node.js ${{ matrix.node-version }}\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ matrix.node-version }}\n        cache: 'npm'\n\n    - name: Install dependencies\n      run: npm ci\n\n    - name: Run tests\n      run: npm test\n\n    - name: Build\n      run: npm run build\n\n  deploy:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    \n    steps:\n    - uses: actions/checkout@v4\n    \n    - name: Build and push Docker image\n      run: |\n        docker build -t ${{ github.repository }}:${{ github.sha }} .\n        docker push ${{ github.repository }}:${{ github.sha }}\"\"\"\n        \n        else:  # simple\n            return \"\"\"# Simple Node.js CI\nname: CI\n\non: [push, pull_request]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - uses: actions/checkout@v4\n    - uses: actions/setup-node@v4\n      with:\n        node-version: '18'\n        cache: 'npm'\n    \n    - run: npm ci\n    - run: npm test\n    - run: npm run build\"\"\"\n    \n    def _generate_terraform(self, request, platform: str, complexity: str) -> CodeGenerationResult:\n        \"\"\"Generate Terraform infrastructure code\"\"\"\n        message = request.message.lower()\n        \n        if 'aws' in message:\n            terraform = self._generate_aws_terraform(complexity)\n        elif 'azure' in message:\n            terraform = self._generate_azure_terraform(complexity)\n        elif 'gcp' in message:\n            terraform = self._generate_gcp_terraform(complexity)\n        else:\n            terraform = self._generate_generic_terraform(complexity)\n        \n        return CodeGenerationResult(\n            success=True,\n            code=terraform,\n            language=\"hcl\",\n            framework=\"terraform\",\n            code_type=CodeType.INFRASTRUCTURE\n        )\n    \n    def _generate_aws_terraform(self, complexity: str) -> str:\n        \"\"\"Generate AWS Terraform configuration\"\"\"\n        if complexity == 'high':\n            return \"\"\"# Production AWS Infrastructure with Terraform\n# Provider configuration\nterraform {\n  required_version = \">= 1.5\"\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"~> 3.4\"\n    }\n  }\n  \n  backend \"s3\" {\n    bucket         = \"company-terraform-state\"\n    key            = \"production/terraform.tfstate\"\n    region         = \"us-east-1\"\n    encrypt        = true\n    dynamodb_table = \"terraform-locks\"\n    \n    assume_role {\n      role_arn = \"arn:aws:iam::123456789012:role/TerraformRole\"\n    }\n  }\n}\n\n# Provider configuration\nprovider \"aws\" {\n  region = var.aws_region\n  \n  default_tags {\n    tags = local.common_tags\n  }\n}\n\n# Local values\nlocals {\n  environment = var.environment\n  project     = var.project_name\n  \n  common_tags = {\n    Environment   = local.environment\n    Project       = local.project\n    ManagedBy     = \"terraform\"\n    Owner         = var.owner\n    CostCenter    = var.cost_center\n    Compliance    = var.compliance_level\n    BackupPolicy  = \"daily\"\n    MonitoringEnabled = \"true\"\n  }\n  \n  vpc_cidr = var.vpc_cidr\n  availability_zones = data.aws_availability_zones.available.names\n  \n  # Subnets calculation\n  public_subnet_cidrs  = [for i, az in local.availability_zones : cidrsubnet(local.vpc_cidr, 8, i)]\n  private_subnet_cidrs = [for i, az in local.availability_zones : cidrsubnet(local.vpc_cidr, 8, i + 10)]\n  database_subnet_cidrs = [for i, az in local.availability_zones : cidrsubnet(local.vpc_cidr, 8, i + 20)]\n}\n\n# Data sources\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\ndata \"aws_caller_identity\" \"current\" {}\n\ndata \"aws_ami\" \"amazon_linux\" {\n  most_recent = true\n  owners      = [\"amazon\"]\n  \n  filter {\n    name   = \"name\"\n    values = [\"amzn2-ami-hvm-*-x86_64-gp2\"]\n  }\n  \n  filter {\n    name   = \"virtualization-type\"\n    values = [\"hvm\"]\n  }\n}\n\n# VPC Configuration\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = local.vpc_cidr\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-vpc\"\n  })\n}\n\n# Internet Gateway\nresource \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-igw\"\n  })\n}\n\n# Public Subnets\nresource \"aws_subnet\" \"public\" {\n  count = length(local.availability_zones)\n  \n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = local.public_subnet_cidrs[count.index]\n  availability_zone       = local.availability_zones[count.index]\n  map_public_ip_on_launch = true\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-public-\\${count.index + 1}\"\n    Type = \"public\"\n    Tier = \"web\"\n  })\n}\n\n# Private Subnets\nresource \"aws_subnet\" \"private\" {\n  count = length(local.availability_zones)\n  \n  vpc_id            = aws_vpc.main.id\n  cidr_block        = local.private_subnet_cidrs[count.index]\n  availability_zone = local.availability_zones[count.index]\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-private-\\${count.index + 1}\"\n    Type = \"private\"\n    Tier = \"application\"\n  })\n}\n\n# Database Subnets\nresource \"aws_subnet\" \"database\" {\n  count = length(local.availability_zones)\n  \n  vpc_id            = aws_vpc.main.id\n  cidr_block        = local.database_subnet_cidrs[count.index]\n  availability_zone = local.availability_zones[count.index]\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-database-\\${count.index + 1}\"\n    Type = \"database\"\n    Tier = \"data\"\n  })\n}\n\n# Elastic IPs for NAT Gateways\nresource \"aws_eip\" \"nat\" {\n  count = length(local.availability_zones)\n  \n  domain = \"vpc\"\n  depends_on = [aws_internet_gateway.main]\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-nat-eip-\\${count.index + 1}\"\n  })\n}\n\n# NAT Gateways\nresource \"aws_nat_gateway\" \"main\" {\n  count = length(local.availability_zones)\n  \n  allocation_id = aws_eip.nat[count.index].id\n  subnet_id     = aws_subnet.public[count.index].id\n  depends_on    = [aws_internet_gateway.main]\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-nat-\\${count.index + 1}\"\n  })\n}\n\n# Route Tables\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.main.id\n  \n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.main.id\n  }\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-public-rt\"\n    Type = \"public\"\n  })\n}\n\nresource \"aws_route_table\" \"private\" {\n  count = length(local.availability_zones)\n  \n  vpc_id = aws_vpc.main.id\n  \n  route {\n    cidr_block     = \"0.0.0.0/0\"\n    nat_gateway_id = aws_nat_gateway.main[count.index].id\n  }\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-private-rt-\\${count.index + 1}\"\n    Type = \"private\"\n  })\n}\n\nresource \"aws_route_table\" \"database\" {\n  vpc_id = aws_vpc.main.id\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-database-rt\"\n    Type = \"database\"\n  })\n}\n\n# Route Table Associations\nresource \"aws_route_table_association\" \"public\" {\n  count = length(aws_subnet.public)\n  \n  subnet_id      = aws_subnet.public[count.index].id\n  route_table_id = aws_route_table.public.id\n}\n\nresource \"aws_route_table_association\" \"private\" {\n  count = length(aws_subnet.private)\n  \n  subnet_id      = aws_subnet.private[count.index].id\n  route_table_id = aws_route_table.private[count.index].id\n}\n\nresource \"aws_route_table_association\" \"database\" {\n  count = length(aws_subnet.database)\n  \n  subnet_id      = aws_subnet.database[count.index].id\n  route_table_id = aws_route_table.database.id\n}\n\n# Security Groups\nresource \"aws_security_group\" \"web\" {\n  name        = \"\\${local.project}-\\${local.environment}-web-sg\"\n  description = \"Security group for web servers\"\n  vpc_id      = aws_vpc.main.id\n  \n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"HTTP\"\n  }\n  \n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"HTTPS\"\n  }\n  \n  ingress {\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [var.admin_cidr]\n    description = \"SSH from admin network\"\n  }\n  \n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"All outbound traffic\"\n  }\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-web-sg\"\n    Type = \"security-group\"\n    Tier = \"web\"\n  })\n}\n\nresource \"aws_security_group\" \"app\" {\n  name        = \"\\${local.project}-\\${local.environment}-app-sg\"\n  description = \"Security group for application servers\"\n  vpc_id      = aws_vpc.main.id\n  \n  ingress {\n    from_port       = 8000\n    to_port         = 8000\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.web.id]\n    description     = \"Application port from web tier\"\n  }\n  \n  ingress {\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [var.admin_cidr]\n    description = \"SSH from admin network\"\n  }\n  \n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"All outbound traffic\"\n  }\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-app-sg\"\n    Type = \"security-group\"\n    Tier = \"application\"\n  })\n}\n\nresource \"aws_security_group\" \"database\" {\n  name        = \"\\${local.project}-\\${local.environment}-db-sg\"\n  description = \"Security group for database\"\n  vpc_id      = aws_vpc.main.id\n  \n  ingress {\n    from_port       = 5432\n    to_port         = 5432\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.app.id]\n    description     = \"PostgreSQL from application tier\"\n  }\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-db-sg\"\n    Type = \"security-group\"\n    Tier = \"database\"\n  })\n}\n\n# Application Load Balancer\nresource \"aws_lb\" \"main\" {\n  name               = \"\\${local.project}-\\${local.environment}-alb\"\n  internal           = false\n  load_balancer_type = \"application\"\n  security_groups    = [aws_security_group.web.id]\n  subnets            = aws_subnet.public[*].id\n  \n  enable_deletion_protection = var.enable_deletion_protection\n  \n  access_logs {\n    bucket  = aws_s3_bucket.logs.bucket\n    prefix  = \"alb\"\n    enabled = true\n  }\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-alb\"\n    Type = \"load-balancer\"\n  })\n}\n\n# RDS Subnet Group\nresource \"aws_db_subnet_group\" \"main\" {\n  name       = \"\\${local.project}-\\${local.environment}-db-subnet-group\"\n  subnet_ids = aws_subnet.database[*].id\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-db-subnet-group\"\n  })\n}\n\n# RDS Database\nresource \"random_password\" \"db_password\" {\n  length  = 32\n  special = true\n}\n\nresource \"aws_db_instance\" \"main\" {\n  identifier     = \"\\${local.project}-\\${local.environment}-db\"\n  engine         = \"postgres\"\n  engine_version = var.postgres_version\n  instance_class = var.db_instance_class\n  \n  allocated_storage     = var.db_allocated_storage\n  max_allocated_storage = var.db_max_allocated_storage\n  storage_type          = \"gp3\"\n  storage_encrypted     = true\n  kms_key_id           = aws_kms_key.main.arn\n  \n  db_name  = var.database_name\n  username = var.database_username\n  password = random_password.db_password.result\n  port     = 5432\n  \n  vpc_security_group_ids = [aws_security_group.database.id]\n  db_subnet_group_name   = aws_db_subnet_group.main.name\n  \n  backup_retention_period = var.backup_retention_period\n  backup_window          = var.backup_window\n  maintenance_window     = var.maintenance_window\n  \n  skip_final_snapshot       = false\n  final_snapshot_identifier = \"\\${local.project}-\\${local.environment}-final-snapshot-\\${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\"\n  delete_automated_backups  = false\n  \n  performance_insights_enabled = true\n  monitoring_interval         = 60\n  monitoring_role_arn        = aws_iam_role.rds_monitoring.arn\n  \n  enabled_cloudwatch_logs_exports = [\"postgresql\"]\n  \n  tags = merge(local.common_tags, {\n    Name = \"\\${local.project}-\\${local.environment}-db\"\n    Type = \"database\"\n  })\n}\n\n# Variables\nvariable \"aws_region\" {\n  description = \"AWS region\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name\"\n  type        = string\n}\n\nvariable \"project_name\" {\n  description = \"Project name\"\n  type        = string\n}\n\nvariable \"vpc_cidr\" {\n  description = \"CIDR block for VPC\"\n  type        = string\n  default     = \"10.0.0.0/16\"\n}\n\nvariable \"admin_cidr\" {\n  description = \"CIDR block for admin access\"\n  type        = string\n}\n\nvariable \"owner\" {\n  description = \"Owner of the resources\"\n  type        = string\n}\n\nvariable \"cost_center\" {\n  description = \"Cost center for billing\"\n  type        = string\n}\n\nvariable \"compliance_level\" {\n  description = \"Compliance level required\"\n  type        = string\n  default     = \"high\"\n}\n\n# Outputs\noutput \"vpc_id\" {\n  description = \"ID of the VPC\"\n  value       = aws_vpc.main.id\n}\n\noutput \"public_subnet_ids\" {\n  description = \"IDs of the public subnets\"\n  value       = aws_subnet.public[*].id\n}\n\noutput \"private_subnet_ids\" {\n  description = \"IDs of the private subnets\"\n  value       = aws_subnet.private[*].id\n}\n\noutput \"database_subnet_ids\" {\n  description = \"IDs of the database subnets\"\n  value       = aws_subnet.database[*].id\n}\n\noutput \"load_balancer_dns_name\" {\n  description = \"DNS name of the load balancer\"\n  value       = aws_lb.main.dns_name\n}\n\noutput \"database_endpoint\" {\n  description = \"RDS instance endpoint\"\n  value       = aws_db_instance.main.endpoint\n  sensitive   = true\n}\n\noutput \"database_port\" {\n  description = \"RDS instance port\"\n  value       = aws_db_instance.main.port\n}\"\"\"\n        \n        elif complexity == 'medium':\n            return \"\"\"# AWS Infrastructure with Terraform\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n\n# VPC\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n  \n  tags = {\n    Name = \"\\${var.project_name}-vpc\"\n    Environment = var.environment\n  }\n}\n\n# Internet Gateway\nresource \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n  \n  tags = {\n    Name = \"\\${var.project_name}-igw\"\n  }\n}\n\n# Public Subnet\nresource \"aws_subnet\" \"public\" {\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = \"10.0.1.0/24\"\n  availability_zone       = data.aws_availability_zones.available.names[0]\n  map_public_ip_on_launch = true\n  \n  tags = {\n    Name = \"\\${var.project_name}-public-subnet\"\n  }\n}\n\n# Private Subnet\nresource \"aws_subnet\" \"private\" {\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = \"10.0.2.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[1]\n  \n  tags = {\n    Name = \"\\${var.project_name}-private-subnet\"\n  }\n}\n\n# Route Table\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.main.id\n  \n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.main.id\n  }\n  \n  tags = {\n    Name = \"\\${var.project_name}-public-rt\"\n  }\n}\n\n# Security Group\nresource \"aws_security_group\" \"web\" {\n  name        = \"\\${var.project_name}-web-sg\"\n  description = \"Security group for web servers\"\n  vpc_id      = aws_vpc.main.id\n  \n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  \n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  \n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n  \n  tags = {\n    Name = \"\\${var.project_name}-web-sg\"\n  }\n}\n\n# Data source\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\n# Variables\nvariable \"aws_region\" {\n  description = \"AWS region\"\n  type        = string\n  default     = \"us-east-1\"\n}\n\nvariable \"project_name\" {\n  description = \"Name of the project\"\n  type        = string\n}\n\nvariable \"environment\" {\n  description = \"Environment (dev, staging, prod)\"\n  type        = string\n}\n\n# Outputs\noutput \"vpc_id\" {\n  description = \"ID of the VPC\"\n  value       = aws_vpc.main.id\n}\n\noutput \"public_subnet_id\" {\n  description = \"ID of the public subnet\"\n  value       = aws_subnet.public.id\n}\"\"\"\n        \n        else:  # simple\n            return \"\"\"# Simple AWS Infrastructure\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-0abcdef1234567890\"\n  instance_type = \"t3.micro\"\n  \n  tags = {\n    Name = \"HelloWorld\"\n  }\n}\n\nresource \"aws_security_group\" \"web\" {\n  name        = \"terraform_example\"\n  description = \"Terraform example security group\"\n  \n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\"\"\"\n    \n    def _generate_default_devops(self, request, platform: str, complexity: str) -> CodeGenerationResult:\n        \"\"\"Generate default DevOps configuration\"\"\"\n        message = request.message.lower()\n        \n        if 'monitor' in message or 'observability' in message:\n            code = self._generate_monitoring_config(platform, complexity)\n        elif 'backup' in message or 'disaster' in message:\n            code = self._generate_backup_config(platform, complexity)\n        else:\n            code = self._generate_basic_devops_config(platform, complexity)\n        \n        return CodeGenerationResult(\n            success=True,\n            code=code,\n            language=\"yaml\",\n            framework=platform,\n            code_type=CodeType.CONFIGURATION\n        )\n    \n    def _extract_dependencies(self, code: str, platform: str) -> List[str]:\n        \"\"\"Extract DevOps dependencies from generated code\"\"\"\n        dependencies = [f\"{platform}-cli\"]\n        \n        # Add specific dependencies based on code content\n        if 'kubectl' in code.lower() or 'kubernetes' in code.lower():\n            dependencies.extend([\"kubectl\", \"kubernetes-tools\"])\n        if 'docker' in code.lower():\n            dependencies.append(\"docker\")\n        if 'terraform' in code.lower():\n            dependencies.append(\"terraform\")\n        if 'ansible' in code.lower():\n            dependencies.append(\"ansible\")\n        if 'helm' in code.lower():\n            dependencies.append(\"helm\")\n        if 'prometheus' in code.lower():\n            dependencies.append(\"prometheus\")\n        if 'grafana' in code.lower():\n            dependencies.append(\"grafana\")\n            \n        return list(set(dependencies))\n    \n    # Additional helper methods for other generators...\n    def _generate_java_dockerfile(self, complexity: str) -> str:\n        \"\"\"Generate Java Spring Boot Dockerfile\"\"\"\n        return \"\"\"# Spring Boot Production Dockerfile\nFROM eclipse-temurin:17-jre-alpine AS runtime\n\nRUN apk add --no-cache curl tini\nRUN addgroup -g 1001 -S spring && adduser -S spring -u 1001 -G spring\n\nWORKDIR /app\nCOPY target/*.jar app.jar\nRUN chown spring:spring app.jar\n\nUSER spring\n\nHEALTHCHECK --interval=30s --timeout=10s \\\n    CMD curl -f http://localhost:8080/actuator/health || exit 1\n\nEXPOSE 8080\nENTRYPOINT [\"tini\", \"--\"]\nCMD [\"java\", \"-jar\", \"app.jar\"]\"\"\"\n    \n    def _generate_go_dockerfile(self, complexity: str) -> str:\n        \"\"\"Generate Go application Dockerfile\"\"\"\n        return \"\"\"# Go Multi-stage Production Dockerfile\nFROM golang:1.21-alpine AS builder\n\nRUN apk add --no-cache ca-certificates git\nWORKDIR /build\n\nCOPY go.mod go.sum ./\nRUN go mod download\n\nCOPY . .\nRUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main .\n\nFROM alpine:latest AS runtime\nRUN apk --no-cache add ca-certificates tzdata\nRUN adduser -D -s /bin/sh appuser\n\nWORKDIR /root/\n\nCOPY --from=builder /build/main .\nRUN chown appuser:appuser main\n\nUSER appuser\n\nEXPOSE 8080\nCMD [\"./main\"]\"\"\"\n    \n    def _generate_nginx_dockerfile(self, complexity: str) -> str:\n        \"\"\"Generate Nginx Dockerfile\"\"\"\n        return \"\"\"# Nginx Production Dockerfile\nFROM nginx:alpine\n\n# Install security updates\nRUN apk update && apk upgrade && rm -rf /var/cache/apk/*\n\n# Copy custom configuration\nCOPY nginx.conf /etc/nginx/nginx.conf\nCOPY default.conf /etc/nginx/conf.d/default.conf\n\n# Copy static files\nCOPY dist/ /usr/share/nginx/html/\n\n# Create non-root user\nRUN adduser -D -s /bin/sh nginx-user\n\n# Set proper permissions\nRUN chown -R nginx-user:nginx-user /usr/share/nginx/html\nRUN chown -R nginx-user:nginx-user /var/cache/nginx\nRUN chown -R nginx-user:nginx-user /etc/nginx\n\n# Switch to non-root user\nUSER nginx-user\n\nEXPOSE 80\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\"\"\"\n    \n    def _generate_generic_dockerfile(self, complexity: str) -> str:\n        \"\"\"Generate generic Dockerfile\"\"\"\n        return \"\"\"# Generic Application Dockerfile\nFROM alpine:latest\n\n# Install basic utilities\nRUN apk add --no-cache ca-certificates curl\n\n# Create non-root user\nRUN adduser -D -s /bin/sh appuser\n\nWORKDIR /app\n\n# Copy application files\nCOPY . .\nRUN chown -R appuser:appuser /app\n\n# Switch to non-root user\nUSER appuser\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=3s \\\n    CMD curl -f http://localhost:8080/health || exit 1\n\nEXPOSE 8080\nCMD [\"./start.sh\"]\"\"\"\n    \n    def _generate_basic_devops(self, request, platform: str, complexity: str) -> CodeGenerationResult:\n        \"\"\"Generate basic DevOps configuration\"\"\"\n        code = self._generate_basic_devops_config(platform, complexity)\n        \n        return CodeGenerationResult(\n            success=True,\n            code=code,\n            language=\"devops\",\n            framework=platform,\n            code_type=CodeType.DEPLOYMENT,\n            complexity=complexity,\n            generator_used=\"basic_devops\"\n        )\n    \n    def _generate_basic_devops_config(self, platform: str, complexity: str) -> str:\n        \"\"\"Generate basic DevOps configuration based on platform\"\"\"\n        if platform in ['docker', 'container']:\n            return self._generate_generic_dockerfile(complexity)\n        elif platform in ['kubernetes', 'k8s']:\n            return self._generate_k8s_deployment_yaml()\n        elif platform == 'terraform':\n            return self._generate_basic_terraform()\n        else:\n            return self._generate_generic_dockerfile(complexity)\n    \n    def _generate_k8s_deployment_yaml(self) -> str:\n        \"\"\"Generate basic Kubernetes deployment YAML\"\"\"\n        return \"\"\"apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-deployment\n  labels:\n    app: myapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myapp:latest\n        ports:\n        - containerPort: 8080\n        env:\n        - name: ENV\n          value: \"production\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: app-service\nspec:\n  selector:\n    app: myapp\n  ports:\n  - port: 80\n    targetPort: 8080\n  type: LoadBalancer\"\"\"\n    \n    def _generate_basic_terraform(self) -> str:\n        \"\"\"Generate basic Terraform configuration\"\"\"\n        return \"\"\"terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n\nvariable \"aws_region\" {\n  description = \"AWS region\"\n  default     = \"us-west-2\"\n}\n\nresource \"aws_instance\" \"web\" {\n  ami           = \"ami-0c55b159cbfafe1d0\"\n  instance_type = \"t3.micro\"\n  \n  tags = {\n    Name = \"WebServer\"\n  }\n}\n\noutput \"instance_ip\" {\n  value = aws_instance.web.public_ip\n}\"\"\"\n}\n\n} // extern \"C\"\n",
  "id": "BLOCK-PY-00067",
  "language": "python",
  "source_file": "/storage/emulated/0/Download/integrate ideas/Generators/devops_generator.py",
  "source_line": 18,
  "validation_status": "validated"
}