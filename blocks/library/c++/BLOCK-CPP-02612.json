{
  "code": "{\n\nABSL_CONST_INIT\nstd::atomic<const void *> VDSOSupport::vdso_base_(\n    debugging_internal::ElfMemImage::kInvalidBase);\n\nABSL_CONST_INIT std::atomic<VDSOSupport::GetCpuFn> VDSOSupport::getcpu_fn_(\n    &InitAndGetCPU);\n\nVDSOSupport::VDSOSupport()\n    // If vdso_base_ is still set to kInvalidBase, we got here\n    // before VDSOSupport::Init has been called. Call it now.\n    : image_(vdso_base_.load(std::memory_order_relaxed) ==\n                     debugging_internal::ElfMemImage::kInvalidBase\n                 ? Init()\n                 : vdso_base_.load(std::memory_order_relaxed)) {}\n\n// NOTE: we can't use GoogleOnceInit() below, because we can be\n// called by tcmalloc, and none of the *once* stuff may be functional yet.\n//\n// In addition, we hope that the VDSOSupportHelper constructor\n// causes this code to run before there are any threads, and before\n// InitGoogle() has executed any chroot or setuid calls.\n//\n// Finally, even if there is a race here, it is harmless, because\n// the operation should be idempotent.\nconst void *VDSOSupport::Init() {\n  const auto kInvalidBase = debugging_internal::ElfMemImage::kInvalidBase;\n#ifdef ABSL_HAVE_GETAUXVAL\n  if (vdso_base_.load(std::memory_order_relaxed) == kInvalidBase) {\n    errno = 0;\n    const void *const sysinfo_ehdr =\n        reinterpret_cast<const void *>(getauxval(AT_SYSINFO_EHDR));\n    if (errno == 0) {\n      vdso_base_.store(sysinfo_ehdr, std::memory_order_relaxed);\n    }\n  }\n#endif  // ABSL_HAVE_GETAUXVAL\n  if (vdso_base_.load(std::memory_order_relaxed) == kInvalidBase) {\n    int fd = open(\"/proc/self/auxv\", O_RDONLY);\n    if (fd == -1) {\n      // Kernel too old to have a VDSO.\n      vdso_base_.store(nullptr, std::memory_order_relaxed);\n      getcpu_fn_.store(&GetCPUViaSyscall, std::memory_order_relaxed);\n      return nullptr;\n    }\n    ElfW(auxv_t) aux;\n    while (read(fd, &aux, sizeof(aux)) == sizeof(aux)) {\n      if (aux.a_type == AT_SYSINFO_EHDR) {\n#if defined(__NetBSD__)\n        vdso_base_.store(reinterpret_cast<void *>(aux.a_v),\n                         std::memory_order_relaxed);\n#else\n        vdso_base_.store(reinterpret_cast<void *>(aux.a_un.a_val),\n                         std::memory_order_relaxed);\n#endif\n        break;\n      }\n    }\n    close(fd);\n    if (vdso_base_.load(std::memory_order_relaxed) == kInvalidBase) {\n      // Didn't find AT_SYSINFO_EHDR in auxv[].\n      vdso_base_.store(nullptr, std::memory_order_relaxed);\n    }\n  }\n  GetCpuFn fn = &GetCPUViaSyscall;  // default if VDSO not present.\n  if (vdso_base_.load(std::memory_order_relaxed)) {\n    VDSOSupport vdso;\n    SymbolInfo info;\n    if (vdso.LookupSymbol(\"__vdso_getcpu\", \"LINUX_2.6\", STT_FUNC, &info)) {\n      fn = reinterpret_cast<GetCpuFn>(const_cast<void *>(info.address));\n    }\n  }\n  // Subtle: this code runs outside of any locks; prevent compiler\n  // from assigning to getcpu_fn_ more than once.\n  getcpu_fn_.store(fn, std::memory_order_relaxed);\n  return vdso_base_.load(std::memory_order_relaxed);\n}\n\nconst void *VDSOSupport::SetBase(const void *base) {\n  ABSL_RAW_CHECK(base != debugging_internal::ElfMemImage::kInvalidBase,\n                 \"internal error\");\n  const void *old_base = vdso_base_.load(std::memory_order_relaxed);\n  vdso_base_.store(base, std::memory_order_relaxed);\n  image_.Init(base);\n  // Also reset getcpu_fn_, so GetCPU could be tested with simulated VDSO.\n  getcpu_fn_.store(&InitAndGetCPU, std::memory_order_relaxed);\n  return old_base;\n}\n\nbool VDSOSupport::LookupSymbol(const char *name,\n                               const char *version,\n                               int type,\n                               SymbolInfo *info) const {\n  return image_.LookupSymbol(name, version, type, info);\n}\n\nbool VDSOSupport::LookupSymbolByAddress(const void *address,\n                                        SymbolInfo *info_out) const {\n  return image_.LookupSymbolByAddress(address, info_out);\n}\n\n// NOLINT on 'long' because this routine mimics kernel api.\nlong VDSOSupport::GetCPUViaSyscall(unsigned *cpu,  // NOLINT(runtime/int)\n                                   void *, void *) {\n#ifdef SYS_getcpu\n  return syscall(SYS_getcpu, cpu, nullptr, nullptr);\n#else\n  // x86_64 never implemented sys_getcpu(), except as a VDSO call.\n  static_cast<void>(cpu);  // Avoid an unused argument compiler warning.\n  errno = ENOSYS;\n  return -1;\n#endif\n}\n\n// Use fast __vdso_getcpu if available.\nlong VDSOSupport::InitAndGetCPU(unsigned *cpu,  // NOLINT(runtime/int)\n                                void *x, void *y) {\n  Init();\n  GetCpuFn fn = getcpu_fn_.load(std::memory_order_relaxed);\n  ABSL_RAW_CHECK(fn != &InitAndGetCPU, \"Init() did not set getcpu_fn_\");\n  return (*fn)(cpu, x, y);\n}\n\n// This function must be very fast, and may be called from very\n// low level (e.g. tcmalloc). Hence I avoid things like\n// GoogleOnceInit() and ::operator new.\nABSL_ATTRIBUTE_NO_SANITIZE_MEMORY\nint GetCPU() {\n  unsigned cpu;\n  long ret_code =  // NOLINT(runtime/int)\n      (*VDSOSupport::getcpu_fn_)(&cpu, nullptr, nullptr);\n  return ret_code == 0 ? static_cast<int>(cpu) : static_cast<int>(ret_code);\n}\n\n}",
  "id": "BLOCK-CPP-02612",
  "language": "c++",
  "source_file": "/storage/emulated/0/Download/cpp_codebases/abseil/absl/debugging/internal/vdso_support.cc",
  "source_line": 66,
  "validation_status": "validated"
}