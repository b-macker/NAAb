{
  "code": "{\nABSL_NAMESPACE_BEGIN\nnamespace random_internal {\n// Returns true if the input value is zero or a power of two. Useful for\n// determining if the range of output values in a URBG\ntemplate <typename UIntType>\nconstexpr bool IsPowerOfTwoOrZero(UIntType n) {\n  return (n == 0) || ((n & (n - 1)) == 0);\n}\n\n// Computes the length of the range of values producible by the URBG, or returns\n// zero if that would encompass the entire range of representable values in\n// URBG::result_type.\ntemplate <typename URBG>\nconstexpr typename URBG::result_type RangeSize() {\n  using result_type = typename URBG::result_type;\n  static_assert((URBG::max)() != (URBG::min)(), \"URBG range cannot be 0.\");\n  return ((URBG::max)() == (std::numeric_limits<result_type>::max)() &&\n          (URBG::min)() == std::numeric_limits<result_type>::lowest())\n             ? result_type{0}\n             : ((URBG::max)() - (URBG::min)() + result_type{1});\n}\n\n// Computes the floor of the log. (i.e., std::floor(std::log2(N));\ntemplate <typename UIntType>\nconstexpr UIntType IntegerLog2(UIntType n) {\n  return (n <= 1) ? 0 : 1 + IntegerLog2(n >> 1);\n}\n\n// Returns the number of bits of randomness returned through\n// `PowerOfTwoVariate(urbg)`.\ntemplate <typename URBG>\nconstexpr size_t NumBits() {\n  return static_cast<size_t>(\n      RangeSize<URBG>() == 0\n          ? std::numeric_limits<typename URBG::result_type>::digits\n          : IntegerLog2(RangeSize<URBG>()));\n}\n\n// Given a shift value `n`, constructs a mask with exactly the low `n` bits set.\n// If `n == 0`, all bits are set.\ntemplate <typename UIntType>\nconstexpr UIntType MaskFromShift(size_t n) {\n  return ((n % std::numeric_limits<UIntType>::digits) == 0)\n             ? ~UIntType{0}\n             : (UIntType{1} << n) - UIntType{1};\n}\n\n// Tags used to dispatch FastUniformBits::generate to the simple or more complex\n// entropy extraction algorithm.\nstruct SimplifiedLoopTag {};\nstruct RejectionLoopTag {};\n\n// FastUniformBits implements a fast path to acquire uniform independent bits\n// from a type which conforms to the [rand.req.urbg] concept.\n// Parameterized by:\n//  `UIntType`: the result (output) type\n//\n// The std::independent_bits_engine [rand.adapt.ibits] adaptor can be\n// instantiated from an existing generator through a copy or a move. It does\n// not, however, facilitate the production of pseudorandom bits from an un-owned\n// generator that will outlive the std::independent_bits_engine instance.\ntemplate <typename UIntType = uint64_t>\nclass FastUniformBits {\n public:\n  using result_type = UIntType;\n\n  static constexpr result_type(min)() { return 0; }\n  static constexpr result_type(max)() {\n    return (std::numeric_limits<result_type>::max)();\n  }\n\n  template <typename URBG>\n  result_type operator()(URBG& g);  // NOLINT(runtime/references)\n\n private:\n  static_assert(IsUnsigned<UIntType>::value,\n                \"Class-template FastUniformBits<> must be parameterized using \"\n                \"an unsigned type.\");\n\n  // Generate() generates a random value, dispatched on whether\n  // the underlying URBG must use rejection sampling to generate a value,\n  // or whether a simplified loop will suffice.\n  template <typename URBG>\n  result_type Generate(URBG& g,  // NOLINT(runtime/references)\n                       SimplifiedLoopTag);\n\n  template <typename URBG>\n  result_type Generate(URBG& g,  // NOLINT(runtime/references)\n                       RejectionLoopTag);\n};\n\ntemplate <typename UIntType>\ntemplate <typename URBG>\ntypename FastUniformBits<UIntType>::result_type\nFastUniformBits<UIntType>::operator()(URBG& g) {  // NOLINT(runtime/references)\n  // kRangeMask is the mask used when sampling variates from the URBG when the\n  // width of the URBG range is not a power of 2.\n  // Y = (2 ^ kRange) - 1\n  static_assert((URBG::max)() > (URBG::min)(),\n                \"URBG::max and URBG::min may not be equal.\");\n\n  using tag = absl::conditional_t<IsPowerOfTwoOrZero(RangeSize<URBG>()),\n                                  SimplifiedLoopTag, RejectionLoopTag>;\n  return Generate(g, tag{});\n}\n\ntemplate <typename UIntType>\ntemplate <typename URBG>\ntypename FastUniformBits<UIntType>::result_type\nFastUniformBits<UIntType>::Generate(URBG& g,  // NOLINT(runtime/references)\n                                    SimplifiedLoopTag) {\n  // The simplified version of FastUniformBits works only on URBGs that have\n  // a range that is a power of 2. In this case we simply loop and shift without\n  // attempting to balance the bits across calls.\n  static_assert(IsPowerOfTwoOrZero(RangeSize<URBG>()),\n                \"incorrect Generate tag for URBG instance\");\n\n  static constexpr size_t kResultBits =\n      std::numeric_limits<result_type>::digits;\n  static constexpr size_t kUrbgBits = NumBits<URBG>();\n  static constexpr size_t kIters =\n      (kResultBits / kUrbgBits) + (kResultBits % kUrbgBits != 0);\n  static constexpr size_t kShift = (kIters == 1) ? 0 : kUrbgBits;\n  static constexpr auto kMin = (URBG::min)();\n\n  result_type r = static_cast<result_type>(g() - kMin);\n  for (size_t n = 1; n < kIters; ++n) {\n    r = static_cast<result_type>(r << kShift) +\n        static_cast<result_type>(g() - kMin);\n  }\n  return r;\n}\n\ntemplate <typename UIntType>\ntemplate <typename URBG>\ntypename FastUniformBits<UIntType>::result_type\nFastUniformBits<UIntType>::Generate(URBG& g,  // NOLINT(runtime/references)\n                                    RejectionLoopTag) {\n  static_assert(!IsPowerOfTwoOrZero(RangeSize<URBG>()),\n                \"incorrect Generate tag for URBG instance\");\n  using urbg_result_type = typename URBG::result_type;\n\n  // See [rand.adapt.ibits] for more details on the constants calculated below.\n  //\n  // It is preferable to use roughly the same number of bits from each generator\n  // call, however this is only possible when the number of bits provided by the\n  // URBG is a divisor of the number of bits in `result_type`. In all other\n  // cases, the number of bits used cannot always be the same, but it can be\n  // guaranteed to be off by at most 1. Thus we run two loops, one with a\n  // smaller bit-width size (`kSmallWidth`) and one with a larger width size\n  // (satisfying `kLargeWidth == kSmallWidth + 1`). The loops are run\n  // `kSmallIters` and `kLargeIters` times respectively such\n  // that\n  //\n  //    `kResultBits == kSmallIters * kSmallBits\n  //                    + kLargeIters * kLargeBits`\n  //\n  // where `kResultBits` is the total number of bits in `result_type`.\n  //\n  static constexpr size_t kResultBits =\n      std::numeric_limits<result_type>::digits;                      // w\n  static constexpr urbg_result_type kUrbgRange = RangeSize<URBG>();  // R\n  static constexpr size_t kUrbgBits = NumBits<URBG>();               // m\n\n  // compute the initial estimate of the bits used.\n  // [rand.adapt.ibits] 2 (c)\n  static constexpr size_t kA =  // ceil(w/m)\n      (kResultBits / kUrbgBits) + ((kResultBits % kUrbgBits) != 0);  // n'\n\n  static constexpr size_t kABits = kResultBits / kA;  // w0'\n  static constexpr urbg_result_type kARejection =\n      ((kUrbgRange >> kABits) << kABits);  // y0'\n\n  // refine the selection to reduce the rejection frequency.\n  static constexpr size_t kTotalIters =\n      ((kUrbgRange - kARejection) <= (kARejection / kA)) ? kA : (kA + 1);  // n\n\n  // [rand.adapt.ibits] 2 (b)\n  static constexpr size_t kSmallIters =\n      kTotalIters - (kResultBits % kTotalIters);                   // n0\n  static constexpr size_t kSmallBits = kResultBits / kTotalIters;  // w0\n  static constexpr urbg_result_type kSmallRejection =\n      ((kUrbgRange >> kSmallBits) << kSmallBits);  // y0\n\n  static constexpr size_t kLargeBits = kSmallBits + 1;  // w0+1\n  static constexpr urbg_result_type kLargeRejection =\n      ((kUrbgRange >> kLargeBits) << kLargeBits);  // y1\n\n  //\n  // Because `kLargeBits == kSmallBits + 1`, it follows that\n  //\n  //     `kResultBits == kSmallIters * kSmallBits + kLargeIters`\n  //\n  // and therefore\n  //\n  //     `kLargeIters == kTotalWidth % kSmallWidth`\n  //\n  // Intuitively, each iteration with the large width accounts for one unit\n  // of the remainder when `kTotalWidth` is divided by `kSmallWidth`. As\n  // mentioned above, if the URBG width is a divisor of `kTotalWidth`, then\n  // there would be no need for any large iterations (i.e., one loop would\n  // suffice), and indeed, in this case, `kLargeIters` would be zero.\n  static_assert(kResultBits == kSmallIters * kSmallBits +\n                                   (kTotalIters - kSmallIters) * kLargeBits,\n                \"Error in looping constant calculations.\");\n\n  // The small shift is essentially small bits, but due to the potential\n  // of generating a smaller result_type from a larger urbg type, the actual\n  // shift might be 0.\n  static constexpr size_t kSmallShift = kSmallBits % kResultBits;\n  static constexpr auto kSmallMask =\n      MaskFromShift<urbg_result_type>(kSmallShift);\n  static constexpr size_t kLargeShift = kLargeBits % kResultBits;\n  static constexpr auto kLargeMask =\n      MaskFromShift<urbg_result_type>(kLargeShift);\n\n  static constexpr auto kMin = (URBG::min)();\n\n  result_type s = 0;\n  for (size_t n = 0; n < kSmallIters; ++n) {\n    urbg_result_type v;\n    do {\n      v = g() - kMin;\n    } while (v >= kSmallRejection);\n\n    s = (s << kSmallShift) + static_cast<result_type>(v & kSmallMask);\n  }\n\n  for (size_t n = kSmallIters; n < kTotalIters; ++n) {\n    urbg_result_type v;\n    do {\n      v = g() - kMin;\n    } while (v >= kLargeRejection);\n\n    s = (s << kLargeShift) + static_cast<result_type>(v & kLargeMask);\n  }\n  return s;\n}\n\n}  // namespace random_internal\nABSL_NAMESPACE_END\n}",
  "id": "BLOCK-CPP-05862",
  "language": "c++",
  "source_file": "/storage/emulated/0/Download/cpp_codebases/abseil/absl/random/internal/fast_uniform_bits.h",
  "source_line": 27,
  "validation_status": "validated"
}