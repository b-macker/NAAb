{
  "code": "#include <cstddef>\n#include <cstdint>\n#include <memory>\n#include <vector>\n#include \"absl/base/attributes.h\"\n#include \"absl/base/config.h\"\n#include \"absl/base/internal/endian.h\"\n#include \"absl/base/prefetch.h\"\n#include \"absl/crc/internal/cpu_detect.h\"\n#include \"absl/crc/internal/crc32_x86_arm_combined_simd.h\"\n#include \"absl/crc/internal/crc_internal.h\"\n#include \"absl/memory/memory.h\"\n#include \"absl/numeric/bits.h\"\n\nusing namespace absl;\nusing namespace crc_internal;\n\nextern \"C\" {\n\nvoid BLOCK-CPP-02494_execute() {\n    {\n protected:\n  // Update partialCRC with crc of 64 byte block. Calling FinalizePclmulStream\n  // would produce a single crc checksum, but it is expensive. PCLMULQDQ has a\n  // high latency, so we run 4 128-bit partial checksums that can be reduced to\n  // a single value by FinalizePclmulStream later. Computing crc for arbitrary\n  // polynomialas with PCLMULQDQ is described in Intel paper \"Fast CRC\n  // Computation for Generic Polynomials Using PCLMULQDQ Instruction\"\n  // https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/fast-crc-computation-generic-polynomials-pclmulqdq-paper.pdf\n  // We are applying it to CRC32C polynomial.\n  ABSL_ATTRIBUTE_ALWAYS_INLINE void Process64BytesPclmul(\n      const uint8_t* p, V128* partialCRC) const {\n    V128 loopMultiplicands = V128_Load(reinterpret_cast<const V128*>(k1k2));\n\n    V128 partialCRC1 = partialCRC[0];\n    V128 partialCRC2 = partialCRC[1];\n    V128 partialCRC3 = partialCRC[2];\n    V128 partialCRC4 = partialCRC[3];\n\n    V128 tmp1 = V128_PMulHi(partialCRC1, loopMultiplicands);\n    V128 tmp2 = V128_PMulHi(partialCRC2, loopMultiplicands);\n    V128 tmp3 = V128_PMulHi(partialCRC3, loopMultiplicands);\n    V128 tmp4 = V128_PMulHi(partialCRC4, loopMultiplicands);\n    V128 data1 = V128_LoadU(reinterpret_cast<const V128*>(p + 16 * 0));\n    V128 data2 = V128_LoadU(reinterpret_cast<const V128*>(p + 16 * 1));\n    V128 data3 = V128_LoadU(reinterpret_cast<const V128*>(p + 16 * 2));\n    V128 data4 = V128_LoadU(reinterpret_cast<const V128*>(p + 16 * 3));\n    partialCRC1 = V128_PMulLow(partialCRC1, loopMultiplicands);\n    partialCRC2 = V128_PMulLow(partialCRC2, loopMultiplicands);\n    partialCRC3 = V128_PMulLow(partialCRC3, loopMultiplicands);\n    partialCRC4 = V128_PMulLow(partialCRC4, loopMultiplicands);\n    partialCRC1 = V128_Xor(tmp1, partialCRC1);\n    partialCRC2 = V128_Xor(tmp2, partialCRC2);\n    partialCRC3 = V128_Xor(tmp3, partialCRC3);\n    partialCRC4 = V128_Xor(tmp4, partialCRC4);\n    partialCRC1 = V128_Xor(partialCRC1, data1);\n    partialCRC2 = V128_Xor(partialCRC2, data2);\n    partialCRC3 = V128_Xor(partialCRC3, data3);\n    partialCRC4 = V128_Xor(partialCRC4, data4);\n    partialCRC[0] = partialCRC1;\n    partialCRC[1] = partialCRC2;\n    partialCRC[2] = partialCRC3;\n    partialCRC[3] = partialCRC4;\n  }\n\n  // Reduce partialCRC produced by Process64BytesPclmul into a single value,\n  // that represents crc checksum of all the processed bytes.\n  ABSL_ATTRIBUTE_ALWAYS_INLINE uint64_t\n  FinalizePclmulStream(V128* partialCRC) const {\n    V128 partialCRC1 = partialCRC[0];\n    V128 partialCRC2 = partialCRC[1];\n    V128 partialCRC3 = partialCRC[2];\n    V128 partialCRC4 = partialCRC[3];\n\n    // Combine 4 vectors of partial crc into a single vector.\n    V128 reductionMultiplicands =\n        V128_Load(reinterpret_cast<const V128*>(k5k6));\n\n    V128 low = V128_PMulLow(reductionMultiplicands, partialCRC1);\n    V128 high = V128_PMulHi(reductionMultiplicands, partialCRC1);\n\n    partialCRC1 = V128_Xor(low, high);\n    partialCRC1 = V128_Xor(partialCRC1, partialCRC2);\n\n    low = V128_PMulLow(reductionMultiplicands, partialCRC3);\n    high = V128_PMulHi(reductionMultiplicands, partialCRC3);\n\n    partialCRC3 = V128_Xor(low, high);\n    partialCRC3 = V128_Xor(partialCRC3, partialCRC4);\n\n    reductionMultiplicands = V128_Load(reinterpret_cast<const V128*>(k3k4));\n\n    low = V128_PMulLow(reductionMultiplicands, partialCRC1);\n    high = V128_PMulHi(reductionMultiplicands, partialCRC1);\n    V128 fullCRC = V128_Xor(low, high);\n    fullCRC = V128_Xor(fullCRC, partialCRC3);\n\n    // Reduce fullCRC into scalar value.\n    reductionMultiplicands = V128_Load(reinterpret_cast<const V128*>(k5k6));\n\n    V128 mask = V128_Load(reinterpret_cast<const V128*>(kMask));\n\n    V128 tmp = V128_PMul01(reductionMultiplicands, fullCRC);\n    fullCRC = V128_ShiftRight<8>(fullCRC);\n    fullCRC = V128_Xor(fullCRC, tmp);\n\n    reductionMultiplicands = V128_Load(reinterpret_cast<const V128*>(k7k0));\n\n    tmp = V128_ShiftRight<4>(fullCRC);\n    fullCRC = V128_And(fullCRC, mask);\n    fullCRC = V128_PMulLow(reductionMultiplicands, fullCRC);\n    fullCRC = V128_Xor(tmp, fullCRC);\n\n    reductionMultiplicands = V128_Load(reinterpret_cast<const V128*>(kPoly));\n\n    tmp = V128_And(fullCRC, mask);\n    tmp = V128_PMul01(reductionMultiplicands, tmp);\n    tmp = V128_And(tmp, mask);\n    tmp = V128_PMulLow(reductionMultiplicands, tmp);\n\n    fullCRC = V128_Xor(tmp, fullCRC);\n\n    return static_cast<uint64_t>(V128_Extract32<1>(fullCRC));\n  }\n\n  // Update crc with 64 bytes of data from p.\n  ABSL_ATTRIBUTE_ALWAYS_INLINE uint64_t Process64BytesCRC(const uint8_t* p,\n                                                          uint64_t crc) const {\n    for (int i = 0; i < 8; i++) {\n      crc =\n          CRC32_u64(static_cast<uint32_t>(crc), absl::little_endian::Load64(p));\n      p += 8;\n    }\n    return crc;\n  }\n\n  // Generated by crc32c_x86_test --crc32c_generate_constants=true\n  // and verified against constants in linux kernel for S390:\n  // https://github.com/torvalds/linux/blob/master/arch/s390/crypto/crc32le-vx.S\n  alignas(16) static constexpr uint64_t k1k2[2] = {0x0740eef02, 0x09e4addf8};\n  alignas(16) static constexpr uint64_t k3k4[2] = {0x1384aa63a, 0x0ba4fc28e};\n  alignas(16) static constexpr uint64_t k5k6[2] = {0x0f20c0dfe, 0x14cd00bd6};\n  alignas(16) static constexpr uint64_t k7k0[2] = {0x0dd45aab8, 0x000000000};\n  alignas(16) static constexpr uint64_t kPoly[2] = {0x105ec76f0, 0x0dea713f1};\n  alignas(16) static constexpr uint32_t kMask[4] = {~0u, 0u, ~0u, 0u};\n\n  // Medium runs of bytes are broken into groups of kGroupsSmall blocks of same\n  // size. Each group is CRCed in parallel then combined at the end of the\n  // block.\n  static constexpr size_t kGroupsSmall = 3;\n  // For large runs we use up to kMaxStreams blocks computed with CRC\n  // instruction, and up to kMaxStreams blocks computed with PCLMULQDQ, which\n  // are combined in the end.\n  static constexpr size_t kMaxStreams = 3;\n}\n}\n\n} // extern \"C\"\n",
  "id": "BLOCK-CPP-02494",
  "language": "c++",
  "source_file": "/storage/emulated/0/Download/cpp_codebases/abseil/absl/crc/internal/crc_x86_arm_combined.cc",
  "source_line": 207,
  "validation_status": "validated"
}