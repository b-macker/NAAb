{
  "code": "{\nABSL_NAMESPACE_BEGIN\nnamespace container_internal {\n\n// Stores information about a sampled hashtable.  All mutations to this *must*\n// be made through `Record*` functions below.  All reads from this *must* only\n// occur in the callback to `HashtablezSampler::Iterate`.\nstruct HashtablezInfo : public profiling_internal::Sample<HashtablezInfo> {\n  // Constructs the object but does not fill in any fields.\n  HashtablezInfo();\n  ~HashtablezInfo();\n  HashtablezInfo(const HashtablezInfo&) = delete;\n  HashtablezInfo& operator=(const HashtablezInfo&) = delete;\n\n  // Puts the object into a clean state, fills in the logically `const` members,\n  // blocking for any readers that are currently sampling the object.\n  void PrepareForSampling(int64_t stride, size_t inline_element_size_value)\n      ABSL_EXCLUSIVE_LOCKS_REQUIRED(init_mu);\n\n  // These fields are mutated by the various Record* APIs and need to be\n  // thread-safe.\n  std::atomic<size_t> capacity;\n  std::atomic<size_t> size;\n  std::atomic<size_t> num_erases;\n  std::atomic<size_t> num_rehashes;\n  std::atomic<size_t> max_probe_length;\n  std::atomic<size_t> total_probe_length;\n  std::atomic<size_t> hashes_bitwise_or;\n  std::atomic<size_t> hashes_bitwise_and;\n  std::atomic<size_t> hashes_bitwise_xor;\n  std::atomic<size_t> max_reserve;\n\n  // All of the fields below are set by `PrepareForSampling`, they must not be\n  // mutated in `Record*` functions.  They are logically `const` in that sense.\n  // These are guarded by init_mu, but that is not externalized to clients,\n  // which can read them only during `SampleRecorder::Iterate` which will hold\n  // the lock.\n  static constexpr int kMaxStackDepth = 64;\n  absl::Time create_time;\n  int32_t depth;\n  void* stack[kMaxStackDepth];\n  size_t inline_element_size;  // How big is the slot?\n};\n\nvoid RecordRehashSlow(HashtablezInfo* info, size_t total_probe_length);\n\nvoid RecordReservationSlow(HashtablezInfo* info, size_t target_capacity);\n\nvoid RecordClearedReservationSlow(HashtablezInfo* info);\n\nvoid RecordStorageChangedSlow(HashtablezInfo* info, size_t size,\n                              size_t capacity);\n\nvoid RecordInsertSlow(HashtablezInfo* info, size_t hash,\n                      size_t distance_from_desired);\n\nvoid RecordEraseSlow(HashtablezInfo* info);\n\nstruct SamplingState {\n  int64_t next_sample;\n  // When we make a sampling decision, we record that distance so we can weight\n  // each sample.\n  int64_t sample_stride;\n};\n\nHashtablezInfo* SampleSlow(SamplingState& next_sample,\n                           size_t inline_element_size);\nvoid UnsampleSlow(HashtablezInfo* info);\n\n#if defined(ABSL_INTERNAL_HASHTABLEZ_SAMPLE)\n#error ABSL_INTERNAL_HASHTABLEZ_SAMPLE cannot be directly set\n#endif  // defined(ABSL_INTERNAL_HASHTABLEZ_SAMPLE)\n\n#if defined(ABSL_INTERNAL_HASHTABLEZ_SAMPLE)\nclass HashtablezInfoHandle {\n public:\n  explicit HashtablezInfoHandle() : info_(nullptr) {}\n  explicit HashtablezInfoHandle(HashtablezInfo* info) : info_(info) {}\n\n  // We do not have a destructor. Caller is responsible for calling Unregister\n  // before destroying the handle.\n  void Unregister() {\n    if (ABSL_PREDICT_TRUE(info_ == nullptr)) return;\n    UnsampleSlow(info_);\n  }\n\n  inline bool IsSampled() const { return ABSL_PREDICT_FALSE(info_ != nullptr); }\n\n  inline void RecordStorageChanged(size_t size, size_t capacity) {\n    if (ABSL_PREDICT_TRUE(info_ == nullptr)) return;\n    RecordStorageChangedSlow(info_, size, capacity);\n  }\n\n  inline void RecordRehash(size_t total_probe_length) {\n    if (ABSL_PREDICT_TRUE(info_ == nullptr)) return;\n    RecordRehashSlow(info_, total_probe_length);\n  }\n\n  inline void RecordReservation(size_t target_capacity) {\n    if (ABSL_PREDICT_TRUE(info_ == nullptr)) return;\n    RecordReservationSlow(info_, target_capacity);\n  }\n\n  inline void RecordClearedReservation() {\n    if (ABSL_PREDICT_TRUE(info_ == nullptr)) return;\n    RecordClearedReservationSlow(info_);\n  }\n\n  inline void RecordInsert(size_t hash, size_t distance_from_desired) {\n    if (ABSL_PREDICT_TRUE(info_ == nullptr)) return;\n    RecordInsertSlow(info_, hash, distance_from_desired);\n  }\n\n  inline void RecordErase() {\n    if (ABSL_PREDICT_TRUE(info_ == nullptr)) return;\n    RecordEraseSlow(info_);\n  }\n\n  friend inline void swap(HashtablezInfoHandle& lhs,\n                          HashtablezInfoHandle& rhs) {\n    std::swap(lhs.info_, rhs.info_);\n  }\n\n private:\n  friend class HashtablezInfoHandlePeer;\n  HashtablezInfo* info_;\n};\n#else\n// Ensure that when Hashtablez is turned off at compile time, HashtablezInfo can\n// be removed by the linker, in order to reduce the binary size.\nclass HashtablezInfoHandle {\n public:\n  explicit HashtablezInfoHandle() = default;\n  explicit HashtablezInfoHandle(std::nullptr_t) {}\n\n  inline void Unregister() {}\n  inline bool IsSampled() const { return false; }\n  inline void RecordStorageChanged(size_t /*size*/, size_t /*capacity*/) {}\n  inline void RecordRehash(size_t /*total_probe_length*/) {}\n  inline void RecordReservation(size_t /*target_capacity*/) {}\n  inline void RecordClearedReservation() {}\n  inline void RecordInsert(size_t /*hash*/, size_t /*distance_from_desired*/) {}\n  inline void RecordErase() {}\n\n  friend inline void swap(HashtablezInfoHandle& /*lhs*/,\n                          HashtablezInfoHandle& /*rhs*/) {}\n};\n#endif  // defined(ABSL_INTERNAL_HASHTABLEZ_SAMPLE)\n\n#if defined(ABSL_INTERNAL_HASHTABLEZ_SAMPLE)\nextern ABSL_PER_THREAD_TLS_KEYWORD SamplingState global_next_sample;\n#endif  // defined(ABSL_INTERNAL_HASHTABLEZ_SAMPLE)\n\n// Returns an RAII sampling handle that manages registration and unregistation\n// with the global sampler.\ninline HashtablezInfoHandle Sample(\n    size_t inline_element_size ABSL_ATTRIBUTE_UNUSED) {\n#if defined(ABSL_INTERNAL_HASHTABLEZ_SAMPLE)\n  if (ABSL_PREDICT_TRUE(--global_next_sample.next_sample > 0)) {\n    return HashtablezInfoHandle(nullptr);\n  }\n  return HashtablezInfoHandle(\n      SampleSlow(global_next_sample, inline_element_size));\n#else\n  return HashtablezInfoHandle(nullptr);\n#endif  // !ABSL_PER_THREAD_TLS\n}\n\nusing HashtablezSampler =\n    ::absl::profiling_internal::SampleRecorder<HashtablezInfo>;\n\n// Returns a global Sampler.\nHashtablezSampler& GlobalHashtablezSampler();\n\nusing HashtablezConfigListener = void (*)();\nvoid SetHashtablezConfigListener(HashtablezConfigListener l);\n\n// Enables or disables sampling for Swiss tables.\nbool IsHashtablezEnabled();\nvoid SetHashtablezEnabled(bool enabled);\nvoid SetHashtablezEnabledInternal(bool enabled);\n\n// Sets the rate at which Swiss tables will be sampled.\nint32_t GetHashtablezSampleParameter();\nvoid SetHashtablezSampleParameter(int32_t rate);\nvoid SetHashtablezSampleParameterInternal(int32_t rate);\n\n// Sets a soft max for the number of samples that will be kept.\nsize_t GetHashtablezMaxSamples();\nvoid SetHashtablezMaxSamples(size_t max);\nvoid SetHashtablezMaxSamplesInternal(size_t max);\n\n// Configuration override.\n// This allows process-wide sampling without depending on order of\n// initialization of static storage duration objects.\n// The definition of this constant is weak, which allows us to inject a\n// different value for it at link time.\nextern \"C\" bool ABSL_INTERNAL_C_SYMBOL(AbslContainerInternalSampleEverything)();\n\n}  // namespace container_internal\nABSL_NAMESPACE_END\n}",
  "id": "BLOCK-CPP-05040",
  "language": "c++",
  "source_file": "/storage/emulated/0/Download/cpp_codebases/abseil/absl/container/internal/hashtablez_sampler.h",
  "source_line": 54,
  "validation_status": "validated"
}