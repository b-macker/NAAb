{
  "code": "{\n  friend class VAOptDefinitionContext;\n  friend class VariadicMacroScopeGuard;\n\n  llvm::unique_function<void(const clang::Token &)> OnToken;\n  std::shared_ptr<PreprocessorOptions> PPOpts;\n  DiagnosticsEngine        *Diags;\n  LangOptions       &LangOpts;\n  const TargetInfo *Target = nullptr;\n  const TargetInfo *AuxTarget = nullptr;\n  FileManager       &FileMgr;\n  SourceManager     &SourceMgr;\n  std::unique_ptr<ScratchBuffer> ScratchBuf;\n  HeaderSearch      &HeaderInfo;\n  ModuleLoader      &TheModuleLoader;\n\n  /// External source of macros.\n  ExternalPreprocessorSource *ExternalSource;\n\n  /// A BumpPtrAllocator object used to quickly allocate and release\n  /// objects internal to the Preprocessor.\n  llvm::BumpPtrAllocator BP;\n\n  /// Identifiers for builtin macros and other builtins.\n  IdentifierInfo *Ident__LINE__, *Ident__FILE__;   // __LINE__, __FILE__\n  IdentifierInfo *Ident__DATE__, *Ident__TIME__;   // __DATE__, __TIME__\n  IdentifierInfo *Ident__INCLUDE_LEVEL__;          // __INCLUDE_LEVEL__\n  IdentifierInfo *Ident__BASE_FILE__;              // __BASE_FILE__\n  IdentifierInfo *Ident__FILE_NAME__;              // __FILE_NAME__\n  IdentifierInfo *Ident__TIMESTAMP__;              // __TIMESTAMP__\n  IdentifierInfo *Ident__COUNTER__;                // __COUNTER__\n  IdentifierInfo *Ident_Pragma, *Ident__pragma;    // _Pragma, __pragma\n  IdentifierInfo *Ident__identifier;               // __identifier\n  IdentifierInfo *Ident__VA_ARGS__;                // __VA_ARGS__\n  IdentifierInfo *Ident__VA_OPT__;                 // __VA_OPT__\n  IdentifierInfo *Ident__has_feature;              // __has_feature\n  IdentifierInfo *Ident__has_extension;            // __has_extension\n  IdentifierInfo *Ident__has_builtin;              // __has_builtin\n  IdentifierInfo *Ident__has_constexpr_builtin;    // __has_constexpr_builtin\n  IdentifierInfo *Ident__has_attribute;            // __has_attribute\n  IdentifierInfo *Ident__has_include;              // __has_include\n  IdentifierInfo *Ident__has_include_next;         // __has_include_next\n  IdentifierInfo *Ident__has_warning;              // __has_warning\n  IdentifierInfo *Ident__is_identifier;            // __is_identifier\n  IdentifierInfo *Ident__building_module;          // __building_module\n  IdentifierInfo *Ident__MODULE__;                 // __MODULE__\n  IdentifierInfo *Ident__has_cpp_attribute;        // __has_cpp_attribute\n  IdentifierInfo *Ident__has_c_attribute;          // __has_c_attribute\n  IdentifierInfo *Ident__has_declspec;             // __has_declspec_attribute\n  IdentifierInfo *Ident__is_target_arch;           // __is_target_arch\n  IdentifierInfo *Ident__is_target_vendor;         // __is_target_vendor\n  IdentifierInfo *Ident__is_target_os;             // __is_target_os\n  IdentifierInfo *Ident__is_target_environment;    // __is_target_environment\n  IdentifierInfo *Ident__is_target_variant_os;\n  IdentifierInfo *Ident__is_target_variant_environment;\n  IdentifierInfo *Ident__FLT_EVAL_METHOD__;        // __FLT_EVAL_METHOD\n\n  // Weak, only valid (and set) while InMacroArgs is true.\n  Token* ArgMacro;\n\n  SourceLocation DATELoc, TIMELoc;\n\n  // FEM_UnsetOnCommandLine means that an explicit evaluation method was\n  // not specified on the command line. The target is queried to set the\n  // default evaluation method.\n  LangOptions::FPEvalMethodKind CurrentFPEvalMethod =\n      LangOptions::FPEvalMethodKind::FEM_UnsetOnCommandLine;\n\n  // The most recent pragma location where the floating point evaluation\n  // method was modified. This is used to determine whether the\n  // 'pragma clang fp eval_method' was used whithin the current scope.\n  SourceLocation LastFPEvalPragmaLocation;\n\n  LangOptions::FPEvalMethodKind TUFPEvalMethod =\n      LangOptions::FPEvalMethodKind::FEM_UnsetOnCommandLine;\n\n  // Next __COUNTER__ value, starts at 0.\n  unsigned CounterValue = 0;\n\n  enum {\n    /// Maximum depth of \\#includes.\n    MaxAllowedIncludeStackDepth = 200\n  };\n\n  // State that is set before the preprocessor begins.\n  bool KeepComments : 1;\n  bool KeepMacroComments : 1;\n  bool SuppressIncludeNotFoundError : 1;\n\n  // State that changes while the preprocessor runs:\n  bool InMacroArgs : 1;            // True if parsing fn macro invocation args.\n\n  /// Whether the preprocessor owns the header search object.\n  bool OwnsHeaderSearch : 1;\n\n  /// True if macro expansion is disabled.\n  bool DisableMacroExpansion : 1;\n\n  /// Temporarily disables DisableMacroExpansion (i.e. enables expansion)\n  /// when parsing preprocessor directives.\n  bool MacroExpansionInDirectivesOverride : 1;\n\n  class ResetMacroExpansionHelper;\n\n  /// Whether we have already loaded macros from the external source.\n  mutable bool ReadMacrosFromExternalSource : 1;\n\n  /// True if pragmas are enabled.\n  bool PragmasEnabled : 1;\n\n  /// True if the current build action is a preprocessing action.\n  bool PreprocessedOutput : 1;\n\n  /// True if we are currently preprocessing a #if or #elif directive\n  bool ParsingIfOrElifDirective;\n\n  /// True if we are pre-expanding macro arguments.\n  bool InMacroArgPreExpansion;\n\n  /// Mapping/lookup information for all identifiers in\n  /// the program, including program keywords.\n  mutable IdentifierTable Identifiers;\n\n  /// This table contains all the selectors in the program.\n  ///\n  /// Unlike IdentifierTable above, this table *isn't* populated by the\n  /// preprocessor. It is declared/expanded here because its role/lifetime is\n  /// conceptually similar to the IdentifierTable. In addition, the current\n  /// control flow (in clang::ParseAST()), make it convenient to put here.\n  ///\n  /// FIXME: Make sure the lifetime of Identifiers/Selectors *isn't* tied to\n  /// the lifetime of the preprocessor.\n  SelectorTable Selectors;\n\n  /// Information about builtins.\n  std::unique_ptr<Builtin::Context> BuiltinInfo;\n\n  /// Tracks all of the pragmas that the client registered\n  /// with this preprocessor.\n  std::unique_ptr<PragmaNamespace> PragmaHandlers;\n\n  /// Pragma handlers of the original source is stored here during the\n  /// parsing of a model file.\n  std::unique_ptr<PragmaNamespace> PragmaHandlersBackup;\n\n  /// Tracks all of the comment handlers that the client registered\n  /// with this preprocessor.\n  std::vector<CommentHandler *> CommentHandlers;\n\n  /// Empty line handler.\n  EmptylineHandler *Emptyline = nullptr;\n\npublic:\n  /// The kind of translation unit we are processing.\n  const TranslationUnitKind TUKind;\n\nprivate:\n  /// The code-completion handler.\n  CodeCompletionHandler *CodeComplete = nullptr;\n\n  /// The file that we're performing code-completion for, if any.\n  const FileEntry *CodeCompletionFile = nullptr;\n\n  /// The offset in file for the code-completion point.\n  unsigned CodeCompletionOffset = 0;\n\n  /// The location for the code-completion point. This gets instantiated\n  /// when the CodeCompletionFile gets \\#include'ed for preprocessing.\n  SourceLocation CodeCompletionLoc;\n\n  /// The start location for the file of the code-completion point.\n  ///\n  /// This gets instantiated when the CodeCompletionFile gets \\#include'ed\n  /// for preprocessing.\n  SourceLocation CodeCompletionFileLoc;\n\n  /// The source location of the \\c import contextual keyword we just\n  /// lexed, if any.\n  SourceLocation ModuleImportLoc;\n\n  /// The import path for named module that we're currently processing.\n  SmallVector<std::pair<IdentifierInfo *, SourceLocation>, 2> NamedModuleImportPath;\n\n  /// Whether the import is an `@import` or a standard c++ modules import.\n  bool IsAtImport = false;\n\n  /// Whether the last token we lexed was an '@'.\n  bool LastTokenWasAt = false;\n\n  /// A position within a C++20 import-seq.\n  class StdCXXImportSeq {\n  public:\n    enum State : int {\n      // Positive values represent a number of unclosed brackets.\n      AtTopLevel = 0,\n      AfterTopLevelTokenSeq = -1,\n      AfterExport = -2,\n      AfterImportSeq = -3,\n    };\n\n    StdCXXImportSeq(State S) : S(S) {}\n\n    /// Saw any kind of open bracket.\n    void handleOpenBracket() {\n      S = static_cast<State>(std::max<int>(S, 0) + 1);\n    }\n    /// Saw any kind of close bracket other than '}'.\n    void handleCloseBracket() {\n      S = static_cast<State>(std::max<int>(S, 1) - 1);\n    }\n    /// Saw a close brace.\n    void handleCloseBrace() {\n      handleCloseBracket();\n      if (S == AtTopLevel && !AfterHeaderName)\n        S = AfterTopLevelTokenSeq;\n    }\n    /// Saw a semicolon.\n    void handleSemi() {\n      if (atTopLevel()) {\n        S = AfterTopLevelTokenSeq;\n        AfterHeaderName = false;\n      }\n    }\n\n    /// Saw an 'export' identifier.\n    void handleExport() {\n      if (S == AfterTopLevelTokenSeq)\n        S = AfterExport;\n      else if (S <= 0)\n        S = AtTopLevel;\n    }\n    /// Saw an 'import' identifier.\n    void handleImport() {\n      if (S == AfterTopLevelTokenSeq || S == AfterExport)\n        S = AfterImportSeq;\n      else if (S <= 0)\n        S = AtTopLevel;\n    }\n\n    /// Saw a 'header-name' token; do not recognize any more 'import' tokens\n    /// until we reach a top-level semicolon.\n    void handleHeaderName() {\n      if (S == AfterImportSeq)\n        AfterHeaderName = true;\n      handleMisc();\n    }\n\n    /// Saw any other token.\n    void handleMisc() {\n      if (S <= 0)\n        S = AtTopLevel;\n    }\n\n    bool atTopLevel() { return S <= 0; }\n    bool afterImportSeq() { return S == AfterImportSeq; }\n    bool afterTopLevelSeq() { return S == AfterTopLevelTokenSeq; }\n\n  private:\n    State S;\n    /// Whether we're in the pp-import-suffix following the header-name in a\n    /// pp-import. If so, a close-brace is not sufficient to end the\n    /// top-level-token-seq of an import-seq.\n    bool AfterHeaderName = false;\n  };\n\n  /// Our current position within a C++20 import-seq.\n  StdCXXImportSeq StdCXXImportSeqState = StdCXXImportSeq::AfterTopLevelTokenSeq;\n\n  /// Track whether we are in a Global Module Fragment\n  class TrackGMF {\n  public:\n    enum GMFState : int {\n      GMFActive = 1,\n      MaybeGMF = 0,\n      BeforeGMFIntroducer = -1,\n      GMFAbsentOrEnded = -2,\n    };\n\n    TrackGMF(GMFState S) : S(S) {}\n\n    /// Saw a semicolon.\n    void handleSemi() {\n      // If it is immediately after the first instance of the module keyword,\n      // then that introduces the GMF.\n      if (S == MaybeGMF)\n        S = GMFActive;\n    }\n\n    /// Saw an 'export' identifier.\n    void handleExport() {\n      // The presence of an 'export' keyword always ends or excludes a GMF.\n      S = GMFAbsentOrEnded;\n    }\n\n    /// Saw an 'import' identifier.\n    void handleImport(bool AfterTopLevelTokenSeq) {\n      // If we see this before any 'module' kw, then we have no GMF.\n      if (AfterTopLevelTokenSeq && S == BeforeGMFIntroducer)\n        S = GMFAbsentOrEnded;\n    }\n\n    /// Saw a 'module' identifier.\n    void handleModule(bool AfterTopLevelTokenSeq) {\n      // This was the first module identifier and not preceded by any token\n      // that would exclude a GMF.  It could begin a GMF, but only if directly\n      // followed by a semicolon.\n      if (AfterTopLevelTokenSeq && S == BeforeGMFIntroducer)\n        S = MaybeGMF;\n      else\n        S = GMFAbsentOrEnded;\n    }\n\n    /// Saw any other token.\n    void handleMisc() {\n      // We saw something other than ; after the 'module' kw, so not a GMF.\n      if (S == MaybeGMF)\n        S = GMFAbsentOrEnded;\n    }\n\n    bool inGMF() { return S == GMFActive; }\n\n  private:\n    /// Track the transitions into and out of a Global Module Fragment,\n    /// if one is present.\n    GMFState S;\n  };\n\n  TrackGMF TrackGMFState = TrackGMF::BeforeGMFIntroducer;\n\n  /// Track the status of the c++20 module decl.\n  ///\n  ///   module-declaration:\n  ///     'export'[opt] 'module' module-name module-partition[opt]\n  ///     attribute-specifier-seq[opt] ';'\n  ///\n  ///   module-name:\n  ///     module-name-qualifier[opt] identifier\n  ///\n  ///   module-partition:\n  ///     ':' module-name-qualifier[opt] identifier\n  ///\n  ///   module-name-qualifier:\n  ///     identifier '.'\n  ///     module-name-qualifier identifier '.'\n  ///\n  /// Transition state:\n  ///\n  ///   NotAModuleDecl --- export ---> FoundExport\n  ///   NotAModuleDecl --- module ---> ImplementationCandidate\n  ///   FoundExport --- module ---> InterfaceCandidate\n  ///   ImplementationCandidate --- Identifier ---> ImplementationCandidate\n  ///   ImplementationCandidate --- period ---> ImplementationCandidate\n  ///   ImplementationCandidate --- colon ---> ImplementationCandidate\n  ///   InterfaceCandidate --- Identifier ---> InterfaceCandidate\n  ///   InterfaceCandidate --- period ---> InterfaceCandidate\n  ///   InterfaceCandidate --- colon ---> InterfaceCandidate\n  ///   ImplementationCandidate --- Semi ---> NamedModuleImplementation\n  ///   NamedModuleInterface --- Semi ---> NamedModuleInterface\n  ///   NamedModuleImplementation --- Anything ---> NamedModuleImplementation\n  ///   NamedModuleInterface --- Anything ---> NamedModuleInterface\n  ///\n  /// FIXME: We haven't handle attribute-specifier-seq here. It may not be bad\n  /// soon since we don't support any module attributes yet.\n  class ModuleDeclSeq {\n    enum ModuleDeclState : int {\n      NotAModuleDecl,\n      FoundExport,\n      InterfaceCandidate,\n      ImplementationCandidate,\n      NamedModuleInterface,\n      NamedModuleImplementation,\n    };\n\n  public:\n    ModuleDeclSeq() = default;\n\n    void handleExport() {\n      if (State == NotAModuleDecl)\n        State = FoundExport;\n      else if (!isNamedModule())\n        reset();\n    }\n\n    void handleModule() {\n      if (State == FoundExport)\n        State = InterfaceCandidate;\n      else if (State == NotAModuleDecl)\n        State = ImplementationCandidate;\n      else if (!isNamedModule())\n        reset();\n    }\n\n    void handleIdentifier(IdentifierInfo *Identifier) {\n      if (isModuleCandidate() && Identifier)\n        Name += Identifier->getName().str();\n      else if (!isNamedModule())\n        reset();\n    }\n\n    void handleColon() {\n      if (isModuleCandidate())\n        Name += \":\";\n      else if (!isNamedModule())\n        reset();\n    }\n\n    void handlePeriod() {\n      if (isModuleCandidate())\n        Name += \".\";\n      else if (!isNamedModule())\n        reset();\n    }\n\n    void handleSemi() {\n      if (!Name.empty() && isModuleCandidate()) {\n        if (State == InterfaceCandidate)\n          State = NamedModuleInterface;\n        else if (State == ImplementationCandidate)\n          State = NamedModuleImplementation;\n        else\n          llvm_unreachable(\"Unimaged ModuleDeclState.\");\n      } else if (!isNamedModule())\n        reset();\n    }\n\n    void handleMisc() {\n      if (!isNamedModule())\n        reset();\n    }\n\n    bool isModuleCandidate() const {\n      return State == InterfaceCandidate || State == ImplementationCandidate;\n    }\n\n    bool isNamedModule() const {\n      return State == NamedModuleInterface ||\n             State == NamedModuleImplementation;\n    }\n\n    bool isNamedInterface() const { return State == NamedModuleInterface; }\n\n    bool isImplementationUnit() const {\n      return State == NamedModuleImplementation && !getName().contains(':');\n    }\n\n    StringRef getName() const {\n      assert(isNamedModule() && \"Can't get name from a non named module\");\n      return Name;\n    }\n\n    StringRef getPrimaryName() const {\n      assert(isNamedModule() && \"Can't get name from a non named module\");\n      return getName().split(':').first;\n    }\n\n    void reset() {\n      Name.clear();\n      State = NotAModuleDecl;\n    }\n\n  private:\n    ModuleDeclState State = NotAModuleDecl;\n    std::string Name;\n  };\n\n  ModuleDeclSeq ModuleDeclState;\n\n  /// Whether the module import expects an identifier next. Otherwise,\n  /// it expects a '.' or ';'.\n  bool ModuleImportExpectsIdentifier = false;\n\n  /// The identifier and source location of the currently-active\n  /// \\#pragma clang arc_cf_code_audited begin.\n  std::pair<IdentifierInfo *, SourceLocation> PragmaARCCFCodeAuditedInfo;\n\n  /// The source location of the currently-active\n  /// \\#pragma clang assume_nonnull begin.\n  SourceLocation PragmaAssumeNonNullLoc;\n\n  /// Set only for preambles which end with an active\n  /// \\#pragma clang assume_nonnull begin.\n  ///\n  /// When the preamble is loaded into the main file,\n  /// `PragmaAssumeNonNullLoc` will be set to this to\n  /// replay the unterminated assume_nonnull.\n  SourceLocation PreambleRecordedPragmaAssumeNonNullLoc;\n\n  /// True if we hit the code-completion point.\n  bool CodeCompletionReached = false;\n\n  /// The code completion token containing the information\n  /// on the stem that is to be code completed.\n  IdentifierInfo *CodeCompletionII = nullptr;\n\n  /// Range for the code completion token.\n  SourceRange CodeCompletionTokenRange;\n\n  /// The directory that the main file should be considered to occupy,\n  /// if it does not correspond to a real file (as happens when building a\n  /// module).\n  OptionalDirectoryEntryRef MainFileDir;\n\n  /// The number of bytes that we will initially skip when entering the\n  /// main file, along with a flag that indicates whether skipping this number\n  /// of bytes will place the lexer at the start of a line.\n  ///\n  /// This is used when loading a precompiled preamble.\n  std::pair<int, bool> SkipMainFilePreamble;\n\n  /// Whether we hit an error due to reaching max allowed include depth. Allows\n  /// to avoid hitting the same error over and over again.\n  bool HasReachedMaxIncludeDepth = false;\n\n  /// The number of currently-active calls to Lex.\n  ///\n  /// Lex is reentrant, and asking for an (end-of-phase-4) token can often\n  /// require asking for multiple additional tokens. This counter makes it\n  /// possible for Lex to detect whether it's producing a token for the end\n  /// of phase 4 of translation or for some other situation.\n  unsigned LexLevel = 0;\n\n  /// The number of (LexLevel 0) preprocessor tokens.\n  unsigned TokenCount = 0;\n\n  /// Preprocess every token regardless of LexLevel.\n  bool PreprocessToken = false;\n\n  /// The maximum number of (LexLevel 0) tokens before issuing a -Wmax-tokens\n  /// warning, or zero for unlimited.\n  unsigned MaxTokens = 0;\n  SourceLocation MaxTokensOverrideLoc;\n\npublic:\n  struct PreambleSkipInfo {\n    SourceLocation HashTokenLoc;\n    SourceLocation IfTokenLoc;\n    bool FoundNonSkipPortion;\n    bool FoundElse;\n    SourceLocation ElseLoc;\n\n    PreambleSkipInfo(SourceLocation HashTokenLoc, SourceLocation IfTokenLoc,\n                     bool FoundNonSkipPortion, bool FoundElse,\n                     SourceLocation ElseLoc)\n        : HashTokenLoc(HashTokenLoc), IfTokenLoc(IfTokenLoc),\n          FoundNonSkipPortion(FoundNonSkipPortion), FoundElse(FoundElse),\n          ElseLoc(ElseLoc) {}\n  };\n\n  using IncludedFilesSet = llvm::DenseSet<const FileEntry *>;\n\nprivate:\n  friend class ASTReader;\n  friend class MacroArgs;\n\n  class PreambleConditionalStackStore {\n    enum State {\n      Off = 0,\n      Recording = 1,\n      Replaying = 2,\n    };\n\n  public:\n    PreambleConditionalStackStore() = default;\n\n    void startRecording() { ConditionalStackState = Recording; }\n    void startReplaying() { ConditionalStackState = Replaying; }\n    bool isRecording() const { return ConditionalStackState == Recording; }\n    bool isReplaying() const { return ConditionalStackState == Replaying; }\n\n    ArrayRef<PPConditionalInfo> getStack() const {\n      return ConditionalStack;\n    }\n\n    void doneReplaying() {\n      ConditionalStack.clear();\n      ConditionalStackState = Off;\n    }\n\n    void setStack(ArrayRef<PPConditionalInfo> s) {\n      if (!isRecording() && !isReplaying())\n        return;\n      ConditionalStack.clear();\n      ConditionalStack.append(s.begin(), s.end());\n    }\n\n    bool hasRecordedPreamble() const { return !ConditionalStack.empty(); }\n\n    bool reachedEOFWhileSkipping() const { return SkipInfo.has_value(); }\n\n    void clearSkipInfo() { SkipInfo.reset(); }\n\n    std::optional<PreambleSkipInfo> SkipInfo;\n\n  private:\n    SmallVector<PPConditionalInfo, 4> ConditionalStack;\n    State ConditionalStackState = Off;\n  } PreambleConditionalStack;\n\n  /// The current top of the stack that we're lexing from if\n  /// not expanding a macro and we are lexing directly from source code.\n  ///\n  /// Only one of CurLexer, or CurTokenLexer will be non-null.\n  std::unique_ptr<Lexer> CurLexer;\n\n  /// The current top of the stack that we're lexing from\n  /// if not expanding a macro.\n  ///\n  /// This is an alias for CurLexer.\n  PreprocessorLexer *CurPPLexer = nullptr;\n\n  /// Used to find the current FileEntry, if CurLexer is non-null\n  /// and if applicable.\n  ///\n  /// This allows us to implement \\#include_next and find directory-specific\n  /// properties.\n  ConstSearchDirIterator CurDirLookup = nullptr;\n\n  /// The current macro we are expanding, if we are expanding a macro.\n  ///\n  /// One of CurLexer and CurTokenLexer must be null.\n  std::unique_ptr<TokenLexer> CurTokenLexer;\n\n  /// The kind of lexer we're currently working with.\n  enum CurLexerKind {\n    CLK_Lexer,\n    CLK_TokenLexer,\n    CLK_CachingLexer,\n    CLK_DependencyDirectivesLexer,\n    CLK_LexAfterModuleImport\n  } CurLexerKind = CLK_Lexer;\n\n  /// If the current lexer is for a submodule that is being built, this\n  /// is that submodule.\n  Module *CurLexerSubmodule = nullptr;\n\n  /// Keeps track of the stack of files currently\n  /// \\#included, and macros currently being expanded from, not counting\n  /// CurLexer/CurTokenLexer.\n  struct IncludeStackInfo {\n    enum CurLexerKind           CurLexerKind;\n    Module                     *TheSubmodule;\n    std::unique_ptr<Lexer>      TheLexer;\n    PreprocessorLexer          *ThePPLexer;\n    std::unique_ptr<TokenLexer> TheTokenLexer;\n    ConstSearchDirIterator      TheDirLookup;\n\n    // The following constructors are completely useless copies of the default\n    // versions, only needed to pacify MSVC.\n    IncludeStackInfo(enum CurLexerKind CurLexerKind, Module *TheSubmodule,\n                     std::unique_ptr<Lexer> &&TheLexer,\n                     PreprocessorLexer *ThePPLexer,\n                     std::unique_ptr<TokenLexer> &&TheTokenLexer,\n                     ConstSearchDirIterator TheDirLookup)\n        : CurLexerKind(std::move(CurLexerKind)),\n          TheSubmodule(std::move(TheSubmodule)), TheLexer(std::move(TheLexer)),\n          ThePPLexer(std::move(ThePPLexer)),\n          TheTokenLexer(std::move(TheTokenLexer)),\n          TheDirLookup(std::move(TheDirLookup)) {}\n  };\n  std::vector<IncludeStackInfo> IncludeMacroStack;\n\n  /// Actions invoked when some preprocessor activity is\n  /// encountered (e.g. a file is \\#included, etc).\n  std::unique_ptr<PPCallbacks> Callbacks;\n\n  struct MacroExpandsInfo {\n    Token Tok;\n    MacroDefinition MD;\n    SourceRange Range;\n\n    MacroExpandsInfo(Token Tok, MacroDefinition MD, SourceRange Range)\n        : Tok(Tok), MD(MD), Range(Range) {}\n  };\n  SmallVector<MacroExpandsInfo, 2> DelayedMacroExpandsCallbacks;\n\n  /// Information about a name that has been used to define a module macro.\n  struct ModuleMacroInfo {\n    /// The most recent macro directive for this identifier.\n    MacroDirective *MD;\n\n    /// The active module macros for this identifier.\n    llvm::TinyPtrVector<ModuleMacro *> ActiveModuleMacros;\n\n    /// The generation number at which we last updated ActiveModuleMacros.\n    /// \\see Preprocessor::VisibleModules.\n    unsigned ActiveModuleMacrosGeneration = 0;\n\n    /// Whether this macro name is ambiguous.\n    bool IsAmbiguous = false;\n\n    /// The module macros that are overridden by this macro.\n    llvm::TinyPtrVector<ModuleMacro *> OverriddenMacros;\n\n    ModuleMacroInfo(MacroDirective *MD) : MD(MD) {}\n  };\n\n  /// The state of a macro for an identifier.\n  class MacroState {\n    mutable llvm::PointerUnion<MacroDirective *, ModuleMacroInfo *> State;\n\n    ModuleMacroInfo *getModuleInfo(Preprocessor &PP,\n                                   const IdentifierInfo *II) const {\n      if (II->isOutOfDate())\n        PP.updateOutOfDateIdentifier(const_cast<IdentifierInfo&>(*II));\n      // FIXME: Find a spare bit on IdentifierInfo and store a\n      //        HasModuleMacros flag.\n      if (!II->hasMacroDefinition() ||\n          (!PP.getLangOpts().Modules &&\n           !PP.getLangOpts().ModulesLocalVisibility) ||\n          !PP.CurSubmoduleState->VisibleModules.getGeneration())\n        return nullptr;\n\n      auto *Info = State.dyn_cast<ModuleMacroInfo*>();\n      if (!Info) {\n        Info = new (PP.getPreprocessorAllocator())\n            ModuleMacroInfo(State.get<MacroDirective *>());\n        State = Info;\n      }\n\n      if (PP.CurSubmoduleState->VisibleModules.getGeneration() !=\n          Info->ActiveModuleMacrosGeneration)\n        PP.updateModuleMacroInfo(II, *Info);\n      return Info;\n    }\n\n  public:\n    MacroState() : MacroState(nullptr) {}\n    MacroState(MacroDirective *MD) : State(MD) {}\n\n    MacroState(MacroState &&O) noexcept : State(O.State) {\n      O.State = (MacroDirective *)nullptr;\n    }\n\n    MacroState &operator=(MacroState &&O) noexcept {\n      auto S = O.State;\n      O.State = (MacroDirective *)nullptr;\n      State = S;\n      return *this;\n    }\n\n    ~MacroState() {\n      if (auto *Info = State.dyn_cast<ModuleMacroInfo*>())\n        Info->~ModuleMacroInfo();\n    }\n\n    MacroDirective *getLatest() const {\n      if (auto *Info = State.dyn_cast<ModuleMacroInfo*>())\n        return Info->MD;\n      return State.get<MacroDirective*>();\n    }\n\n    void setLatest(MacroDirective *MD) {\n      if (auto *Info = State.dyn_cast<ModuleMacroInfo*>())\n        Info->MD = MD;\n      else\n        State = MD;\n    }\n\n    bool isAmbiguous(Preprocessor &PP, const IdentifierInfo *II) const {\n      auto *Info = getModuleInfo(PP, II);\n      return Info ? Info->IsAmbiguous : false;\n    }\n\n    ArrayRef<ModuleMacro *>\n    getActiveModuleMacros(Preprocessor &PP, const IdentifierInfo *II) const {\n      if (auto *Info = getModuleInfo(PP, II))\n        return Info->ActiveModuleMacros;\n      return std::nullopt;\n    }\n\n    MacroDirective::DefInfo findDirectiveAtLoc(SourceLocation Loc,\n                                               SourceManager &SourceMgr) const {\n      // FIXME: Incorporate module macros into the result of this.\n      if (auto *Latest = getLatest())\n        return Latest->findDirectiveAtLoc(Loc, SourceMgr);\n      return {};\n    }\n\n    void overrideActiveModuleMacros(Preprocessor &PP, IdentifierInfo *II) {\n      if (auto *Info = getModuleInfo(PP, II)) {\n        Info->OverriddenMacros.insert(Info->OverriddenMacros.end(),\n                                      Info->ActiveModuleMacros.begin(),\n                                      Info->ActiveModuleMacros.end());\n        Info->ActiveModuleMacros.clear();\n        Info->IsAmbiguous = false;\n      }\n    }\n\n    ArrayRef<ModuleMacro*> getOverriddenMacros() const {\n      if (auto *Info = State.dyn_cast<ModuleMacroInfo*>())\n        return Info->OverriddenMacros;\n      return std::nullopt;\n    }\n\n    void setOverriddenMacros(Preprocessor &PP,\n                             ArrayRef<ModuleMacro *> Overrides) {\n      auto *Info = State.dyn_cast<ModuleMacroInfo*>();\n      if (!Info) {\n        if (Overrides.empty())\n          return;\n        Info = new (PP.getPreprocessorAllocator())\n            ModuleMacroInfo(State.get<MacroDirective *>());\n        State = Info;\n      }\n      Info->OverriddenMacros.clear();\n      Info->OverriddenMacros.insert(Info->OverriddenMacros.end(),\n                                    Overrides.begin(), Overrides.end());\n      Info->ActiveModuleMacrosGeneration = 0;\n    }\n  };\n\n  /// For each IdentifierInfo that was associated with a macro, we\n  /// keep a mapping to the history of all macro definitions and #undefs in\n  /// the reverse order (the latest one is in the head of the list).\n  ///\n  /// This mapping lives within the \\p CurSubmoduleState.\n  using MacroMap = llvm::DenseMap<const IdentifierInfo *, MacroState>;\n\n  struct SubmoduleState;\n\n  /// Information about a submodule that we're currently building.\n  struct BuildingSubmoduleInfo {\n    /// The module that we are building.\n    Module *M;\n\n    /// The location at which the module was included.\n    SourceLocation ImportLoc;\n\n    /// Whether we entered this submodule via a pragma.\n    bool IsPragma;\n\n    /// The previous SubmoduleState.\n    SubmoduleState *OuterSubmoduleState;\n\n    /// The number of pending module macro names when we started building this.\n    unsigned OuterPendingModuleMacroNames;\n\n    BuildingSubmoduleInfo(Module *M, SourceLocation ImportLoc, bool IsPragma,\n                          SubmoduleState *OuterSubmoduleState,\n                          unsigned OuterPendingModuleMacroNames)\n        : M(M), ImportLoc(ImportLoc), IsPragma(IsPragma),\n          OuterSubmoduleState(OuterSubmoduleState),\n          OuterPendingModuleMacroNames(OuterPendingModuleMacroNames) {}\n  };\n  SmallVector<BuildingSubmoduleInfo, 8> BuildingSubmoduleStack;\n\n  /// Information about a submodule's preprocessor state.\n  struct SubmoduleState {\n    /// The macros for the submodule.\n    MacroMap Macros;\n\n    /// The set of modules that are visible within the submodule.\n    VisibleModuleSet VisibleModules;\n\n    // FIXME: CounterValue?\n    // FIXME: PragmaPushMacroInfo?\n  };\n  std::map<Module *, SubmoduleState> Submodules;\n\n  /// The preprocessor state for preprocessing outside of any submodule.\n  SubmoduleState NullSubmoduleState;\n\n  /// The current submodule state. Will be \\p NullSubmoduleState if we're not\n  /// in a submodule.\n  SubmoduleState *CurSubmoduleState;\n\n  /// The files that have been included.\n  IncludedFilesSet IncludedFiles;\n\n  /// The set of top-level modules that affected preprocessing, but were not\n  /// imported.\n  llvm::SmallSetVector<Module *, 2> AffectingClangModules;\n\n  /// The set of known macros exported from modules.\n  llvm::FoldingSet<ModuleMacro> ModuleMacros;\n\n  /// The names of potential module macros that we've not yet processed.\n  llvm::SmallVector<const IdentifierInfo *, 32> PendingModuleMacroNames;\n\n  /// The list of module macros, for each identifier, that are not overridden by\n  /// any other module macro.\n  llvm::DenseMap<const IdentifierInfo *, llvm::TinyPtrVector<ModuleMacro *>>\n      LeafModuleMacros;\n\n  /// Macros that we want to warn because they are not used at the end\n  /// of the translation unit.\n  ///\n  /// We store just their SourceLocations instead of\n  /// something like MacroInfo*. The benefit of this is that when we are\n  /// deserializing from PCH, we don't need to deserialize identifier & macros\n  /// just so that we can report that they are unused, we just warn using\n  /// the SourceLocations of this set (that will be filled by the ASTReader).\n  using WarnUnusedMacroLocsTy = llvm::SmallDenseSet<SourceLocation, 32>;\n  WarnUnusedMacroLocsTy WarnUnusedMacroLocs;\n\n  /// This is a pair of an optional message and source location used for pragmas\n  /// that annotate macros like pragma clang restrict_expansion and pragma clang\n  /// deprecated. This pair stores the optional message and the location of the\n  /// annotation pragma for use producing diagnostics and notes.\n  using MsgLocationPair = std::pair<std::string, SourceLocation>;\n\n  struct MacroAnnotationInfo {\n    SourceLocation Location;\n    std::string Message;\n  };\n\n  struct MacroAnnotations {\n    std::optional<MacroAnnotationInfo> DeprecationInfo;\n    std::optional<MacroAnnotationInfo> RestrictExpansionInfo;\n    std::optional<SourceLocation> FinalAnnotationLoc;\n\n    static MacroAnnotations makeDeprecation(SourceLocation Loc,\n                                            std::string Msg) {\n      return MacroAnnotations{MacroAnnotationInfo{Loc, std::move(Msg)},\n                              std::nullopt, std::nullopt};\n    }\n\n    static MacroAnnotations makeRestrictExpansion(SourceLocation Loc,\n                                                  std::string Msg) {\n      return MacroAnnotations{\n          std::nullopt, MacroAnnotationInfo{Loc, std::move(Msg)}, std::nullopt};\n    }\n\n    static MacroAnnotations makeFinal(SourceLocation Loc) {\n      return MacroAnnotations{std::nullopt, std::nullopt, Loc};\n    }\n  };\n\n  /// Warning information for macro annotations.\n  llvm::DenseMap<const IdentifierInfo *, MacroAnnotations> AnnotationInfos;\n\n  /// A \"freelist\" of MacroArg objects that can be\n  /// reused for quick allocation.\n  MacroArgs *MacroArgCache = nullptr;\n\n  /// For each IdentifierInfo used in a \\#pragma push_macro directive,\n  /// we keep a MacroInfo stack used to restore the previous macro value.\n  llvm::DenseMap<IdentifierInfo *, std::vector<MacroInfo *>>\n      PragmaPushMacroInfo;\n\n  // Various statistics we track for performance analysis.\n  unsigned NumDirectives = 0;\n  unsigned NumDefined = 0;\n  unsigned NumUndefined = 0;\n  unsigned NumPragma = 0;\n  unsigned NumIf = 0;\n  unsigned NumElse = 0;\n  unsigned NumEndif = 0;\n  unsigned NumEnteredSourceFiles = 0;\n  unsigned MaxIncludeStackDepth = 0;\n  unsigned NumMacroExpanded = 0;\n  unsigned NumFnMacroExpanded = 0;\n  unsigned NumBuiltinMacroExpanded = 0;\n  unsigned NumFastMacroExpanded = 0;\n  unsigned NumTokenPaste = 0;\n  unsigned NumFastTokenPaste = 0;\n  unsigned NumSkipped = 0;\n\n  /// The predefined macros that preprocessor should use from the\n  /// command line etc.\n  std::string Predefines;\n\n  /// The file ID for the preprocessor predefines.\n  FileID PredefinesFileID;\n\n  /// The file ID for the PCH through header.\n  FileID PCHThroughHeaderFileID;\n\n  /// Whether tokens are being skipped until a #pragma hdrstop is seen.\n  bool SkippingUntilPragmaHdrStop = false;\n\n  /// Whether tokens are being skipped until the through header is seen.\n  bool SkippingUntilPCHThroughHeader = false;\n\n  /// \\{\n  /// Cache of macro expanders to reduce malloc traffic.\n  enum { TokenLexerCacheSize = 8 };\n  unsigned NumCachedTokenLexers;\n  std::unique_ptr<TokenLexer> TokenLexerCache[TokenLexerCacheSize];\n  /// \\}\n\n  /// Keeps macro expanded tokens for TokenLexers.\n  //\n  /// Works like a stack; a TokenLexer adds the macro expanded tokens that is\n  /// going to lex in the cache and when it finishes the tokens are removed\n  /// from the end of the cache.\n  SmallVector<Token, 16> MacroExpandedTokens;\n  std::vector<std::pair<TokenLexer *, size_t>> MacroExpandingLexersStack;\n\n  /// A record of the macro definitions and expansions that\n  /// occurred during preprocessing.\n  ///\n  /// This is an optional side structure that can be enabled with\n  /// \\c createPreprocessingRecord() prior to preprocessing.\n  PreprocessingRecord *Record = nullptr;\n\n  /// Cached tokens state.\n  using CachedTokensTy = SmallVector<Token, 1>;\n\n  /// Cached tokens are stored here when we do backtracking or\n  /// lookahead. They are \"lexed\" by the CachingLex() method.\n  CachedTokensTy CachedTokens;\n\n  /// The position of the cached token that CachingLex() should\n  /// \"lex\" next.\n  ///\n  /// If it points beyond the CachedTokens vector, it means that a normal\n  /// Lex() should be invoked.\n  CachedTokensTy::size_type CachedLexPos = 0;\n\n  /// Stack of backtrack positions, allowing nested backtracks.\n  ///\n  /// The EnableBacktrackAtThisPos() method pushes a position to\n  /// indicate where CachedLexPos should be set when the BackTrack() method is\n  /// invoked (at which point the last position is popped).\n  std::vector<CachedTokensTy::size_type> BacktrackPositions;\n\n  /// True if \\p Preprocessor::SkipExcludedConditionalBlock() is running.\n  /// This is used to guard against calling this function recursively.\n  ///\n  /// See comments at the use-site for more context about why it is needed.\n  bool SkippingExcludedConditionalBlock = false;\n\n  /// Keeps track of skipped range mappings that were recorded while skipping\n  /// excluded conditional directives. It maps the source buffer pointer at\n  /// the beginning of a skipped block, to the number of bytes that should be\n  /// skipped.\n  llvm::DenseMap<const char *, unsigned> RecordedSkippedRanges;\n\n  void updateOutOfDateIdentifier(IdentifierInfo &II) const;\n\npublic:\n  Preprocessor(std::shared_ptr<PreprocessorOptions> PPOpts,\n               DiagnosticsEngine &diags, LangOptions &opts, SourceManager &SM,\n               HeaderSearch &Headers, ModuleLoader &TheModuleLoader,\n               IdentifierInfoLookup *IILookup = nullptr,\n               bool OwnsHeaderSearch = false,\n               TranslationUnitKind TUKind = TU_Complete);\n\n  ~Preprocessor();\n\n  /// Initialize the preprocessor using information about the target.\n  ///\n  /// \\param Target is owned by the caller and must remain valid for the\n  /// lifetime of the preprocessor.\n  /// \\param AuxTarget is owned by the caller and must remain valid for\n  /// the lifetime of the preprocessor.\n  void Initialize(const TargetInfo &Target,\n                  const TargetInfo *AuxTarget = nullptr);\n\n  /// Initialize the preprocessor to parse a model file\n  ///\n  /// To parse model files the preprocessor of the original source is reused to\n  /// preserver the identifier table. However to avoid some duplicate\n  /// information in the preprocessor some cleanup is needed before it is used\n  /// to parse model files. This method does that cleanup.\n  void InitializeForModelFile();\n\n  /// Cleanup after model file parsing\n  void FinalizeForModelFile();\n\n  /// Retrieve the preprocessor options used to initialize this\n  /// preprocessor.\n  PreprocessorOptions &getPreprocessorOpts() const { return *PPOpts; }\n\n  DiagnosticsEngine &getDiagnostics() const { return *Diags; }\n  void setDiagnostics(DiagnosticsEngine &D) { Diags = &D; }\n\n  const LangOptions &getLangOpts() const { return LangOpts; }\n  const TargetInfo &getTargetInfo() const { return *Target; }\n  const TargetInfo *getAuxTargetInfo() const { return AuxTarget; }\n  FileManager &getFileManager() const { return FileMgr; }\n  SourceManager &getSourceManager() const { return SourceMgr; }\n  HeaderSearch &getHeaderSearchInfo() const { return HeaderInfo; }\n\n  IdentifierTable &getIdentifierTable() { return Identifiers; }\n  const IdentifierTable &getIdentifierTable() const { return Identifiers; }\n  SelectorTable &getSelectorTable() { return Selectors; }\n  Builtin::Context &getBuiltinInfo() { return *BuiltinInfo; }\n  llvm::BumpPtrAllocator &getPreprocessorAllocator() { return BP; }\n\n  void setExternalSource(ExternalPreprocessorSource *Source) {\n    ExternalSource = Source;\n  }\n\n  ExternalPreprocessorSource *getExternalSource() const {\n    return ExternalSource;\n  }\n\n  /// Retrieve the module loader associated with this preprocessor.\n  ModuleLoader &getModuleLoader() const { return TheModuleLoader; }\n\n  bool hadModuleLoaderFatalFailure() const {\n    return TheModuleLoader.HadFatalFailure;\n  }\n\n  /// Retrieve the number of Directives that have been processed by the\n  /// Preprocessor.\n  unsigned getNumDirectives() const {\n    return NumDirectives;\n  }\n\n  /// True if we are currently preprocessing a #if or #elif directive\n  bool isParsingIfOrElifDirective() const {\n    return ParsingIfOrElifDirective;\n  }\n\n  /// Control whether the preprocessor retains comments in output.\n  void SetCommentRetentionState(bool KeepComments, bool KeepMacroComments) {\n    this->KeepComments = KeepComments | KeepMacroComments;\n    this->KeepMacroComments = KeepMacroComments;\n  }\n\n  bool getCommentRetentionState() const { return KeepComments; }\n\n  void setPragmasEnabled(bool Enabled) { PragmasEnabled = Enabled; }\n  bool getPragmasEnabled() const { return PragmasEnabled; }\n\n  void SetSuppressIncludeNotFoundError(bool Suppress) {\n    SuppressIncludeNotFoundError = Suppress;\n  }\n\n  bool GetSuppressIncludeNotFoundError() {\n    return SuppressIncludeNotFoundError;\n  }\n\n  /// Sets whether the preprocessor is responsible for producing output or if\n  /// it is producing tokens to be consumed by Parse and Sema.\n  void setPreprocessedOutput(bool IsPreprocessedOutput) {\n    PreprocessedOutput = IsPreprocessedOutput;\n  }\n\n  /// Returns true if the preprocessor is responsible for generating output,\n  /// false if it is producing tokens to be consumed by Parse and Sema.\n  bool isPreprocessedOutput() const { return PreprocessedOutput; }\n\n  /// Return true if we are lexing directly from the specified lexer.\n  bool isCurrentLexer(const PreprocessorLexer *L) const {\n    return CurPPLexer == L;\n  }\n\n  /// Return the current lexer being lexed from.\n  ///\n  /// Note that this ignores any potentially active macro expansions and _Pragma\n  /// expansions going on at the time.\n  PreprocessorLexer *getCurrentLexer() const { return CurPPLexer; }\n\n  /// Return the current file lexer being lexed from.\n  ///\n  /// Note that this ignores any potentially active macro expansions and _Pragma\n  /// expansions going on at the time.\n  PreprocessorLexer *getCurrentFileLexer() const;\n\n  /// Return the submodule owning the file being lexed. This may not be\n  /// the current module if we have changed modules since entering the file.\n  Module *getCurrentLexerSubmodule() const { return CurLexerSubmodule; }\n\n  /// Returns the FileID for the preprocessor predefines.\n  FileID getPredefinesFileID() const { return PredefinesFileID; }\n\n  /// \\{\n  /// Accessors for preprocessor callbacks.\n  ///\n  /// Note that this class takes ownership of any PPCallbacks object given to\n  /// it.\n  PPCallbacks *getPPCallbacks() const { return Callbacks.get(); }\n  void addPPCallbacks(std::unique_ptr<PPCallbacks> C) {\n    if (Callbacks)\n      C = std::make_unique<PPChainedCallbacks>(std::move(C),\n                                                std::move(Callbacks));\n    Callbacks = std::move(C);\n  }\n  /// \\}\n\n  /// Get the number of tokens processed so far.\n  unsigned getTokenCount() const { return TokenCount; }\n\n  /// Get the max number of tokens before issuing a -Wmax-tokens warning.\n  unsigned getMaxTokens() const { return MaxTokens; }\n\n  void overrideMaxTokens(unsigned Value, SourceLocation Loc) {\n    MaxTokens = Value;\n    MaxTokensOverrideLoc = Loc;\n  };\n\n  SourceLocation getMaxTokensOverrideLoc() const { return MaxTokensOverrideLoc; }\n\n  /// Register a function that would be called on each token in the final\n  /// expanded token stream.\n  /// This also reports annotation tokens produced by the parser.\n  void setTokenWatcher(llvm::unique_function<void(const clang::Token &)> F) {\n    OnToken = std::move(F);\n  }\n\n  void setPreprocessToken(bool Preprocess) { PreprocessToken = Preprocess; }\n\n  bool isMacroDefined(StringRef Id) {\n    return isMacroDefined(&Identifiers.get(Id));\n  }\n  bool isMacroDefined(const IdentifierInfo *II) {\n    return II->hasMacroDefinition() &&\n           (!getLangOpts().Modules || (bool)getMacroDefinition(II));\n  }\n\n  /// Determine whether II is defined as a macro within the module M,\n  /// if that is a module that we've already preprocessed. Does not check for\n  /// macros imported into M.\n  bool isMacroDefinedInLocalModule(const IdentifierInfo *II, Module *M) {\n    if (!II->hasMacroDefinition())\n      return false;\n    auto I = Submodules.find(M);\n    if (I == Submodules.end())\n      return false;\n    auto J = I->second.Macros.find(II);\n    if (J == I->second.Macros.end())\n      return false;\n    auto *MD = J->second.getLatest();\n    return MD && MD->isDefined();\n  }\n\n  MacroDefinition getMacroDefinition(const IdentifierInfo *II) {\n    if (!II->hasMacroDefinition())\n      return {};\n\n    MacroState &S = CurSubmoduleState->Macros[II];\n    auto *MD = S.getLatest();\n    while (MD && isa<VisibilityMacroDirective>(MD))\n      MD = MD->getPrevious();\n    return MacroDefinition(dyn_cast_or_null<DefMacroDirective>(MD),\n                           S.getActiveModuleMacros(*this, II),\n                           S.isAmbiguous(*this, II));\n  }\n\n  MacroDefinition getMacroDefinitionAtLoc(const IdentifierInfo *II,\n                                          SourceLocation Loc) {\n    if (!II->hadMacroDefinition())\n      return {};\n\n    MacroState &S = CurSubmoduleState->Macros[II];\n    MacroDirective::DefInfo DI;\n    if (auto *MD = S.getLatest())\n      DI = MD->findDirectiveAtLoc(Loc, getSourceManager());\n    // FIXME: Compute the set of active module macros at the specified location.\n    return MacroDefinition(DI.getDirective(),\n                           S.getActiveModuleMacros(*this, II),\n                           S.isAmbiguous(*this, II));\n  }\n\n  /// Given an identifier, return its latest non-imported MacroDirective\n  /// if it is \\#define'd and not \\#undef'd, or null if it isn't \\#define'd.\n  MacroDirective *getLocalMacroDirective(const IdentifierInfo *II) const {\n    if (!II->hasMacroDefinition())\n      return nullptr;\n\n    auto *MD = getLocalMacroDirectiveHistory(II);\n    if (!MD || MD->getDefinition().isUndefined())\n      return nullptr;\n\n    return MD;\n  }\n\n  const MacroInfo *getMacroInfo(const IdentifierInfo *II) const {\n    return const_cast<Preprocessor*>(this)->getMacroInfo(II);\n  }\n\n  MacroInfo *getMacroInfo(const IdentifierInfo *II) {\n    if (!II->hasMacroDefinition())\n      return nullptr;\n    if (auto MD = getMacroDefinition(II))\n      return MD.getMacroInfo();\n    return nullptr;\n  }\n\n  /// Given an identifier, return the latest non-imported macro\n  /// directive for that identifier.\n  ///\n  /// One can iterate over all previous macro directives from the most recent\n  /// one.\n  MacroDirective *getLocalMacroDirectiveHistory(const IdentifierInfo *II) const;\n\n  /// Add a directive to the macro directive history for this identifier.\n  void appendMacroDirective(IdentifierInfo *II, MacroDirective *MD);\n  DefMacroDirective *appendDefMacroDirective(IdentifierInfo *II, MacroInfo *MI,\n                                             SourceLocation Loc) {\n    DefMacroDirective *MD = AllocateDefMacroDirective(MI, Loc);\n    appendMacroDirective(II, MD);\n    return MD;\n  }\n  DefMacroDirective *appendDefMacroDirective(IdentifierInfo *II,\n                                             MacroInfo *MI) {\n    return appendDefMacroDirective(II, MI, MI->getDefinitionLoc());\n  }\n\n  /// Set a MacroDirective that was loaded from a PCH file.\n  void setLoadedMacroDirective(IdentifierInfo *II, MacroDirective *ED,\n                               MacroDirective *MD);\n\n  /// Register an exported macro for a module and identifier.\n  ModuleMacro *addModuleMacro(Module *Mod, IdentifierInfo *II, MacroInfo *Macro,\n                              ArrayRef<ModuleMacro *> Overrides, bool &IsNew);\n  ModuleMacro *getModuleMacro(Module *Mod, const IdentifierInfo *II);\n\n  /// Get the list of leaf (non-overridden) module macros for a name.\n  ArrayRef<ModuleMacro*> getLeafModuleMacros(const IdentifierInfo *II) const {\n    if (II->isOutOfDate())\n      updateOutOfDateIdentifier(const_cast<IdentifierInfo&>(*II));\n    auto I = LeafModuleMacros.find(II);\n    if (I != LeafModuleMacros.end())\n      return I->second;\n    return std::nullopt;\n  }\n\n  /// Get the list of submodules that we're currently building.\n  ArrayRef<BuildingSubmoduleInfo> getBuildingSubmodules() const {\n    return BuildingSubmoduleStack;\n  }\n\n  /// \\{\n  /// Iterators for the macro history table. Currently defined macros have\n  /// IdentifierInfo::hasMacroDefinition() set and an empty\n  /// MacroInfo::getUndefLoc() at the head of the list.\n  using macro_iterator = MacroMap::const_iterator;\n\n  macro_iterator macro_begin(bool IncludeExternalMacros = true) const;\n  macro_iterator macro_end(bool IncludeExternalMacros = true) const;\n\n  llvm::iterator_range<macro_iterator>\n  macros(bool IncludeExternalMacros = true) const {\n    macro_iterator begin = macro_begin(IncludeExternalMacros);\n    macro_iterator end = macro_end(IncludeExternalMacros);\n    return llvm::make_range(begin, end);\n  }\n\n  /// \\}\n\n  /// Mark the given clang module as affecting the current clang module or translation unit.\n  void markClangModuleAsAffecting(Module *M) {\n    assert(M->isModuleMapModule());\n    if (!BuildingSubmoduleStack.empty()) {\n      if (M != BuildingSubmoduleStack.back().M)\n        BuildingSubmoduleStack.back().M->AffectingClangModules.insert(M);\n    } else {\n      AffectingClangModules.insert(M);\n    }\n  }\n\n  /// Get the set of top-level clang modules that affected preprocessing, but were not\n  /// imported.\n  const llvm::SmallSetVector<Module *, 2> &getAffectingClangModules() const {\n    return AffectingClangModules;\n  }\n\n  /// Mark the file as included.\n  /// Returns true if this is the first time the file was included.\n  bool markIncluded(const FileEntry *File) {\n    HeaderInfo.getFileInfo(File);\n    return IncludedFiles.insert(File).second;\n  }\n\n  /// Return true if this header has already been included.\n  bool alreadyIncluded(const FileEntry *File) const {\n    HeaderInfo.getFileInfo(File);\n    return IncludedFiles.count(File);\n  }\n\n  /// Get the set of included files.\n  IncludedFilesSet &getIncludedFiles() { return IncludedFiles; }\n  const IncludedFilesSet &getIncludedFiles() const { return IncludedFiles; }\n\n  /// Return the name of the macro defined before \\p Loc that has\n  /// spelling \\p Tokens.  If there are multiple macros with same spelling,\n  /// return the last one defined.\n  StringRef getLastMacroWithSpelling(SourceLocation Loc,\n                                     ArrayRef<TokenValue> Tokens) const;\n\n  /// Get the predefines for this processor.\n  /// Used by some third-party tools to inspect and add predefines (see\n  /// https://github.com/llvm/llvm-project/issues/57483).\n  const std::string &getPredefines() const { return Predefines; }\n\n  /// Set the predefines for this Preprocessor.\n  ///\n  /// These predefines are automatically injected when parsing the main file.\n  void setPredefines(std::string P) { Predefines = std::move(P); }\n\n  /// Return information about the specified preprocessor\n  /// identifier token.\n  IdentifierInfo *getIdentifierInfo(StringRef Name) const {\n    return &Identifiers.get(Name);\n  }\n\n  /// Add the specified pragma handler to this preprocessor.\n  ///\n  /// If \\p Namespace is non-null, then it is a token required to exist on the\n  /// pragma line before the pragma string starts, e.g. \"STDC\" or \"GCC\".\n  void AddPragmaHandler(StringRef Namespace, PragmaHandler *Handler);\n  void AddPragmaHandler(PragmaHandler *Handler) {\n    AddPragmaHandler(StringRef(), Handler);\n  }\n\n  /// Remove the specific pragma handler from this preprocessor.\n  ///\n  /// If \\p Namespace is non-null, then it should be the namespace that\n  /// \\p Handler was added to. It is an error to remove a handler that\n  /// has not been registered.\n  void RemovePragmaHandler(StringRef Namespace, PragmaHandler *Handler);\n  void RemovePragmaHandler(PragmaHandler *Handler) {\n    RemovePragmaHandler(StringRef(), Handler);\n  }\n\n  /// Install empty handlers for all pragmas (making them ignored).\n  void IgnorePragmas();\n\n  /// Set empty line handler.\n  void setEmptylineHandler(EmptylineHandler *Handler) { Emptyline = Handler; }\n\n  EmptylineHandler *getEmptylineHandler() const { return Emptyline; }\n\n  /// Add the specified comment handler to the preprocessor.\n  void addCommentHandler(CommentHandler *Handler);\n\n  /// Remove the specified comment handler.\n  ///\n  /// It is an error to remove a handler that has not been registered.\n  void removeCommentHandler(CommentHandler *Handler);\n\n  /// Set the code completion handler to the given object.\n  void setCodeCompletionHandler(CodeCompletionHandler &Handler) {\n    CodeComplete = &Handler;\n  }\n\n  /// Retrieve the current code-completion handler.\n  CodeCompletionHandler *getCodeCompletionHandler() const {\n    return CodeComplete;\n  }\n\n  /// Clear out the code completion handler.\n  void clearCodeCompletionHandler() {\n    CodeComplete = nullptr;\n  }\n\n  /// Hook used by the lexer to invoke the \"included file\" code\n  /// completion point.\n  void CodeCompleteIncludedFile(llvm::StringRef Dir, bool IsAngled);\n\n  /// Hook used by the lexer to invoke the \"natural language\" code\n  /// completion point.\n  void CodeCompleteNaturalLanguage();\n\n  /// Set the code completion token for filtering purposes.\n  void setCodeCompletionIdentifierInfo(IdentifierInfo *Filter) {\n    CodeCompletionII = Filter;\n  }\n\n  /// Set the code completion token range for detecting replacement range later\n  /// on.\n  void setCodeCompletionTokenRange(const SourceLocation Start,\n                                   const SourceLocation End) {\n    CodeCompletionTokenRange = {Start, End};\n  }\n  SourceRange getCodeCompletionTokenRange() const {\n    return CodeCompletionTokenRange;\n  }\n\n  /// Get the code completion token for filtering purposes.\n  StringRef getCodeCompletionFilter() {\n    if (CodeCompletionII)\n      return CodeCompletionII->getName();\n    return {};\n  }\n\n  /// Retrieve the preprocessing record, or NULL if there is no\n  /// preprocessing record.\n  PreprocessingRecord *getPreprocessingRecord() const { return Record; }\n\n  /// Create a new preprocessing record, which will keep track of\n  /// all macro expansions, macro definitions, etc.\n  void createPreprocessingRecord();\n\n  /// Returns true if the FileEntry is the PCH through header.\n  bool isPCHThroughHeader(const FileEntry *FE);\n\n  /// True if creating a PCH with a through header.\n  bool creatingPCHWithThroughHeader();\n\n  /// True if using a PCH with a through header.\n  bool usingPCHWithThroughHeader();\n\n  /// True if creating a PCH with a #pragma hdrstop.\n  bool creatingPCHWithPragmaHdrStop();\n\n  /// True if using a PCH with a #pragma hdrstop.\n  bool usingPCHWithPragmaHdrStop();\n\n  /// Skip tokens until after the #include of the through header or\n  /// until after a #pragma hdrstop.\n  void SkipTokensWhileUsingPCH();\n\n  /// Process directives while skipping until the through header or\n  /// #pragma hdrstop is found.\n  void HandleSkippedDirectiveWhileUsingPCH(Token &Result,\n                                           SourceLocation HashLoc);\n\n  /// Enter the specified FileID as the main source file,\n  /// which implicitly adds the builtin defines etc.\n  void EnterMainSourceFile();\n\n  /// Inform the preprocessor callbacks that processing is complete.\n  void EndSourceFile();\n\n  /// Add a source file to the top of the include stack and\n  /// start lexing tokens from it instead of the current buffer.\n  ///\n  /// Emits a diagnostic, doesn't enter the file, and returns true on error.\n  bool EnterSourceFile(FileID FID, ConstSearchDirIterator Dir,\n                       SourceLocation Loc, bool IsFirstIncludeOfFile = true);\n\n  /// Add a Macro to the top of the include stack and start lexing\n  /// tokens from it instead of the current buffer.\n  ///\n  /// \\param Args specifies the tokens input to a function-like macro.\n  /// \\param ILEnd specifies the location of the ')' for a function-like macro\n  /// or the identifier for an object-like macro.\n  void EnterMacro(Token &Tok, SourceLocation ILEnd, MacroInfo *Macro,\n                  MacroArgs *Args);\n\nprivate:\n  /// Add a \"macro\" context to the top of the include stack,\n  /// which will cause the lexer to start returning the specified tokens.\n  ///\n  /// If \\p DisableMacroExpansion is true, tokens lexed from the token stream\n  /// will not be subject to further macro expansion. Otherwise, these tokens\n  /// will be re-macro-expanded when/if expansion is enabled.\n  ///\n  /// If \\p OwnsTokens is false, this method assumes that the specified stream\n  /// of tokens has a permanent owner somewhere, so they do not need to be\n  /// copied. If it is true, it assumes the array of tokens is allocated with\n  /// \\c new[] and the Preprocessor will delete[] it.\n  ///\n  /// If \\p IsReinject the resulting tokens will have Token::IsReinjected flag\n  /// set, see the flag documentation for details.\n  void EnterTokenStream(const Token *Toks, unsigned NumToks,\n                        bool DisableMacroExpansion, bool OwnsTokens,\n                        bool IsReinject);\n\npublic:\n  void EnterTokenStream(std::unique_ptr<Token[]> Toks, unsigned NumToks,\n                        bool DisableMacroExpansion, bool IsReinject) {\n    EnterTokenStream(Toks.release(), NumToks, DisableMacroExpansion, true,\n                     IsReinject);\n  }\n\n  void EnterTokenStream(ArrayRef<Token> Toks, bool DisableMacroExpansion,\n                        bool IsReinject) {\n    EnterTokenStream(Toks.data(), Toks.size(), DisableMacroExpansion, false,\n                     IsReinject);\n  }\n\n  /// Pop the current lexer/macro exp off the top of the lexer stack.\n  ///\n  /// This should only be used in situations where the current state of the\n  /// top-of-stack lexer is known.\n  void RemoveTopOfLexerStack();\n\n  /// From the point that this method is called, and until\n  /// CommitBacktrackedTokens() or Backtrack() is called, the Preprocessor\n  /// keeps track of the lexed tokens so that a subsequent Backtrack() call will\n  /// make the Preprocessor re-lex the same tokens.\n  ///\n  /// Nested backtracks are allowed, meaning that EnableBacktrackAtThisPos can\n  /// be called multiple times and CommitBacktrackedTokens/Backtrack calls will\n  /// be combined with the EnableBacktrackAtThisPos calls in reverse order.\n  ///\n  /// NOTE: *DO NOT* forget to call either CommitBacktrackedTokens or Backtrack\n  /// at some point after EnableBacktrackAtThisPos. If you don't, caching of\n  /// tokens will continue indefinitely.\n  ///\n  void EnableBacktrackAtThisPos();\n\n  /// Disable the last EnableBacktrackAtThisPos call.\n  void CommitBacktrackedTokens();\n\n  /// Make Preprocessor re-lex the tokens that were lexed since\n  /// EnableBacktrackAtThisPos() was previously called.\n  void Backtrack();\n\n  /// True if EnableBacktrackAtThisPos() was called and\n  /// caching of tokens is on.\n  bool isBacktrackEnabled() const { return !BacktrackPositions.empty(); }\n\n  /// Lex the next token for this preprocessor.\n  void Lex(Token &Result);\n\n  /// Lex a token, forming a header-name token if possible.\n  bool LexHeaderName(Token &Result, bool AllowMacroExpansion = true);\n\n  bool LexAfterModuleImport(Token &Result);\n  void CollectPpImportSuffix(SmallVectorImpl<Token> &Toks);\n\n  void makeModuleVisible(Module *M, SourceLocation Loc);\n\n  SourceLocation getModuleImportLoc(Module *M) const {\n    return CurSubmoduleState->VisibleModules.getImportLoc(M);\n  }\n\n  /// Lex a string literal, which may be the concatenation of multiple\n  /// string literals and may even come from macro expansion.\n  /// \\returns true on success, false if a error diagnostic has been generated.\n  bool LexStringLiteral(Token &Result, std::string &String,\n                        const char *DiagnosticTag, bool AllowMacroExpansion) {\n    if (AllowMacroExpansion)\n      Lex(Result);\n    else\n      LexUnexpandedToken(Result);\n    return FinishLexStringLiteral(Result, String, DiagnosticTag,\n                                  AllowMacroExpansion);\n  }\n\n  /// Complete the lexing of a string literal where the first token has\n  /// already been lexed (see LexStringLiteral).\n  bool FinishLexStringLiteral(Token &Result, std::string &String,\n                              const char *DiagnosticTag,\n                              bool AllowMacroExpansion);\n\n  /// Lex a token.  If it's a comment, keep lexing until we get\n  /// something not a comment.\n  ///\n  /// This is useful in -E -C mode where comments would foul up preprocessor\n  /// directive handling.\n  void LexNonComment(Token &Result) {\n    do\n      Lex(Result);\n    while (Result.getKind() == tok::comment);\n  }\n\n  /// Just like Lex, but disables macro expansion of identifier tokens.\n  void LexUnexpandedToken(Token &Result) {\n    // Disable macro expansion.\n    bool OldVal = DisableMacroExpansion;\n    DisableMacroExpansion = true;\n    // Lex the token.\n    Lex(Result);\n\n    // Reenable it.\n    DisableMacroExpansion = OldVal;\n  }\n\n  /// Like LexNonComment, but this disables macro expansion of\n  /// identifier tokens.\n  void LexUnexpandedNonComment(Token &Result) {\n    do\n      LexUnexpandedToken(Result);\n    while (Result.getKind() == tok::comment);\n  }\n\n  /// Parses a simple integer literal to get its numeric value.  Floating\n  /// point literals and user defined literals are rejected.  Used primarily to\n  /// handle pragmas that accept integer arguments.\n  bool parseSimpleIntegerLiteral(Token &Tok, uint64_t &Value);\n\n  /// Disables macro expansion everywhere except for preprocessor directives.\n  void SetMacroExpansionOnlyInDirectives() {\n    DisableMacroExpansion = true;\n    MacroExpansionInDirectivesOverride = true;\n  }\n\n  /// Peeks ahead N tokens and returns that token without consuming any\n  /// tokens.\n  ///\n  /// LookAhead(0) returns the next token that would be returned by Lex(),\n  /// LookAhead(1) returns the token after it, etc.  This returns normal\n  /// tokens after phase 5.  As such, it is equivalent to using\n  /// 'Lex', not 'LexUnexpandedToken'.\n  const Token &LookAhead(unsigned N) {\n    assert(LexLevel == 0 && \"cannot use lookahead while lexing\");\n    if (CachedLexPos + N < CachedTokens.size())\n      return CachedTokens[CachedLexPos+N];\n    else\n      return PeekAhead(N+1);\n  }\n\n  /// When backtracking is enabled and tokens are cached,\n  /// this allows to revert a specific number of tokens.\n  ///\n  /// Note that the number of tokens being reverted should be up to the last\n  /// backtrack position, not more.\n  void RevertCachedTokens(unsigned N) {\n    assert(isBacktrackEnabled() &&\n           \"Should only be called when tokens are cached for backtracking\");\n    assert(signed(CachedLexPos) - signed(N) >= signed(BacktrackPositions.back())\n         && \"Should revert tokens up to the last backtrack position, not more\");\n    assert(signed(CachedLexPos) - signed(N) >= 0 &&\n           \"Corrupted backtrack positions ?\");\n    CachedLexPos -= N;\n  }\n\n  /// Enters a token in the token stream to be lexed next.\n  ///\n  /// If BackTrack() is called afterwards, the token will remain at the\n  /// insertion point.\n  /// If \\p IsReinject is true, resulting token will have Token::IsReinjected\n  /// flag set. See the flag documentation for details.\n  void EnterToken(const Token &Tok, bool IsReinject) {\n    if (LexLevel) {\n      // It's not correct in general to enter caching lex mode while in the\n      // middle of a nested lexing action.\n      auto TokCopy = std::make_unique<Token[]>(1);\n      TokCopy[0] = Tok;\n      EnterTokenStream(std::move(TokCopy), 1, true, IsReinject);\n    } else {\n      EnterCachingLexMode();\n      assert(IsReinject && \"new tokens in the middle of cached stream\");\n      CachedTokens.insert(CachedTokens.begin()+CachedLexPos, Tok);\n    }\n  }\n\n  /// We notify the Preprocessor that if it is caching tokens (because\n  /// backtrack is enabled) it should replace the most recent cached tokens\n  /// with the given annotation token. This function has no effect if\n  /// backtracking is not enabled.\n  ///\n  /// Note that the use of this function is just for optimization, so that the\n  /// cached tokens doesn't get re-parsed and re-resolved after a backtrack is\n  /// invoked.\n  void AnnotateCachedTokens(const Token &Tok) {\n    assert(Tok.isAnnotation() && \"Expected annotation token\");\n    if (CachedLexPos != 0 && isBacktrackEnabled())\n      AnnotatePreviousCachedTokens(Tok);\n  }\n\n  /// Get the location of the last cached token, suitable for setting the end\n  /// location of an annotation token.\n  SourceLocation getLastCachedTokenLocation() const {\n    assert(CachedLexPos != 0);\n    return CachedTokens[CachedLexPos-1].getLastLoc();\n  }\n\n  /// Whether \\p Tok is the most recent token (`CachedLexPos - 1`) in\n  /// CachedTokens.\n  bool IsPreviousCachedToken(const Token &Tok) const;\n\n  /// Replace token in `CachedLexPos - 1` in CachedTokens by the tokens\n  /// in \\p NewToks.\n  ///\n  /// Useful when a token needs to be split in smaller ones and CachedTokens\n  /// most recent token must to be updated to reflect that.\n  void ReplacePreviousCachedToken(ArrayRef<Token> NewToks);\n\n  /// Replace the last token with an annotation token.\n  ///\n  /// Like AnnotateCachedTokens(), this routine replaces an\n  /// already-parsed (and resolved) token with an annotation\n  /// token. However, this routine only replaces the last token with\n  /// the annotation token; it does not affect any other cached\n  /// tokens. This function has no effect if backtracking is not\n  /// enabled.\n  void ReplaceLastTokenWithAnnotation(const Token &Tok) {\n    assert(Tok.isAnnotation() && \"Expected annotation token\");\n    if (CachedLexPos != 0 && isBacktrackEnabled())\n      CachedTokens[CachedLexPos-1] = Tok;\n  }\n\n  /// Enter an annotation token into the token stream.\n  void EnterAnnotationToken(SourceRange Range, tok::TokenKind Kind,\n                            void *AnnotationVal);\n\n  /// Determine whether it's possible for a future call to Lex to produce an\n  /// annotation token created by a previous call to EnterAnnotationToken.\n  bool mightHavePendingAnnotationTokens() {\n    return CurLexerKind != CLK_Lexer;\n  }\n\n  /// Update the current token to represent the provided\n  /// identifier, in order to cache an action performed by typo correction.\n  void TypoCorrectToken(const Token &Tok) {\n    assert(Tok.getIdentifierInfo() && \"Expected identifier token\");\n    if (CachedLexPos != 0 && isBacktrackEnabled())\n      CachedTokens[CachedLexPos-1] = Tok;\n  }\n\n  /// Recompute the current lexer kind based on the CurLexer/\n  /// CurTokenLexer pointers.\n  void recomputeCurLexerKind();\n\n  /// Returns true if incremental processing is enabled\n  bool isIncrementalProcessingEnabled() const {\n    return getLangOpts().IncrementalExtensions;\n  }\n\n  /// Enables the incremental processing\n  void enableIncrementalProcessing(bool value = true) {\n    // FIXME: Drop this interface.\n    const_cast<LangOptions &>(getLangOpts()).IncrementalExtensions = value;\n  }\n\n  /// Specify the point at which code-completion will be performed.\n  ///\n  /// \\param File the file in which code completion should occur. If\n  /// this file is included multiple times, code-completion will\n  /// perform completion the first time it is included. If NULL, this\n  /// function clears out the code-completion point.\n  ///\n  /// \\param Line the line at which code completion should occur\n  /// (1-based).\n  ///\n  /// \\param Column the column at which code completion should occur\n  /// (1-based).\n  ///\n  /// \\returns true if an error occurred, false otherwise.\n  bool SetCodeCompletionPoint(const FileEntry *File,\n                              unsigned Line, unsigned Column);\n\n  /// Determine if we are performing code completion.\n  bool isCodeCompletionEnabled() const { return CodeCompletionFile != nullptr; }\n\n  /// Returns the location of the code-completion point.\n  ///\n  /// Returns an invalid location if code-completion is not enabled or the file\n  /// containing the code-completion point has not been lexed yet.\n  SourceLocation getCodeCompletionLoc() const { return CodeCompletionLoc; }\n\n  /// Returns the start location of the file of code-completion point.\n  ///\n  /// Returns an invalid location if code-completion is not enabled or the file\n  /// containing the code-completion point has not been lexed yet.\n  SourceLocation getCodeCompletionFileLoc() const {\n    return CodeCompletionFileLoc;\n  }\n\n  /// Returns true if code-completion is enabled and we have hit the\n  /// code-completion point.\n  bool isCodeCompletionReached() const { return CodeCompletionReached; }\n\n  /// Note that we hit the code-completion point.\n  void setCodeCompletionReached() {\n    assert(isCodeCompletionEnabled() && \"Code-completion not enabled!\");\n    CodeCompletionReached = true;\n    // Silence any diagnostics that occur after we hit the code-completion.\n    getDiagnostics().setSuppressAllDiagnostics(true);\n  }\n\n  /// The location of the currently-active \\#pragma clang\n  /// arc_cf_code_audited begin.\n  ///\n  /// Returns an invalid location if there is no such pragma active.\n  std::pair<IdentifierInfo *, SourceLocation>\n  getPragmaARCCFCodeAuditedInfo() const {\n    return PragmaARCCFCodeAuditedInfo;\n  }\n\n  /// Set the location of the currently-active \\#pragma clang\n  /// arc_cf_code_audited begin.  An invalid location ends the pragma.\n  void setPragmaARCCFCodeAuditedInfo(IdentifierInfo *Ident,\n                                     SourceLocation Loc) {\n    PragmaARCCFCodeAuditedInfo = {Ident, Loc};\n  }\n\n  /// The location of the currently-active \\#pragma clang\n  /// assume_nonnull begin.\n  ///\n  /// Returns an invalid location if there is no such pragma active.\n  SourceLocation getPragmaAssumeNonNullLoc() const {\n    return PragmaAssumeNonNullLoc;\n  }\n\n  /// Set the location of the currently-active \\#pragma clang\n  /// assume_nonnull begin.  An invalid location ends the pragma.\n  void setPragmaAssumeNonNullLoc(SourceLocation Loc) {\n    PragmaAssumeNonNullLoc = Loc;\n  }\n\n  /// Get the location of the recorded unterminated \\#pragma clang\n  /// assume_nonnull begin in the preamble, if one exists.\n  ///\n  /// Returns an invalid location if the premable did not end with\n  /// such a pragma active or if there is no recorded preamble.\n  SourceLocation getPreambleRecordedPragmaAssumeNonNullLoc() const {\n    return PreambleRecordedPragmaAssumeNonNullLoc;\n  }\n\n  /// Record the location of the unterminated \\#pragma clang\n  /// assume_nonnull begin in the preamble.\n  void setPreambleRecordedPragmaAssumeNonNullLoc(SourceLocation Loc) {\n    PreambleRecordedPragmaAssumeNonNullLoc = Loc;\n  }\n\n  /// Set the directory in which the main file should be considered\n  /// to have been found, if it is not a real file.\n  void setMainFileDir(DirectoryEntryRef Dir) { MainFileDir = Dir; }\n\n  /// Instruct the preprocessor to skip part of the main source file.\n  ///\n  /// \\param Bytes The number of bytes in the preamble to skip.\n  ///\n  /// \\param StartOfLine Whether skipping these bytes puts the lexer at the\n  /// start of a line.\n  void setSkipMainFilePreamble(unsigned Bytes, bool StartOfLine) {\n    SkipMainFilePreamble.first = Bytes;\n    SkipMainFilePreamble.second = StartOfLine;\n  }\n\n  /// Forwarding function for diagnostics.  This emits a diagnostic at\n  /// the specified Token's location, translating the token's start\n  /// position in the current buffer into a SourcePosition object for rendering.\n  DiagnosticBuilder Diag(SourceLocation Loc, unsigned DiagID) const {\n    return Diags->Report(Loc, DiagID);\n  }\n\n  DiagnosticBuilder Diag(const Token &Tok, unsigned DiagID) const {\n    return Diags->Report(Tok.getLocation(), DiagID);\n  }\n\n  /// Return the 'spelling' of the token at the given\n  /// location; does not go up to the spelling location or down to the\n  /// expansion location.\n  ///\n  /// \\param buffer A buffer which will be used only if the token requires\n  ///   \"cleaning\", e.g. if it contains trigraphs or escaped newlines\n  /// \\param invalid If non-null, will be set \\c true if an error occurs.\n  StringRef getSpelling(SourceLocation loc,\n                        SmallVectorImpl<char> &buffer,\n                        bool *invalid = nullptr) const {\n    return Lexer::getSpelling(loc, buffer, SourceMgr, LangOpts, invalid);\n  }\n\n  /// Return the 'spelling' of the Tok token.\n  ///\n  /// The spelling of a token is the characters used to represent the token in\n  /// the source file after trigraph expansion and escaped-newline folding.  In\n  /// particular, this wants to get the true, uncanonicalized, spelling of\n  /// things like digraphs, UCNs, etc.\n  ///\n  /// \\param Invalid If non-null, will be set \\c true if an error occurs.\n  std::string getSpelling(const Token &Tok, bool *Invalid = nullptr) const {\n    return Lexer::getSpelling(Tok, SourceMgr, LangOpts, Invalid);\n  }\n\n  /// Get the spelling of a token into a preallocated buffer, instead\n  /// of as an std::string.\n  ///\n  /// The caller is required to allocate enough space for the token, which is\n  /// guaranteed to be at least Tok.getLength() bytes long. The length of the\n  /// actual result is returned.\n  ///\n  /// Note that this method may do two possible things: it may either fill in\n  /// the buffer specified with characters, or it may *change the input pointer*\n  /// to point to a constant buffer with the data already in it (avoiding a\n  /// copy).  The caller is not allowed to modify the returned buffer pointer\n  /// if an internal buffer is returned.\n  unsigned getSpelling(const Token &Tok, const char *&Buffer,\n                       bool *Invalid = nullptr) const {\n    return Lexer::getSpelling(Tok, Buffer, SourceMgr, LangOpts, Invalid);\n  }\n\n  /// Get the spelling of a token into a SmallVector.\n  ///\n  /// Note that the returned StringRef may not point to the\n  /// supplied buffer if a copy can be avoided.\n  StringRef getSpelling(const Token &Tok,\n                        SmallVectorImpl<char> &Buffer,\n                        bool *Invalid = nullptr) const;\n\n  /// Relex the token at the specified location.\n  /// \\returns true if there was a failure, false on success.\n  bool getRawToken(SourceLocation Loc, Token &Result,\n                   bool IgnoreWhiteSpace = false) {\n    return Lexer::getRawToken(Loc, Result, SourceMgr, LangOpts, IgnoreWhiteSpace);\n  }\n\n  /// Given a Token \\p Tok that is a numeric constant with length 1,\n  /// return the character.\n  char\n  getSpellingOfSingleCharacterNumericConstant(const Token &Tok,\n                                              bool *Invalid = nullptr) const {\n    assert(Tok.is(tok::numeric_constant) &&\n           Tok.getLength() == 1 && \"Called on unsupported token\");\n    assert(!Tok.needsCleaning() && \"Token can't need cleaning with length 1\");\n\n    // If the token is carrying a literal data pointer, just use it.\n    if (const char *D = Tok.getLiteralData())\n      return *D;\n\n    // Otherwise, fall back on getCharacterData, which is slower, but always\n    // works.\n    return *SourceMgr.getCharacterData(Tok.getLocation(), Invalid);\n  }\n\n  /// Retrieve the name of the immediate macro expansion.\n  ///\n  /// This routine starts from a source location, and finds the name of the\n  /// macro responsible for its immediate expansion. It looks through any\n  /// intervening macro argument expansions to compute this. It returns a\n  /// StringRef that refers to the SourceManager-owned buffer of the source\n  /// where that macro name is spelled. Thus, the result shouldn't out-live\n  /// the SourceManager.\n  StringRef getImmediateMacroName(SourceLocation Loc) {\n    return Lexer::getImmediateMacroName(Loc, SourceMgr, getLangOpts());\n  }\n\n  /// Plop the specified string into a scratch buffer and set the\n  /// specified token's location and length to it.\n  ///\n  /// If specified, the source location provides a location of the expansion\n  /// point of the token.\n  void CreateString(StringRef Str, Token &Tok,\n                    SourceLocation ExpansionLocStart = SourceLocation(),\n                    SourceLocation ExpansionLocEnd = SourceLocation());\n\n  /// Split the first Length characters out of the token starting at TokLoc\n  /// and return a location pointing to the split token. Re-lexing from the\n  /// split token will return the split token rather than the original.\n  SourceLocation SplitToken(SourceLocation TokLoc, unsigned Length);\n\n  /// Computes the source location just past the end of the\n  /// token at this source location.\n  ///\n  /// This routine can be used to produce a source location that\n  /// points just past the end of the token referenced by \\p Loc, and\n  /// is generally used when a diagnostic needs to point just after a\n  /// token where it expected something different that it received. If\n  /// the returned source location would not be meaningful (e.g., if\n  /// it points into a macro), this routine returns an invalid\n  /// source location.\n  ///\n  /// \\param Offset an offset from the end of the token, where the source\n  /// location should refer to. The default offset (0) produces a source\n  /// location pointing just past the end of the token; an offset of 1 produces\n  /// a source location pointing to the last character in the token, etc.\n  SourceLocation getLocForEndOfToken(SourceLocation Loc, unsigned Offset = 0) {\n    return Lexer::getLocForEndOfToken(Loc, Offset, SourceMgr, LangOpts);\n  }\n\n  /// Returns true if the given MacroID location points at the first\n  /// token of the macro expansion.\n  ///\n  /// \\param MacroBegin If non-null and function returns true, it is set to\n  /// begin location of the macro.\n  bool isAtStartOfMacroExpansion(SourceLocation loc,\n                                 SourceLocation *MacroBegin = nullptr) const {\n    return Lexer::isAtStartOfMacroExpansion(loc, SourceMgr, LangOpts,\n                                            MacroBegin);\n  }\n\n  /// Returns true if the given MacroID location points at the last\n  /// token of the macro expansion.\n  ///\n  /// \\param MacroEnd If non-null and function returns true, it is set to\n  /// end location of the macro.\n  bool isAtEndOfMacroExpansion(SourceLocation loc,\n                               SourceLocation *MacroEnd = nullptr) const {\n    return Lexer::isAtEndOfMacroExpansion(loc, SourceMgr, LangOpts, MacroEnd);\n  }\n\n  /// Print the token to stderr, used for debugging.\n  void DumpToken(const Token &Tok, bool DumpFlags = false) const;\n  void DumpLocation(SourceLocation Loc) const;\n  void DumpMacro(const MacroInfo &MI) const;\n  void dumpMacroInfo(const IdentifierInfo *II);\n\n  /// Given a location that specifies the start of a\n  /// token, return a new location that specifies a character within the token.\n  SourceLocation AdvanceToTokenCharacter(SourceLocation TokStart,\n                                         unsigned Char) const {\n    return Lexer::AdvanceToTokenCharacter(TokStart, Char, SourceMgr, LangOpts);\n  }\n\n  /// Increment the counters for the number of token paste operations\n  /// performed.\n  ///\n  /// If fast was specified, this is a 'fast paste' case we handled.\n  void IncrementPasteCounter(bool isFast) {\n    if (isFast)\n      ++NumFastTokenPaste;\n    else\n      ++NumTokenPaste;\n  }\n\n  void PrintStats();\n\n  size_t getTotalMemory() const;\n\n  /// When the macro expander pastes together a comment (/##/) in Microsoft\n  /// mode, this method handles updating the current state, returning the\n  /// token on the next source line.\n  void HandleMicrosoftCommentPaste(Token &Tok);\n\n  //===--------------------------------------------------------------------===//\n  // Preprocessor callback methods.  These are invoked by a lexer as various\n  // directives and events are found.\n\n  /// Given a tok::raw_identifier token, look up the\n  /// identifier information for the token and install it into the token,\n  /// updating the token kind accordingly.\n  IdentifierInfo *LookUpIdentifierInfo(Token &Identifier) const;\n\nprivate:\n  llvm::DenseMap<IdentifierInfo*,unsigned> PoisonReasons;\n\npublic:\n  /// Specifies the reason for poisoning an identifier.\n  ///\n  /// If that identifier is accessed while poisoned, then this reason will be\n  /// used instead of the default \"poisoned\" diagnostic.\n  void SetPoisonReason(IdentifierInfo *II, unsigned DiagID);\n\n  /// Display reason for poisoned identifier.\n  void HandlePoisonedIdentifier(Token & Identifier);\n\n  void MaybeHandlePoisonedIdentifier(Token & Identifier) {\n    if(IdentifierInfo * II = Identifier.getIdentifierInfo()) {\n      if(II->isPoisoned()) {\n        HandlePoisonedIdentifier(Identifier);\n      }\n    }\n  }\n\nprivate:\n  /// Identifiers used for SEH handling in Borland. These are only\n  /// allowed in particular circumstances\n  // __except block\n  IdentifierInfo *Ident__exception_code,\n                 *Ident___exception_code,\n                 *Ident_GetExceptionCode;\n  // __except filter expression\n  IdentifierInfo *Ident__exception_info,\n                 *Ident___exception_info,\n                 *Ident_GetExceptionInfo;\n  // __finally\n  IdentifierInfo *Ident__abnormal_termination,\n                 *Ident___abnormal_termination,\n                 *Ident_AbnormalTermination;\n\n  const char *getCurLexerEndPos();\n  void diagnoseMissingHeaderInUmbrellaDir(const Module &Mod);\n\npublic:\n  void PoisonSEHIdentifiers(bool Poison = true); // Borland\n\n  /// Callback invoked when the lexer reads an identifier and has\n  /// filled in the tokens IdentifierInfo member.\n  ///\n  /// This callback potentially macro expands it or turns it into a named\n  /// token (like 'for').\n  ///\n  /// \\returns true if we actually computed a token, false if we need to\n  /// lex again.\n  bool HandleIdentifier(Token &Identifier);\n\n  /// Callback invoked when the lexer hits the end of the current file.\n  ///\n  /// This either returns the EOF token and returns true, or\n  /// pops a level off the include stack and returns false, at which point the\n  /// client should call lex again.\n  bool HandleEndOfFile(Token &Result, bool isEndOfMacro = false);\n\n  /// Callback invoked when the current TokenLexer hits the end of its\n  /// token stream.\n  bool HandleEndOfTokenLexer(Token &Result);\n\n  /// Callback invoked when the lexer sees a # token at the start of a\n  /// line.\n  ///\n  /// This consumes the directive, modifies the lexer/preprocessor state, and\n  /// advances the lexer(s) so that the next token read is the correct one.\n  void HandleDirective(Token &Result);\n\n  /// Ensure that the next token is a tok::eod token.\n  ///\n  /// If not, emit a diagnostic and consume up until the eod.\n  /// If \\p EnableMacros is true, then we consider macros that expand to zero\n  /// tokens as being ok.\n  ///\n  /// \\return The location of the end of the directive (the terminating\n  /// newline).\n  SourceLocation CheckEndOfDirective(const char *DirType,\n                                     bool EnableMacros = false);\n\n  /// Read and discard all tokens remaining on the current line until\n  /// the tok::eod token is found. Returns the range of the skipped tokens.\n  SourceRange DiscardUntilEndOfDirective();\n\n  /// Returns true if the preprocessor has seen a use of\n  /// __DATE__ or __TIME__ in the file so far.\n  bool SawDateOrTime() const {\n    return DATELoc != SourceLocation() || TIMELoc != SourceLocation();\n  }\n  unsigned getCounterValue() const { return CounterValue; }\n  void setCounterValue(unsigned V) { CounterValue = V; }\n\n  LangOptions::FPEvalMethodKind getCurrentFPEvalMethod() const {\n    assert(CurrentFPEvalMethod != LangOptions::FEM_UnsetOnCommandLine &&\n           \"FPEvalMethod should be set either from command line or from the \"\n           \"target info\");\n    return CurrentFPEvalMethod;\n  }\n\n  LangOptions::FPEvalMethodKind getTUFPEvalMethod() const {\n    return TUFPEvalMethod;\n  }\n\n  SourceLocation getLastFPEvalPragmaLocation() const {\n    return LastFPEvalPragmaLocation;\n  }\n\n  void setCurrentFPEvalMethod(SourceLocation PragmaLoc,\n                              LangOptions::FPEvalMethodKind Val) {\n    assert(Val != LangOptions::FEM_UnsetOnCommandLine &&\n           \"FPEvalMethod should never be set to FEM_UnsetOnCommandLine\");\n    // This is the location of the '#pragma float_control\" where the\n    // execution state is modifed.\n    LastFPEvalPragmaLocation = PragmaLoc;\n    CurrentFPEvalMethod = Val;\n    TUFPEvalMethod = Val;\n  }\n\n  void setTUFPEvalMethod(LangOptions::FPEvalMethodKind Val) {\n    assert(Val != LangOptions::FEM_UnsetOnCommandLine &&\n           \"TUPEvalMethod should never be set to FEM_UnsetOnCommandLine\");\n    TUFPEvalMethod = Val;\n  }\n\n  /// Retrieves the module that we're currently building, if any.\n  Module *getCurrentModule();\n\n  /// Retrieves the module whose implementation we're current compiling, if any.\n  Module *getCurrentModuleImplementation();\n\n  /// If we are preprocessing a named module.\n  bool isInNamedModule() const { return ModuleDeclState.isNamedModule(); }\n\n  /// If we are proprocessing a named interface unit.\n  /// Note that a module implementation partition is not considered as an\n  /// named interface unit here although it is importable\n  /// to ease the parsing.\n  bool isInNamedInterfaceUnit() const {\n    return ModuleDeclState.isNamedInterface();\n  }\n\n  /// Get the named module name we're preprocessing.\n  /// Requires we're preprocessing a named module.\n  StringRef getNamedModuleName() const { return ModuleDeclState.getName(); }\n\n  /// If we are implementing an implementation module unit.\n  /// Note that the module implementation partition is not considered as an\n  /// implementation unit.\n  bool isInImplementationUnit() const {\n    return ModuleDeclState.isImplementationUnit();\n  }\n\n  /// If we're importing a standard C++20 Named Modules.\n  bool isInImportingCXXNamedModules() const {\n    // NamedModuleImportPath will be non-empty only if we're importing\n    // Standard C++ named modules.\n    return !NamedModuleImportPath.empty() && getLangOpts().CPlusPlusModules &&\n           !IsAtImport;\n  }\n\n  /// Allocate a new MacroInfo object with the provided SourceLocation.\n  MacroInfo *AllocateMacroInfo(SourceLocation L);\n\n  /// Turn the specified lexer token into a fully checked and spelled\n  /// filename, e.g. as an operand of \\#include.\n  ///\n  /// The caller is expected to provide a buffer that is large enough to hold\n  /// the spelling of the filename, but is also expected to handle the case\n  /// when this method decides to use a different buffer.\n  ///\n  /// \\returns true if the input filename was in <>'s or false if it was\n  /// in \"\"'s.\n  bool GetIncludeFilenameSpelling(SourceLocation Loc,StringRef &Buffer);\n\n  /// Given a \"foo\" or \\<foo> reference, look up the indicated file.\n  ///\n  /// Returns std::nullopt on failure.  \\p isAngled indicates whether the file\n  /// reference is for system \\#include's or not (i.e. using <> instead of \"\").\n  OptionalFileEntryRef\n  LookupFile(SourceLocation FilenameLoc, StringRef Filename, bool isAngled,\n             ConstSearchDirIterator FromDir, const FileEntry *FromFile,\n             ConstSearchDirIterator *CurDir, SmallVectorImpl<char> *SearchPath,\n             SmallVectorImpl<char> *RelativePath,\n             ModuleMap::KnownHeader *SuggestedModule, bool *IsMapped,\n             bool *IsFrameworkFound, bool SkipCache = false,\n             bool OpenFile = true, bool CacheFailures = true);\n\n  /// Return true if we're in the top-level file, not in a \\#include.\n  bool isInPrimaryFile() const;\n\n  /// Lex an on-off-switch (C99 6.10.6p2) and verify that it is\n  /// followed by EOD.  Return true if the token is not a valid on-off-switch.\n  bool LexOnOffSwitch(tok::OnOffSwitch &Result);\n\n  bool CheckMacroName(Token &MacroNameTok, MacroUse isDefineUndef,\n                      bool *ShadowFlag = nullptr);\n\n  void EnterSubmodule(Module *M, SourceLocation ImportLoc, bool ForPragma);\n  Module *LeaveSubmodule(bool ForPragma);\n\nprivate:\n  friend void TokenLexer::ExpandFunctionArguments();\n\n  void PushIncludeMacroStack() {\n    assert(CurLexerKind != CLK_CachingLexer && \"cannot push a caching lexer\");\n    IncludeMacroStack.emplace_back(CurLexerKind, CurLexerSubmodule,\n                                   std::move(CurLexer), CurPPLexer,\n                                   std::move(CurTokenLexer), CurDirLookup);\n    CurPPLexer = nullptr;\n  }\n\n  void PopIncludeMacroStack() {\n    CurLexer = std::move(IncludeMacroStack.back().TheLexer);\n    CurPPLexer = IncludeMacroStack.back().ThePPLexer;\n    CurTokenLexer = std::move(IncludeMacroStack.back().TheTokenLexer);\n    CurDirLookup  = IncludeMacroStack.back().TheDirLookup;\n    CurLexerSubmodule = IncludeMacroStack.back().TheSubmodule;\n    CurLexerKind = IncludeMacroStack.back().CurLexerKind;\n    IncludeMacroStack.pop_back();\n  }\n\n  void PropagateLineStartLeadingSpaceInfo(Token &Result);\n\n  /// Determine whether we need to create module macros for #defines in the\n  /// current context.\n  bool needModuleMacros() const;\n\n  /// Update the set of active module macros and ambiguity flag for a module\n  /// macro name.\n  void updateModuleMacroInfo(const IdentifierInfo *II, ModuleMacroInfo &Info);\n\n  DefMacroDirective *AllocateDefMacroDirective(MacroInfo *MI,\n                                               SourceLocation Loc);\n  UndefMacroDirective *AllocateUndefMacroDirective(SourceLocation UndefLoc);\n  VisibilityMacroDirective *AllocateVisibilityMacroDirective(SourceLocation Loc,\n                                                             bool isPublic);\n\n  /// Lex and validate a macro name, which occurs after a\n  /// \\#define or \\#undef.\n  ///\n  /// \\param MacroNameTok Token that represents the name defined or undefined.\n  /// \\param IsDefineUndef Kind if preprocessor directive.\n  /// \\param ShadowFlag Points to flag that is set if macro name shadows\n  ///                   a keyword.\n  ///\n  /// This emits a diagnostic, sets the token kind to eod,\n  /// and discards the rest of the macro line if the macro name is invalid.\n  void ReadMacroName(Token &MacroNameTok, MacroUse IsDefineUndef = MU_Other,\n                     bool *ShadowFlag = nullptr);\n\n  /// ReadOptionalMacroParameterListAndBody - This consumes all (i.e. the\n  /// entire line) of the macro's tokens and adds them to MacroInfo, and while\n  /// doing so performs certain validity checks including (but not limited to):\n  ///   - # (stringization) is followed by a macro parameter\n  /// \\param MacroNameTok - Token that represents the macro name\n  /// \\param ImmediatelyAfterHeaderGuard - Macro follows an #ifdef header guard\n  ///\n  ///  Either returns a pointer to a MacroInfo object OR emits a diagnostic and\n  ///  returns a nullptr if an invalid sequence of tokens is encountered.\n  MacroInfo *ReadOptionalMacroParameterListAndBody(\n      const Token &MacroNameTok, bool ImmediatelyAfterHeaderGuard);\n\n  /// The ( starting an argument list of a macro definition has just been read.\n  /// Lex the rest of the parameters and the closing ), updating \\p MI with\n  /// what we learn and saving in \\p LastTok the last token read.\n  /// Return true if an error occurs parsing the arg list.\n  bool ReadMacroParameterList(MacroInfo *MI, Token& LastTok);\n\n  /// Provide a suggestion for a typoed directive. If there is no typo, then\n  /// just skip suggesting.\n  ///\n  /// \\param Tok - Token that represents the directive\n  /// \\param Directive - String reference for the directive name\n  void SuggestTypoedDirective(const Token &Tok, StringRef Directive) const;\n\n  /// We just read a \\#if or related directive and decided that the\n  /// subsequent tokens are in the \\#if'd out portion of the\n  /// file.  Lex the rest of the file, until we see an \\#endif.  If \\p\n  /// FoundNonSkipPortion is true, then we have already emitted code for part of\n  /// this \\#if directive, so \\#else/\\#elif blocks should never be entered. If\n  /// \\p FoundElse is false, then \\#else directives are ok, if not, then we have\n  /// already seen one so a \\#else directive is a duplicate.  When this returns,\n  /// the caller can lex the first valid token.\n  void SkipExcludedConditionalBlock(SourceLocation HashTokenLoc,\n                                    SourceLocation IfTokenLoc,\n                                    bool FoundNonSkipPortion, bool FoundElse,\n                                    SourceLocation ElseLoc = SourceLocation());\n\n  /// Information about the result for evaluating an expression for a\n  /// preprocessor directive.\n  struct DirectiveEvalResult {\n    /// Whether the expression was evaluated as true or not.\n    bool Conditional;\n\n    /// True if the expression contained identifiers that were undefined.\n    bool IncludedUndefinedIds;\n\n    /// The source range for the expression.\n    SourceRange ExprRange;\n  };\n\n  /// Evaluate an integer constant expression that may occur after a\n  /// \\#if or \\#elif directive and return a \\p DirectiveEvalResult object.\n  ///\n  /// If the expression is equivalent to \"!defined(X)\" return X in IfNDefMacro.\n  DirectiveEvalResult EvaluateDirectiveExpression(IdentifierInfo *&IfNDefMacro);\n\n  /// Process a '__has_include(\"path\")' expression.\n  ///\n  /// Returns true if successful.\n  bool EvaluateHasInclude(Token &Tok, IdentifierInfo *II);\n\n  /// Process '__has_include_next(\"path\")' expression.\n  ///\n  /// Returns true if successful.\n  bool EvaluateHasIncludeNext(Token &Tok, IdentifierInfo *II);\n\n  /// Get the directory and file from which to start \\#include_next lookup.\n  std::pair<ConstSearchDirIterator, const FileEntry *>\n  getIncludeNextStart(const Token &IncludeNextTok) const;\n\n  /// Install the standard preprocessor pragmas:\n  /// \\#pragma GCC poison/system_header/dependency and \\#pragma once.\n  void RegisterBuiltinPragmas();\n\n  /// Register builtin macros such as __LINE__ with the identifier table.\n  void RegisterBuiltinMacros();\n\n  /// If an identifier token is read that is to be expanded as a macro, handle\n  /// it and return the next token as 'Tok'.  If we lexed a token, return true;\n  /// otherwise the caller should lex again.\n  bool HandleMacroExpandedIdentifier(Token &Identifier, const MacroDefinition &MD);\n\n  /// Cache macro expanded tokens for TokenLexers.\n  //\n  /// Works like a stack; a TokenLexer adds the macro expanded tokens that is\n  /// going to lex in the cache and when it finishes the tokens are removed\n  /// from the end of the cache.\n  Token *cacheMacroExpandedTokens(TokenLexer *tokLexer,\n                                  ArrayRef<Token> tokens);\n\n  void removeCachedMacroExpandedTokensOfLastLexer();\n\n  /// Determine whether the next preprocessor token to be\n  /// lexed is a '('.  If so, consume the token and return true, if not, this\n  /// method should have no observable side-effect on the lexed tokens.\n  bool isNextPPTokenLParen();\n\n  /// After reading \"MACRO(\", this method is invoked to read all of the formal\n  /// arguments specified for the macro invocation.  Returns null on error.\n  MacroArgs *ReadMacroCallArgumentList(Token &MacroName, MacroInfo *MI,\n                                       SourceLocation &MacroEnd);\n\n  /// If an identifier token is read that is to be expanded\n  /// as a builtin macro, handle it and return the next token as 'Tok'.\n  void ExpandBuiltinMacro(Token &Tok);\n\n  /// Read a \\c _Pragma directive, slice it up, process it, then\n  /// return the first token after the directive.\n  /// This assumes that the \\c _Pragma token has just been read into \\p Tok.\n  void Handle_Pragma(Token &Tok);\n\n  /// Like Handle_Pragma except the pragma text is not enclosed within\n  /// a string literal.\n  void HandleMicrosoft__pragma(Token &Tok);\n\n  /// Add a lexer to the top of the include stack and\n  /// start lexing tokens from it instead of the current buffer.\n  void EnterSourceFileWithLexer(Lexer *TheLexer, ConstSearchDirIterator Dir);\n\n  /// Set the FileID for the preprocessor predefines.\n  void setPredefinesFileID(FileID FID) {\n    assert(PredefinesFileID.isInvalid() && \"PredefinesFileID already set!\");\n    PredefinesFileID = FID;\n  }\n\n  /// Set the FileID for the PCH through header.\n  void setPCHThroughHeaderFileID(FileID FID);\n\n  /// Returns true if we are lexing from a file and not a\n  /// pragma or a macro.\n  static bool IsFileLexer(const Lexer* L, const PreprocessorLexer* P) {\n    return L ? !L->isPragmaLexer() : P != nullptr;\n  }\n\n  static bool IsFileLexer(const IncludeStackInfo& I) {\n    return IsFileLexer(I.TheLexer.get(), I.ThePPLexer);\n  }\n\n  bool IsFileLexer() const {\n    return IsFileLexer(CurLexer.get(), CurPPLexer);\n  }\n\n  //===--------------------------------------------------------------------===//\n  // Caching stuff.\n  void CachingLex(Token &Result);\n\n  bool InCachingLexMode() const {\n    // If the Lexer pointers are 0 and IncludeMacroStack is empty, it means\n    // that we are past EOF, not that we are in CachingLex mode.\n    return !CurPPLexer && !CurTokenLexer && !IncludeMacroStack.empty();\n  }\n\n  void EnterCachingLexMode();\n  void EnterCachingLexModeUnchecked();\n\n  void ExitCachingLexMode() {\n    if (InCachingLexMode())\n      RemoveTopOfLexerStack();\n  }\n\n  const Token &PeekAhead(unsigned N);\n  void AnnotatePreviousCachedTokens(const Token &Tok);\n\n  //===--------------------------------------------------------------------===//\n  /// Handle*Directive - implement the various preprocessor directives.  These\n  /// should side-effect the current preprocessor object so that the next call\n  /// to Lex() will return the appropriate token next.\n  void HandleLineDirective();\n  void HandleDigitDirective(Token &Tok);\n  void HandleUserDiagnosticDirective(Token &Tok, bool isWarning);\n  void HandleIdentSCCSDirective(Token &Tok);\n  void HandleMacroPublicDirective(Token &Tok);\n  void HandleMacroPrivateDirective();\n\n  /// An additional notification that can be produced by a header inclusion or\n  /// import to tell the parser what happened.\n  struct ImportAction {\n    enum ActionKind {\n      None,\n      ModuleBegin,\n      ModuleImport,\n      HeaderUnitImport,\n      SkippedModuleImport,\n      Failure,\n    } Kind;\n    Module *ModuleForHeader = nullptr;\n\n    ImportAction(ActionKind AK, Module *Mod = nullptr)\n        : Kind(AK), ModuleForHeader(Mod) {\n      assert((AK == None || Mod || AK == Failure) &&\n             \"no module for module action\");\n    }\n  };\n\n  OptionalFileEntryRef LookupHeaderIncludeOrImport(\n      ConstSearchDirIterator *CurDir, StringRef &Filename,\n      SourceLocation FilenameLoc, CharSourceRange FilenameRange,\n      const Token &FilenameTok, bool &IsFrameworkFound, bool IsImportDecl,\n      bool &IsMapped, ConstSearchDirIterator LookupFrom,\n      const FileEntry *LookupFromFile, StringRef &LookupFilename,\n      SmallVectorImpl<char> &RelativePath, SmallVectorImpl<char> &SearchPath,\n      ModuleMap::KnownHeader &SuggestedModule, bool isAngled);\n\n  // File inclusion.\n  void HandleIncludeDirective(SourceLocation HashLoc, Token &Tok,\n                              ConstSearchDirIterator LookupFrom = nullptr,\n                              const FileEntry *LookupFromFile = nullptr);\n  ImportAction\n  HandleHeaderIncludeOrImport(SourceLocation HashLoc, Token &IncludeTok,\n                              Token &FilenameTok, SourceLocation EndLoc,\n                              ConstSearchDirIterator LookupFrom = nullptr,\n                              const FileEntry *LookupFromFile = nullptr);\n  void HandleIncludeNextDirective(SourceLocation HashLoc, Token &Tok);\n  void HandleIncludeMacrosDirective(SourceLocation HashLoc, Token &Tok);\n  void HandleImportDirective(SourceLocation HashLoc, Token &Tok);\n  void HandleMicrosoftImportDirective(Token &Tok);\n\npublic:\n  /// Check that the given module is available, producing a diagnostic if not.\n  /// \\return \\c true if the check failed (because the module is not available).\n  ///         \\c false if the module appears to be usable.\n  static bool checkModuleIsAvailable(const LangOptions &LangOpts,\n                                     const TargetInfo &TargetInfo,\n                                     DiagnosticsEngine &Diags, Module *M);\n\n  // Module inclusion testing.\n  /// Find the module that owns the source or header file that\n  /// \\p Loc points to. If the location is in a file that was included\n  /// into a module, or is outside any module, returns nullptr.\n  Module *getModuleForLocation(SourceLocation Loc, bool AllowTextual);\n\n  /// We want to produce a diagnostic at location IncLoc concerning an\n  /// unreachable effect at location MLoc (eg, where a desired entity was\n  /// declared or defined). Determine whether the right way to make MLoc\n  /// reachable is by #include, and if so, what header should be included.\n  ///\n  /// This is not necessarily fast, and might load unexpected module maps, so\n  /// should only be called by code that intends to produce an error.\n  ///\n  /// \\param IncLoc The location at which the missing effect was detected.\n  /// \\param MLoc A location within an unimported module at which the desired\n  ///        effect occurred.\n  /// \\return A file that can be #included to provide the desired effect. Null\n  ///         if no such file could be determined or if a #include is not\n  ///         appropriate (eg, if a module should be imported instead).\n  const FileEntry *getHeaderToIncludeForDiagnostics(SourceLocation IncLoc,\n                                                    SourceLocation MLoc);\n\n  bool isRecordingPreamble() const {\n    return PreambleConditionalStack.isRecording();\n  }\n\n  bool hasRecordedPreamble() const {\n    return PreambleConditionalStack.hasRecordedPreamble();\n  }\n\n  ArrayRef<PPConditionalInfo> getPreambleConditionalStack() const {\n      return PreambleConditionalStack.getStack();\n  }\n\n  void setRecordedPreambleConditionalStack(ArrayRef<PPConditionalInfo> s) {\n    PreambleConditionalStack.setStack(s);\n  }\n\n  void setReplayablePreambleConditionalStack(\n      ArrayRef<PPConditionalInfo> s, std::optional<PreambleSkipInfo> SkipInfo) {\n    PreambleConditionalStack.startReplaying();\n    PreambleConditionalStack.setStack(s);\n    PreambleConditionalStack.SkipInfo = SkipInfo;\n  }\n\n  std::optional<PreambleSkipInfo> getPreambleSkipInfo() const {\n    return PreambleConditionalStack.SkipInfo;\n  }\n\nprivate:\n  /// After processing predefined file, initialize the conditional stack from\n  /// the preamble.\n  void replayPreambleConditionalStack();\n\n  // Macro handling.\n  void HandleDefineDirective(Token &Tok, bool ImmediatelyAfterHeaderGuard);\n  void HandleUndefDirective();\n\n  // Conditional Inclusion.\n  void HandleIfdefDirective(Token &Result, const Token &HashToken,\n                            bool isIfndef, bool ReadAnyTokensBeforeDirective);\n  void HandleIfDirective(Token &IfToken, const Token &HashToken,\n                         bool ReadAnyTokensBeforeDirective);\n  void HandleEndifDirective(Token &EndifToken);\n  void HandleElseDirective(Token &Result, const Token &HashToken);\n  void HandleElifFamilyDirective(Token &ElifToken, const Token &HashToken,\n                                 tok::PPKeywordKind Kind);\n\n  // Pragmas.\n  void HandlePragmaDirective(PragmaIntroducer Introducer);\n\npublic:\n  void HandlePragmaOnce(Token &OnceTok);\n  void HandlePragmaMark(Token &MarkTok);\n  void HandlePragmaPoison();\n  void HandlePragmaSystemHeader(Token &SysHeaderTok);\n  void HandlePragmaDependency(Token &DependencyTok);\n  void HandlePragmaPushMacro(Token &Tok);\n  void HandlePragmaPopMacro(Token &Tok);\n  void HandlePragmaIncludeAlias(Token &Tok);\n  void HandlePragmaModuleBuild(Token &Tok);\n  void HandlePragmaHdrstop(Token &Tok);\n  IdentifierInfo *ParsePragmaPushOrPopMacro(Token &Tok);\n\n  // Return true and store the first token only if any CommentHandler\n  // has inserted some tokens and getCommentRetentionState() is false.\n  bool HandleComment(Token &result, SourceRange Comment);\n\n  /// A macro is used, update information about macros that need unused\n  /// warnings.\n  void markMacroAsUsed(MacroInfo *MI);\n\n  void addMacroDeprecationMsg(const IdentifierInfo *II, std::string Msg,\n                              SourceLocation AnnotationLoc) {\n    auto Annotations = AnnotationInfos.find(II);\n    if (Annotations == AnnotationInfos.end())\n      AnnotationInfos.insert(std::make_pair(\n          II,\n          MacroAnnotations::makeDeprecation(AnnotationLoc, std::move(Msg))));\n    else\n      Annotations->second.DeprecationInfo =\n          MacroAnnotationInfo{AnnotationLoc, std::move(Msg)};\n  }\n\n  void addRestrictExpansionMsg(const IdentifierInfo *II, std::string Msg,\n                               SourceLocation AnnotationLoc) {\n    auto Annotations = AnnotationInfos.find(II);\n    if (Annotations == AnnotationInfos.end())\n      AnnotationInfos.insert(\n          std::make_pair(II, MacroAnnotations::makeRestrictExpansion(\n                                 AnnotationLoc, std::move(Msg))));\n    else\n      Annotations->second.RestrictExpansionInfo =\n          MacroAnnotationInfo{AnnotationLoc, std::move(Msg)};\n  }\n\n  void addFinalLoc(const IdentifierInfo *II, SourceLocation AnnotationLoc) {\n    auto Annotations = AnnotationInfos.find(II);\n    if (Annotations == AnnotationInfos.end())\n      AnnotationInfos.insert(\n          std::make_pair(II, MacroAnnotations::makeFinal(AnnotationLoc)));\n    else\n      Annotations->second.FinalAnnotationLoc = AnnotationLoc;\n  }\n\n  const MacroAnnotations &getMacroAnnotations(const IdentifierInfo *II) const {\n    return AnnotationInfos.find(II)->second;\n  }\n\n  void emitMacroExpansionWarnings(const Token &Identifier) const {\n    if (Identifier.getIdentifierInfo()->isDeprecatedMacro())\n      emitMacroDeprecationWarning(Identifier);\n\n    if (Identifier.getIdentifierInfo()->isRestrictExpansion() &&\n        !SourceMgr.isInMainFile(Identifier.getLocation()))\n      emitRestrictExpansionWarning(Identifier);\n  }\n\n  static void processPathForFileMacro(SmallVectorImpl<char> &Path,\n                                      const LangOptions &LangOpts,\n                                      const TargetInfo &TI);\n\n  static void processPathToFileName(SmallVectorImpl<char> &FileName,\n                                    const PresumedLoc &PLoc,\n                                    const LangOptions &LangOpts,\n                                    const TargetInfo &TI);\n\nprivate:\n  void emitMacroDeprecationWarning(const Token &Identifier) const;\n  void emitRestrictExpansionWarning(const Token &Identifier) const;\n  void emitFinalMacroWarning(const Token &Identifier, bool IsUndef) const;\n\n  /// This boolean state keeps track if the current scanned token (by this PP)\n  /// is in an \"-Wunsafe-buffer-usage\" opt-out region. Assuming PP scans a\n  /// translation unit in a linear order.\n  bool InSafeBufferOptOutRegion = false;\n\n  /// Hold the start location of the current \"-Wunsafe-buffer-usage\" opt-out\n  /// region if PP is currently in such a region.  Hold undefined value\n  /// otherwise.\n  SourceLocation CurrentSafeBufferOptOutStart; // It is used to report the start location of an never-closed region.\n\n  // An ordered sequence of \"-Wunsafe-buffer-usage\" opt-out regions in one\n  // translation unit. Each region is represented by a pair of start and end\n  // locations.  A region is \"open\" if its' start and end locations are\n  // identical.\n  SmallVector<std::pair<SourceLocation, SourceLocation>, 8> SafeBufferOptOutMap;\n\npublic:\n  /// \\return true iff the given `Loc` is in a \"-Wunsafe-buffer-usage\" opt-out\n  /// region.  This `Loc` must be a source location that has been pre-processed.\n  bool isSafeBufferOptOut(const SourceManager&SourceMgr, const SourceLocation &Loc) const;\n\n  /// Alter the state of whether this PP currently is in a\n  /// \"-Wunsafe-buffer-usage\" opt-out region.\n  ///\n  /// \\param isEnter: true if this PP is entering a region; otherwise, this PP\n  /// is exiting a region\n  /// \\param Loc: the location of the entry or exit of a\n  /// region\n  /// \\return true iff it is INVALID to enter or exit a region, i.e.,\n  /// attempt to enter a region before exiting a previous region, or exiting a\n  /// region that PP is not currently in.\n  bool enterOrExitSafeBufferOptOutRegion(bool isEnter,\n                                         const SourceLocation &Loc);\n\n  /// \\return true iff this PP is currently in a \"-Wunsafe-buffer-usage\"\n  ///          opt-out region\n  bool isPPInSafeBufferOptOutRegion();\n\n  /// \\param StartLoc: output argument. It will be set to the start location of\n  /// the current \"-Wunsafe-buffer-usage\" opt-out region iff this function\n  /// returns true.\n  /// \\return true iff this PP is currently in a \"-Wunsafe-buffer-usage\"\n  ///          opt-out region\n  bool isPPInSafeBufferOptOutRegion(SourceLocation &StartLoc);\n}",
  "id": "BLOCK-CPP-19100",
  "language": "c++",
  "source_file": "/storage/emulated/0/Download/cpp_codebases/llvm/clang/include/clang/Lex/Preprocessor.h",
  "source_line": 128,
  "validation_status": "validated"
}