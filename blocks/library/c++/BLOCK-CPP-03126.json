{
  "code": "{\n\n// ThreadIdentity storage is persistent, we maintain a free-list of previously\n// released ThreadIdentity objects.\nABSL_CONST_INIT static base_internal::SpinLock freelist_lock(\n    absl::kConstInit, base_internal::SCHEDULE_KERNEL_ONLY);\nABSL_CONST_INIT static base_internal::ThreadIdentity* thread_identity_freelist;\n\n// A per-thread destructor for reclaiming associated ThreadIdentity objects.\n// Since we must preserve their storage we cache them for re-use.\nstatic void ReclaimThreadIdentity(void* v) {\n  base_internal::ThreadIdentity* identity =\n      static_cast<base_internal::ThreadIdentity*>(v);\n\n  // all_locks might have been allocated by the Mutex implementation.\n  // We free it here when we are notified that our thread is dying.\n  if (identity->per_thread_synch.all_locks != nullptr) {\n    base_internal::LowLevelAlloc::Free(identity->per_thread_synch.all_locks);\n  }\n\n  // We must explicitly clear the current thread's identity:\n  // (a) Subsequent (unrelated) per-thread destructors may require an identity.\n  //     We must guarantee a new identity is used in this case (this instructor\n  //     will be reinvoked up to PTHREAD_DESTRUCTOR_ITERATIONS in this case).\n  // (b) ThreadIdentity implementations may depend on memory that is not\n  //     reinitialized before reuse.  We must allow explicit clearing of the\n  //     association state in this case.\n  base_internal::ClearCurrentThreadIdentity();\n  {\n    base_internal::SpinLockHolder l(&freelist_lock);\n    identity->next = thread_identity_freelist;\n    thread_identity_freelist = identity;\n  }\n}\n\n// Return value rounded up to next multiple of align.\n// Align must be a power of two.\nstatic intptr_t RoundUp(intptr_t addr, intptr_t align) {\n  return (addr + align - 1) & ~(align - 1);\n}\n\nvoid OneTimeInitThreadIdentity(base_internal::ThreadIdentity* identity) {\n  PerThreadSem::Init(identity);\n  identity->ticker.store(0, std::memory_order_relaxed);\n  identity->wait_start.store(0, std::memory_order_relaxed);\n  identity->is_idle.store(false, std::memory_order_relaxed);\n}\n\nstatic void ResetThreadIdentityBetweenReuse(\n    base_internal::ThreadIdentity* identity) {\n  base_internal::PerThreadSynch* pts = &identity->per_thread_synch;\n  pts->next = nullptr;\n  pts->skip = nullptr;\n  pts->may_skip = false;\n  pts->waitp = nullptr;\n  pts->suppress_fatal_errors = false;\n  pts->readers = 0;\n  pts->priority = 0;\n  pts->next_priority_read_cycles = 0;\n  pts->state.store(base_internal::PerThreadSynch::State::kAvailable,\n                   std::memory_order_relaxed);\n  pts->maybe_unlocking = false;\n  pts->wake = false;\n  pts->cond_waiter = false;\n  pts->all_locks = nullptr;\n  identity->blocked_count_ptr = nullptr;\n  identity->ticker.store(0, std::memory_order_relaxed);\n  identity->wait_start.store(0, std::memory_order_relaxed);\n  identity->is_idle.store(false, std::memory_order_relaxed);\n  identity->next = nullptr;\n}\n\nstatic base_internal::ThreadIdentity* NewThreadIdentity() {\n  base_internal::ThreadIdentity* identity = nullptr;\n\n  {\n    // Re-use a previously released object if possible.\n    base_internal::SpinLockHolder l(&freelist_lock);\n    if (thread_identity_freelist) {\n      identity = thread_identity_freelist;  // Take list-head.\n      thread_identity_freelist = thread_identity_freelist->next;\n    }\n  }\n\n  if (identity == nullptr) {\n    // Allocate enough space to align ThreadIdentity to a multiple of\n    // PerThreadSynch::kAlignment. This space is never released (it is\n    // added to a freelist by ReclaimThreadIdentity instead).\n    void* allocation = base_internal::LowLevelAlloc::Alloc(\n        sizeof(*identity) + base_internal::PerThreadSynch::kAlignment - 1);\n    // Round up the address to the required alignment.\n    identity = reinterpret_cast<base_internal::ThreadIdentity*>(\n        RoundUp(reinterpret_cast<intptr_t>(allocation),\n                base_internal::PerThreadSynch::kAlignment));\n    OneTimeInitThreadIdentity(identity);\n  }\n  ResetThreadIdentityBetweenReuse(identity);\n\n  return identity;\n}\n\n// Allocates and attaches ThreadIdentity object for the calling thread.  Returns\n// the new identity.\n// REQUIRES: CurrentThreadIdentity(false) == nullptr\nbase_internal::ThreadIdentity* CreateThreadIdentity() {\n  base_internal::ThreadIdentity* identity = NewThreadIdentity();\n  // Associate the value with the current thread, and attach our destructor.\n  base_internal::SetCurrentThreadIdentity(identity, ReclaimThreadIdentity);\n  return identity;\n}\n\n}",
  "id": "BLOCK-CPP-03126",
  "language": "c++",
  "source_file": "/storage/emulated/0/Download/cpp_codebases/abseil/absl/synchronization/internal/create_thread_identity.cc",
  "source_line": 33,
  "validation_status": "validated"
}