{
  "code": "{\n\n#ifdef ABSL_INTERNAL_NEED_REDUNDANT_CONSTEXPR_DECL\nconstexpr uint64_t KernelTimeout::kNoTimeout;\nconstexpr int64_t KernelTimeout::kMaxNanos;\n#endif\n\nint64_t KernelTimeout::SteadyClockNow() {\n  if (!SupportsSteadyClock()) {\n    return absl::GetCurrentTimeNanos();\n  }\n  return std::chrono::duration_cast<std::chrono::nanoseconds>(\n             std::chrono::steady_clock::now().time_since_epoch())\n      .count();\n}\n\nKernelTimeout::KernelTimeout(absl::Time t) {\n  // `absl::InfiniteFuture()` is a common \"no timeout\" value and cheaper to\n  // compare than convert.\n  if (t == absl::InfiniteFuture()) {\n    rep_ = kNoTimeout;\n    return;\n  }\n\n  int64_t unix_nanos = absl::ToUnixNanos(t);\n\n  // A timeout that lands before the unix epoch is converted to 0.\n  // In theory implementations should expire these timeouts immediately.\n  if (unix_nanos < 0) {\n    unix_nanos = 0;\n  }\n\n  // Values greater than or equal to kMaxNanos are converted to infinite.\n  if (unix_nanos >= kMaxNanos) {\n    rep_ = kNoTimeout;\n    return;\n  }\n\n  rep_ = static_cast<uint64_t>(unix_nanos) << 1;\n}\n\nKernelTimeout::KernelTimeout(absl::Duration d) {\n  // `absl::InfiniteDuration()` is a common \"no timeout\" value and cheaper to\n  // compare than convert.\n  if (d == absl::InfiniteDuration()) {\n    rep_ = kNoTimeout;\n    return;\n  }\n\n  int64_t nanos = absl::ToInt64Nanoseconds(d);\n\n  // Negative durations are normalized to 0.\n  // In theory implementations should expire these timeouts immediately.\n  if (nanos < 0) {\n    nanos = 0;\n  }\n\n  int64_t now = SteadyClockNow();\n  if (nanos > kMaxNanos - now) {\n    // Durations that would be greater than kMaxNanos are converted to infinite.\n    rep_ = kNoTimeout;\n    return;\n  }\n\n  nanos += now;\n  rep_ = (static_cast<uint64_t>(nanos) << 1) | uint64_t{1};\n}\n\nint64_t KernelTimeout::MakeAbsNanos() const {\n  if (!has_timeout()) {\n    return kMaxNanos;\n  }\n\n  int64_t nanos = RawAbsNanos();\n\n  if (is_relative_timeout()) {\n    // We need to change epochs, because the relative timeout might be\n    // represented by an absolute timestamp from another clock.\n    nanos = std::max<int64_t>(nanos - SteadyClockNow(), 0);\n    int64_t now = absl::GetCurrentTimeNanos();\n    if (nanos > kMaxNanos - now) {\n      // Overflow.\n      nanos = kMaxNanos;\n    } else {\n      nanos += now;\n    }\n  } else if (nanos == 0) {\n    // Some callers have assumed that 0 means no timeout, so instead we return a\n    // time of 1 nanosecond after the epoch.\n    nanos = 1;\n  }\n\n  return nanos;\n}\n\nint64_t KernelTimeout::InNanosecondsFromNow() const {\n  if (!has_timeout()) {\n    return kMaxNanos;\n  }\n\n  int64_t nanos = RawAbsNanos();\n  if (is_absolute_timeout()) {\n    return std::max<int64_t>(nanos - absl::GetCurrentTimeNanos(), 0);\n  }\n  return std::max<int64_t>(nanos - SteadyClockNow(), 0);\n}\n\nstruct timespec KernelTimeout::MakeAbsTimespec() const {\n  return absl::ToTimespec(absl::Nanoseconds(MakeAbsNanos()));\n}\n\nstruct timespec KernelTimeout::MakeRelativeTimespec() const {\n  return absl::ToTimespec(absl::Nanoseconds(InNanosecondsFromNow()));\n}\n\n#ifndef _WIN32\nstruct timespec KernelTimeout::MakeClockAbsoluteTimespec(clockid_t c) const {\n  if (!has_timeout()) {\n    return absl::ToTimespec(absl::Nanoseconds(kMaxNanos));\n  }\n\n  int64_t nanos = RawAbsNanos();\n  if (is_absolute_timeout()) {\n    nanos -= absl::GetCurrentTimeNanos();\n  } else {\n    nanos -= SteadyClockNow();\n  }\n\n  struct timespec now;\n  ABSL_RAW_CHECK(clock_gettime(c, &now) == 0, \"clock_gettime() failed\");\n  absl::Duration from_clock_epoch =\n      absl::DurationFromTimespec(now) + absl::Nanoseconds(nanos);\n  if (from_clock_epoch <= absl::ZeroDuration()) {\n    // Some callers have assumed that 0 means no timeout, so instead we return a\n    // time of 1 nanosecond after the epoch. For safety we also do not return\n    // negative values.\n    return absl::ToTimespec(absl::Nanoseconds(1));\n  }\n  return absl::ToTimespec(from_clock_epoch);\n}\n#endif\n\nKernelTimeout::DWord KernelTimeout::InMillisecondsFromNow() const {\n  constexpr DWord kInfinite = std::numeric_limits<DWord>::max();\n\n  if (!has_timeout()) {\n    return kInfinite;\n  }\n\n  constexpr uint64_t kNanosInMillis = uint64_t{1'000'000};\n  constexpr uint64_t kMaxValueNanos =\n      std::numeric_limits<int64_t>::max() - kNanosInMillis + 1;\n\n  uint64_t ns_from_now = static_cast<uint64_t>(InNanosecondsFromNow());\n  if (ns_from_now >= kMaxValueNanos) {\n    // Rounding up would overflow.\n    return kInfinite;\n  }\n  // Convert to milliseconds, always rounding up.\n  uint64_t ms_from_now = (ns_from_now + kNanosInMillis - 1) / kNanosInMillis;\n  if (ms_from_now > kInfinite) {\n    return kInfinite;\n  }\n  return static_cast<DWord>(ms_from_now);\n}\n\nstd::chrono::time_point<std::chrono::system_clock>\nKernelTimeout::ToChronoTimePoint() const {\n  if (!has_timeout()) {\n    return std::chrono::time_point<std::chrono::system_clock>::max();\n  }\n\n  // The cast to std::microseconds is because (on some platforms) the\n  // std::ratio used by std::chrono::steady_clock doesn't convert to\n  // std::nanoseconds, so it doesn't compile.\n  auto micros = std::chrono::duration_cast<std::chrono::microseconds>(\n      std::chrono::nanoseconds(MakeAbsNanos()));\n  return std::chrono::system_clock::from_time_t(0) + micros;\n}\n\nstd::chrono::nanoseconds KernelTimeout::ToChronoDuration() const {\n  if (!has_timeout()) {\n    return std::chrono::nanoseconds::max();\n  }\n  return std::chrono::nanoseconds(InNanosecondsFromNow());\n}\n\n}",
  "id": "BLOCK-CPP-03177",
  "language": "c++",
  "source_file": "/storage/emulated/0/Download/cpp_codebases/abseil/absl/synchronization/internal/kernel_timeout.cc",
  "source_line": 36,
  "validation_status": "validated"
}