{
  "code": "{\n\n// Note: all constants below are never ODR used and internal to cord, we define\n// these as static constexpr to avoid 'in struct' definition and usage clutter.\n\n// Largest and smallest flat node lengths we are willing to allocate\n// Flat allocation size is stored in tag, which currently can encode sizes up\n// to 4K, encoded as multiple of either 8 or 32 bytes.\n// If we allow for larger sizes, we need to change this to 8/64, 16/128, etc.\n// kMinFlatSize is bounded by tag needing to be at least FLAT * 8 bytes, and\n// ideally a 'nice' size aligning with allocation and cacheline sizes like 32.\n// kMaxFlatSize is bounded by the size resulting in a computed tag no greater\n// than MAX_FLAT_TAG. MAX_FLAT_TAG provides for additional 'high' tag values.\nstatic constexpr size_t kFlatOverhead = offsetof(CordRep, storage);\nstatic constexpr size_t kMinFlatSize = 32;\nstatic constexpr size_t kMaxFlatSize = 4096;\nstatic constexpr size_t kMaxFlatLength = kMaxFlatSize - kFlatOverhead;\nstatic constexpr size_t kMinFlatLength = kMinFlatSize - kFlatOverhead;\nstatic constexpr size_t kMaxLargeFlatSize = 256 * 1024;\nstatic constexpr size_t kMaxLargeFlatLength = kMaxLargeFlatSize - kFlatOverhead;\n\n// kTagBase should make the Size <--> Tag computation resilient\n// against changes to the value of FLAT when we add a new tag..\nstatic constexpr uint8_t kTagBase = FLAT - 4;\n\n// Converts the provided rounded size to the corresponding tag\nconstexpr uint8_t AllocatedSizeToTagUnchecked(size_t size) {\n  return static_cast<uint8_t>(size <= 512 ? kTagBase + size / 8\n                              : size <= 8192\n                                  ? kTagBase + 512 / 8 + size / 64 - 512 / 64\n                                  : kTagBase + 512 / 8 + ((8192 - 512) / 64) +\n                                        size / 4096 - 8192 / 4096);\n}\n\n// Converts the provided tag to the corresponding allocated size\nconstexpr size_t TagToAllocatedSize(uint8_t tag) {\n  return (tag <= kTagBase + 512 / 8) ? tag * 8 - kTagBase * 8\n         : (tag <= kTagBase + (512 / 8) + ((8192 - 512) / 64))\n             ? 512 + tag * 64 - kTagBase * 64 - 512 / 8 * 64\n             : 8192 + tag * 4096 - kTagBase * 4096 -\n                   ((512 / 8) + ((8192 - 512) / 64)) * 4096;\n}\n\nstatic_assert(AllocatedSizeToTagUnchecked(kMinFlatSize) == FLAT, \"\");\nstatic_assert(AllocatedSizeToTagUnchecked(kMaxLargeFlatSize) == MAX_FLAT_TAG,\n              \"\");\n\n// RoundUp logically performs `((n + m - 1) / m) * m` to round up to the nearest\n// multiple of `m`, optimized for the invariant that `m` is a power of 2.\nconstexpr size_t RoundUp(size_t n, size_t m) {\n  return (n + m - 1) & (0 - m);\n}\n\n// Returns the size to the nearest equal or larger value that can be\n// expressed exactly as a tag value.\ninline size_t RoundUpForTag(size_t size) {\n  return RoundUp(size, (size <= 512) ? 8 : (size <= 8192 ? 64 : 4096));\n}\n\n// Converts the allocated size to a tag, rounding down if the size\n// does not exactly match a 'tag expressible' size value. The result is\n// undefined if the size exceeds the maximum size that can be encoded in\n// a tag, i.e., if size is larger than TagToAllocatedSize(<max tag>).\ninline uint8_t AllocatedSizeToTag(size_t size) {\n  const uint8_t tag = AllocatedSizeToTagUnchecked(size);\n  assert(tag <= MAX_FLAT_TAG);\n  return tag;\n}\n\n// Converts the provided tag to the corresponding available data length\nconstexpr size_t TagToLength(uint8_t tag) {\n  return TagToAllocatedSize(tag) - kFlatOverhead;\n}\n\n// Enforce that kMaxFlatSize maps to a well-known exact tag value.\nstatic_assert(TagToAllocatedSize(MAX_FLAT_TAG) == kMaxLargeFlatSize,\n              \"Bad tag logic\");\n\nstruct CordRepFlat : public CordRep {\n  // Tag for explicit 'large flat' allocation\n  struct Large {};\n\n  // Creates a new flat node.\n  template <size_t max_flat_size, typename... Args>\n  static CordRepFlat* NewImpl(size_t len, Args... args ABSL_ATTRIBUTE_UNUSED) {\n    if (len <= kMinFlatLength) {\n      len = kMinFlatLength;\n    } else if (len > max_flat_size - kFlatOverhead) {\n      len = max_flat_size - kFlatOverhead;\n    }\n\n    // Round size up so it matches a size we can exactly express in a tag.\n    const size_t size = RoundUpForTag(len + kFlatOverhead);\n    void* const raw_rep = ::operator new(size);\n    // GCC 13 has a false-positive -Wstringop-overflow warning here.\n    #if ABSL_INTERNAL_HAVE_MIN_GNUC_VERSION(13, 0)\n    #pragma GCC diagnostic push\n    #pragma GCC diagnostic ignored \"-Wstringop-overflow\"\n    #endif\n    CordRepFlat* rep = new (raw_rep) CordRepFlat();\n    rep->tag = AllocatedSizeToTag(size);\n    #if ABSL_INTERNAL_HAVE_MIN_GNUC_VERSION(13, 0)\n    #pragma GCC diagnostic pop\n    #endif\n    return rep;\n  }\n\n  static CordRepFlat* New(size_t len) { return NewImpl<kMaxFlatSize>(len); }\n\n  static CordRepFlat* New(Large, size_t len) {\n    return NewImpl<kMaxLargeFlatSize>(len);\n  }\n\n  // Deletes a CordRepFlat instance created previously through a call to New().\n  // Flat CordReps are allocated and constructed with raw ::operator new and\n  // placement new, and must be destructed and deallocated accordingly.\n  static void Delete(CordRep*rep) {\n    assert(rep->tag >= FLAT && rep->tag <= MAX_FLAT_TAG);\n\n#if defined(__cpp_sized_deallocation)\n    size_t size = TagToAllocatedSize(rep->tag);\n    rep->~CordRep();\n    ::operator delete(rep, size);\n#else\n    rep->~CordRep();\n    ::operator delete(rep);\n#endif\n  }\n\n  // Create a CordRepFlat containing `data`, with an optional additional\n  // extra capacity of up to `extra` bytes. Requires that `data.size()`\n  // is less than kMaxFlatLength.\n  static CordRepFlat* Create(absl::string_view data, size_t extra = 0) {\n    assert(data.size() <= kMaxFlatLength);\n    CordRepFlat* flat = New(data.size() + (std::min)(extra, kMaxFlatLength));\n    memcpy(flat->Data(), data.data(), data.size());\n    flat->length = data.size();\n    return flat;\n  }\n\n  // Returns a pointer to the data inside this flat rep.\n  char* Data() { return reinterpret_cast<char*>(storage); }\n  const char* Data() const { return reinterpret_cast<const char*>(storage); }\n\n  // Returns the maximum capacity (payload size) of this instance.\n  size_t Capacity() const { return TagToLength(tag); }\n\n  // Returns the allocated size (payload + overhead) of this instance.\n  size_t AllocatedSize() const { return TagToAllocatedSize(tag); }\n};\n\n// Now that CordRepFlat is defined, we can define CordRep's helper casts:\ninline CordRepFlat* CordRep::flat() {\n  assert(tag >= FLAT && tag <= MAX_FLAT_TAG);\n  return reinterpret_cast<CordRepFlat*>(this);\n}\n\ninline const CordRepFlat* CordRep::flat() const {\n  assert(tag >= FLAT && tag <= MAX_FLAT_TAG);\n  return reinterpret_cast<const CordRepFlat*>(this);\n}\n\n}",
  "id": "BLOCK-CPP-06166",
  "language": "c++",
  "source_file": "/storage/emulated/0/Download/cpp_codebases/abseil/absl/strings/internal/cord_rep_flat.h",
  "source_line": 29,
  "validation_status": "validated"
}