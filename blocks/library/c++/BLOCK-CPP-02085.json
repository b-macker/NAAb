{
  "code": "#include \"absl/synchronization/mutex.h\"\n#include <windows.h>\n#include <fcntl.h>\n#include <pthread.h>\n#include <sched.h>\n#include <sys/time.h>\n#include <assert.h>\n#include <errno.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <time.h>\n#include <algorithm>\n#include <atomic>\n#include <cstddef>\n#include <cstdlib>\n#include <cstring>\n#include <thread>  // NOLINT(build/c++11)\n#include \"absl/base/attributes.h\"\n#include \"absl/base/call_once.h\"\n#include \"absl/base/config.h\"\n#include \"absl/base/dynamic_annotations.h\"\n#include \"absl/base/internal/atomic_hook.h\"\n#include \"absl/base/internal/cycleclock.h\"\n#include \"absl/base/internal/hide_ptr.h\"\n#include \"absl/base/internal/low_level_alloc.h\"\n#include \"absl/base/internal/raw_logging.h\"\n#include \"absl/base/internal/spinlock.h\"\n#include \"absl/base/internal/sysinfo.h\"\n#include \"absl/base/internal/thread_identity.h\"\n#include \"absl/base/internal/tsan_mutex_interface.h\"\n#include \"absl/base/optimization.h\"\n#include \"absl/debugging/stacktrace.h\"\n#include \"absl/debugging/symbolize.h\"\n#include \"absl/synchronization/internal/graphcycles.h\"\n#include \"absl/synchronization/internal/per_thread_sem.h\"\n#include \"absl/time/time.h\"\n\nusing namespace absl;\nusing namespace synchronization_internal;\nusing namespace synchronization_internal;\n\nextern \"C\" {\n\nvoid BLOCK-CPP-02085_execute() {\n    {\n  if (synch_deadlock_detection.load(std::memory_order_acquire) ==\n      OnDeadlockCycle::kIgnore) {\n    return InvalidGraphId();\n  }\n\n  SynchLocksHeld* all_locks = Synch_GetAllLocks();\n\n  absl::base_internal::SpinLockHolder lock(&deadlock_graph_mu);\n  const GraphId mu_id = GetGraphIdLocked(mu);\n\n  if (all_locks->n == 0) {\n    // There are no other locks held. Return now so that we don't need to\n    // call GetSynchEvent(). This way we do not record the stack trace\n    // for this Mutex. It's ok, since if this Mutex is involved in a deadlock,\n    // it can't always be the first lock acquired by a thread.\n    return mu_id;\n  }\n\n  // We prefer to keep stack traces that show a thread holding and acquiring\n  // as many locks as possible.  This increases the chances that a given edge\n  // in the acquires-before graph will be represented in the stack traces\n  // recorded for the locks.\n  deadlock_graph->UpdateStackTrace(mu_id, all_locks->n + 1, GetStack);\n\n  // For each other mutex already held by this thread:\n  for (int i = 0; i != all_locks->n; i++) {\n    const GraphId other_node_id = all_locks->locks[i].id;\n    const Mutex* other =\n        static_cast<const Mutex*>(deadlock_graph->Ptr(other_node_id));\n    if (other == nullptr) {\n      // Ignore stale lock\n      continue;\n    }\n\n    // Add the acquired-before edge to the graph.\n    if (!deadlock_graph->InsertEdge(other_node_id, mu_id)) {\n      ScopedDeadlockReportBuffers scoped_buffers;\n      DeadlockReportBuffers* b = scoped_buffers.b;\n      static int number_of_reported_deadlocks = 0;\n      number_of_reported_deadlocks++;\n      // Symbolize only 2 first deadlock report to avoid huge slowdowns.\n      bool symbolize = number_of_reported_deadlocks <= 2;\n      ABSL_RAW_LOG(ERROR, \"Potential Mutex deadlock: %s\",\n                   CurrentStackString(b->buf, sizeof (b->buf), symbolize));\n      size_t len = 0;\n      for (int j = 0; j != all_locks->n; j++) {\n        void* pr = deadlock_graph->Ptr(all_locks->locks[j].id);\n        if (pr != nullptr) {\n          snprintf(b->buf + len, sizeof(b->buf) - len, \" %p\", pr);\n          len += strlen(&b->buf[len]);\n        }\n      }\n      ABSL_RAW_LOG(ERROR,\n                   \"Acquiring absl::Mutex %p while holding %s; a cycle in the \"\n                   \"historical lock ordering graph has been observed\",\n                   static_cast<void*>(mu), b->buf);\n      ABSL_RAW_LOG(ERROR, \"Cycle: \");\n      int path_len = deadlock_graph->FindPath(mu_id, other_node_id,\n                                              ABSL_ARRAYSIZE(b->path), b->path);\n      for (int j = 0; j != path_len && j != ABSL_ARRAYSIZE(b->path); j++) {\n        GraphId id = b->path[j];\n        Mutex* path_mu = static_cast<Mutex*>(deadlock_graph->Ptr(id));\n        if (path_mu == nullptr) continue;\n        void** stack;\n        int depth = deadlock_graph->GetStackTrace(id, &stack);\n        snprintf(b->buf, sizeof(b->buf),\n                 \"mutex@%p stack: \", static_cast<void*>(path_mu));\n        StackString(stack, depth, b->buf + strlen(b->buf),\n                    static_cast<int>(sizeof(b->buf) - strlen(b->buf)),\n                    symbolize);\n        ABSL_RAW_LOG(ERROR, \"%s\", b->buf);\n      }\n      if (path_len > static_cast<int>(ABSL_ARRAYSIZE(b->path))) {\n        ABSL_RAW_LOG(ERROR, \"(long cycle; list truncated)\");\n      }\n      if (synch_deadlock_detection.load(std::memory_order_acquire) ==\n          OnDeadlockCycle::kAbort) {\n        deadlock_graph_mu.Unlock();  // avoid deadlock in fatal sighandler\n        ABSL_RAW_LOG(FATAL, \"dying due to potential deadlock\");\n        return mu_id;\n      }\n      break;  // report at most one potential deadlock per acquisition\n    }\n  }\n\n  return mu_id;\n}\n}\n\n} // extern \"C\"\n",
  "id": "BLOCK-CPP-02085",
  "language": "c++",
  "source_file": "/storage/emulated/0/Download/cpp_codebases/abseil/absl/synchronization/mutex.cc",
  "source_line": 1375,
  "validation_status": "validated"
}